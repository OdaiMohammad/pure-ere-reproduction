{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7145ef96-18f7-4c97-ba26-a3d20df5fcda",
   "metadata": {},
   "source": [
    "# Running the relation model\n",
    "In this notebook we will run and evalute the relation model proposed in the research paper [A Frustratingly Easy Approach for Entity and Relation Extraction](https://arxiv.org/pdf/2010.12812.pdf).\n",
    "\n",
    "This is a reproduction based on the instructions left by the authors in their [GitHub repo](https://github.com/princeton-nlp/PURE)\n",
    "\n",
    "**Environment information**\n",
    "\n",
    "- Windows 11\n",
    "- Python 3.6.13\n",
    "- pip 21.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c0e8b-76a1-468e-b48a-9b473be65ca7",
   "metadata": {},
   "source": [
    "## Basic setup\n",
    "Firstly, we setup our notebook by importing needed libraries and modules.\n",
    "\n",
    "And we initialize a logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35c9995f-df21-4e6c-bed8-d759200ef493",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers import AlbertModel, AlbertPreTrainedModel\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger('run_relation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51decb14-3791-4e74-affc-f40cf2917b08",
   "metadata": {},
   "source": [
    "## Main classes\n",
    "The authors have implemented their system in an OOP style. Let's go through the defined classes and understand what they do.\n",
    "\n",
    "### BertForRelation\n",
    "This Python class is a custom implementation of a relation classification model based on the BERT (Bidirectional Encoder Representations from Transformers) architecture. Let me break down the key components:\n",
    "This class inherits from BertPreTrainedModel. Therefore, it's building on top of an existing BERT model. This is done to leverage th pre-trained BERT model's weights and then fine-tune it for our specific task.\n",
    "\n",
    "The BertForRelation class is designed for relation classification tasks, where the goal is to predict the relationship between entities in a given text. It leverages the BERT (Bidirectional Encoder Representations from Transformers) architecture and extends the BertPreTrainedModel class, building upon a pre-trained BERT model.\n",
    "\n",
    "The constructor initializes various components of the model:\n",
    "\n",
    "- config: BERT model configuration.\n",
    "- num_rel_labels: Number of distinct relation labels.\n",
    "\n",
    "The setup includes:\n",
    "\n",
    "- bert: The BERT model initialized with the provided configuration.\n",
    "- dropout: A dropout layer with a dropout probability specified in the BERT configuration.\n",
    "- layer_norm: Layer normalization applied to the concatenated output of the subject and object representations.\n",
    "- classifier: A linear layer for classification, mapping the concatenated representation to the output logits.\n",
    "- init_weights(): Initialization of the model's weights.\n",
    "\n",
    "We must note the setup of the model:\n",
    "\n",
    "```python\n",
    "self.classifier = nn.Linear(config.hidden_size * 2, self.num_labels)\n",
    "```\n",
    "\n",
    "The model is a linear layer that takes the concatenated representation of subject and object entities as input and produces logits for each possible relation label.\n",
    "\n",
    "\n",
    "- It's defined using nn.Linear and consists of two layers.\n",
    "- Input dimension (input_dim) is set to the sum of the following:\n",
    "  - config.hidden_size: corresponds to the hidden size of the BERT model. In BERT, each token in the input sequence is associated with a hidden vector of this size.\n",
    "  - * 2: The * 2 indicates that the representations of the subject and object entities are concatenated. So, the input dimension is twice the hidden size. This is likely because the model wants to capture information from both the start and end embeddings of the entities.\n",
    "\n",
    "Output Layer:\n",
    "\n",
    "`self.num_labels` is the number of distinct relation labels that the model is designed to classify. Each output neuron in the linear layer corresponds to a specific relation label.\n",
    "\n",
    "The overall architecture is a simple linear transformation that maps the concatenated representation of subject and object entities to a vector of logits, where each element of the vector corresponds to the model's prediction for a specific relation label. This linear layer is typically followed by a softmax activation during training to convert the logits into probabilities and compute the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3a60c06-d042-4fa9-a2a0-8daba9d62f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForRelation(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_rel_labels):\n",
    "        super(BertForRelation, self).__init__(config)\n",
    "        self.num_labels = num_rel_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.layer_norm = BertLayerNorm(config.hidden_size * 2)\n",
    "        self.classifier = nn.Linear(config.hidden_size * 2, self.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, sub_idx=None, obj_idx=None, input_position=None):\n",
    "        outputs = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, output_hidden_states=False, output_attentions=False, position_ids=input_position)\n",
    "        sequence_output = outputs[0]\n",
    "        sub_output = torch.cat([a[i].unsqueeze(0) for a, i in zip(sequence_output, sub_idx)])\n",
    "        obj_output = torch.cat([a[i].unsqueeze(0) for a, i in zip(sequence_output, obj_idx)])\n",
    "        rep = torch.cat((sub_output, obj_output), dim=1)\n",
    "        rep = self.layer_norm(rep)\n",
    "        rep = self.dropout(rep)\n",
    "        logits = self.classifier(rep)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba491f0-3343-4ccf-9d62-820f4794881f",
   "metadata": {},
   "source": [
    "### AlbertForRelation\n",
    "\n",
    "There's also the class AlbertForEntity. Which is very similar to the BertForEntity with a key difference in the underlying transformer architecture they use: BertForRelation is based on BERT, while AlbertForRelation is based on ALBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33aafec3-d7f0-4a7c-9472-1a574176cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbertForRelation(AlbertPreTrainedModel):\n",
    "    def __init__(self, config, num_rel_labels):\n",
    "        super(AlbertForRelation, self).__init__(config)\n",
    "        self.num_labels = num_rel_labels\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.layer_norm = BertLayerNorm(config.hidden_size * 2)\n",
    "        self.classifier = nn.Linear(config.hidden_size * 2, self.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, sub_idx=None, obj_idx=None):\n",
    "        outputs = self.albert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, output_hidden_states=False, output_attentions=False)\n",
    "        sequence_output = outputs[0]\n",
    "        sub_output = torch.cat([a[i].unsqueeze(0) for a, i in zip(sequence_output, sub_idx)])\n",
    "        obj_output = torch.cat([a[i].unsqueeze(0) for a, i in zip(sequence_output, obj_idx)])\n",
    "        rep = torch.cat((sub_output, obj_output), dim=1)\n",
    "        rep = self.layer_norm(rep)\n",
    "        rep = self.dropout(rep)\n",
    "        logits = self.classifier(rep)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081a11b-3e18-4310-bf9c-2cbb163685e1",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Represents a dataset. It's a convenient wrapper for handling datasets, reading data from JSON files, and creating Document objects.\n",
    "\n",
    "Let's break down its components:\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the Dataset class.\n",
    "- Takes three parameters: `json_file`, `pred_file` **(default is `None`)**, and `doc_range` **(default is `None`)**.\n",
    "- Reads data from the specified JSON files (`json_file` and `pred_file`).\n",
    "- If a document range (`doc_range`) is provided, it selects a subset of documents within that range.\n",
    "- Creates a list of Document objects based on the read data.\n",
    "\n",
    "#### `update_from_js` method:\n",
    "\n",
    "- Updates the dataset with new data (`js`).\n",
    "- Re-creates the list of `Document` objects based on the updated data.\n",
    "\n",
    "#### \\`_read method`:\n",
    "\n",
    "- Reads data from JSON files (`json_file` and optionally `pred_file`).\n",
    "If `pred_file` is provided, it merges the data from the gold (`gold_docs`) and predicted (`pred_docs`) files.\n",
    "- Returns the merged list of documents.\n",
    "\n",
    "#### `__getitem__` method:\n",
    "\n",
    "- Enables indexing of the dataset. Given an index `ix`, it returns the corresponding Document object.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "- Returns the length of the dataset, i.e., the number of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73432310-8161-4745-b55a-f93e909e4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, json_file, pred_file=None, doc_range=None):\n",
    "        self.js = self._read(json_file, pred_file)\n",
    "        if doc_range is not None:\n",
    "            self.js = self.js[doc_range[0]:doc_range[1]]\n",
    "        self.documents = [Document(js) for js in self.js]\n",
    "\n",
    "    def update_from_js(self, js):\n",
    "        self.js = js\n",
    "        self.documents = [Document(js) for js in self.js]\n",
    "\n",
    "    def _read(self, json_file, pred_file=None):\n",
    "        gold_docs = [json.loads(line) for line in open(json_file)]\n",
    "        if pred_file is None:\n",
    "            return gold_docs\n",
    "\n",
    "        pred_docs = [json.loads(line) for line in open(pred_file)]\n",
    "        merged_docs = []\n",
    "        for gold, pred in zip(gold_docs, pred_docs):\n",
    "            assert gold[\"doc_key\"] == pred[\"doc_key\"]\n",
    "            assert gold[\"sentences\"] == pred[\"sentences\"]\n",
    "            merged = copy.deepcopy(gold)\n",
    "            for k, v in pred.items():\n",
    "                if \"predicted\" in k:\n",
    "                    merged[k] = v\n",
    "            merged_docs.append(merged)\n",
    "\n",
    "        return merged_docs\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.documents[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f5272-c06f-454b-a090-6598218876b0",
   "metadata": {},
   "source": [
    "### Document\n",
    "\n",
    "This class represents a document. It encapsulates information about a document, its sentences, and any associated clusters. It provides methods for accessing and manipulating this information.\n",
    "\n",
    "Let's go through each part:\n",
    "\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the Document class.\n",
    "- Takes a JSON object (`js`) as input.\n",
    "- Extracts the document key (`_doc_key`) from the JSON object.\n",
    "- Uses the `fields_to_batches` function to extract specific fields from the JSON and create a list of entries.\n",
    "- Computes sentence lengths and starts to facilitate sentence indexing.\n",
    "- Creates a list of Sentence objects based on the entries.\n",
    "- If \"`clusters`\" or \"`predicted_clusters`\" are present in the JSON, creates lists of Cluster objects for clusters and predicted clusters.\n",
    "\n",
    "#### `__repr__` method:\n",
    "\n",
    "- Returns a string representation of the document, including sentence indices and their corresponding text.\n",
    "\n",
    "#### `__getitem__` method:\n",
    "\n",
    "- Enables indexing of the document. Given an index ix, it returns the corresponding `Sentence` object.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "- Returns the number of sentences in the document.\n",
    "\n",
    "#### `print_plaintext method`:\n",
    "\n",
    "- Prints the plaintext representation of the document, sentence by sentence.\n",
    "\n",
    "#### `find_cluster` method:\n",
    "\n",
    "- Searches through reference clusters (either predicted or actual) to find the one containing a specified entity.\n",
    "- Returns the found cluster or None if no match is found.\n",
    "\n",
    "#### `n_tokens property`:\n",
    "\n",
    "- Returns the total number of tokens in the document by summing the number of tokens in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd3ebedd-f439-4d22-a812-560ca07efe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, js):\n",
    "        self._doc_key = js[\"doc_key\"]\n",
    "        entries = fields_to_batches(js, [\"doc_key\", \"clusters\", \"predicted_clusters\", \"section_starts\"])\n",
    "        sentence_lengths = [len(entry[\"sentences\"]) for entry in entries]\n",
    "        sentence_starts = np.cumsum(sentence_lengths)\n",
    "        sentence_starts = np.roll(sentence_starts, 1)\n",
    "        sentence_starts[0] = 0\n",
    "        self.sentence_starts = sentence_starts\n",
    "        self.sentences = [Sentence(entry, sentence_start, sentence_ix)\n",
    "                          for sentence_ix, (entry, sentence_start)\n",
    "                          in enumerate(zip(entries, sentence_starts))]\n",
    "        if \"clusters\" in js:\n",
    "            self.clusters = [Cluster(entry, i, self)\n",
    "                             for i, entry in enumerate(js[\"clusters\"])]\n",
    "        if \"predicted_clusters\" in js:\n",
    "            self.predicted_clusters = [Cluster(entry, i, self)\n",
    "                                       for i, entry in enumerate(js[\"predicted_clusters\"])]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([str(i) + \": \" + \" \".join(sent.text) for i, sent in enumerate(self.sentences)])\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.sentences[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def print_plaintext(self):\n",
    "        for sent in self:\n",
    "            print(\" \".join(sent.text))\n",
    "\n",
    "\n",
    "    def find_cluster(self, entity, predicted=True):\n",
    "        \"\"\"\n",
    "        Search through erence clusters and return the one containing the query entity, if it's\n",
    "        part of a cluster. If we don't find a match, return None.\n",
    "        \"\"\"\n",
    "        clusters = self.predicted_clusters if predicted else self.clusters\n",
    "        for clust in clusters:\n",
    "            for entry in clust:\n",
    "                if entry.span == entity.span:\n",
    "                    return clust\n",
    "\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def n_tokens(self):\n",
    "        return sum([len(sent) for sent in self.sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e81cad-9a62-40fb-b427-6958a22f4759",
   "metadata": {},
   "source": [
    "### Cluster\n",
    "\n",
    "The `Cluster` class represents a cluster of entities within a document. It is used to group together entities that belong to the same cluster, providing information about the members of the cluster.\n",
    "This class is designed to encapsulate information about a cluster of entities within a document. It facilitates the organization and representation of entities belonging to the same cluster.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `cluster`: A list of entries representing the entities in the cluster.\n",
    "  - `cluster_id`: An identifier for the cluster.\n",
    "  - `document`: The document object to which the cluster belongs.\n",
    "- Attributes\n",
    "  - `members`: A list of ClusterMember instances, each representing an entity in the cluster.\n",
    "  - `cluster_id`: The identifier for the cluster.\n",
    "  \n",
    "#### Initialization Details\n",
    "- The `__init__` method initializes the cluster by extracting information about each entity in the cluster.\n",
    "- For each entry in the cluster, it determines the corresponding sentence and span in the document.\n",
    "- It creates `ClusterMember` instances for each entity and appends them to the members list.\n",
    "\n",
    "#### Representation\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the cluster, including the cluster identifier and a representation of its members.\n",
    "Accessing Members\n",
    "\n",
    "`__getitem__` Method:\n",
    "Allows accessing individual members of the cluster using indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bf27b5db-6ece-4a9e-9e13-24e60c57ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self, cluster, cluster_id, document):\n",
    "        members = []\n",
    "        for entry in cluster:\n",
    "            sentence_ix = get_sentence_of_span(entry, document.sentence_starts, document.n_tokens)\n",
    "            sentence = document[sentence_ix]\n",
    "            span = Span(entry[0], entry[1], sentence.text, sentence.sentence_start)\n",
    "            ners = [x for x in sentence.ner if x.span == span]\n",
    "            assert len(ners) <= 1\n",
    "            ner = ners[0] if len(ners) == 1 else None\n",
    "            to_append = ClusterMember(span, ner, sentence, cluster_id)\n",
    "            members.append(to_append)\n",
    "\n",
    "        self.members = members\n",
    "        self.cluster_id = cluster_id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.cluster_id}: \" + self.members.__repr__()\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.members[ix]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784f412-5c4f-486c-bcd8-1b3294e894af",
   "metadata": {},
   "source": [
    "### ClusterMember\n",
    "\n",
    "Represents an individual entity within a cluster. It provides information about the entity's span, associated named entity recognition (NER) information, the sentence it belongs to, and the identifier of the cluster to which it is assigned. The class serves as a container for information about an individual entity within a cluster. It encapsulates details such as the span, NER information, sentence context, and the cluster to which the entity is assigned.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `span`: A Span instance representing the span of the entity in the document.\n",
    "  - `ner`: A NER instance representing the NER information for the entity.\n",
    "  - `sentence`: A Sentence instance representing the sentence containing the entity.\n",
    "  - `cluster_id`: The identifier of the cluster to which the entity belongs.\n",
    "- Attributes\n",
    "  - `span`: A Span instance representing the span of the entity.\n",
    "  - `ner`: A NER instance representing the NER information for the entity.\n",
    "  - `sentence`: A Sentence instance representing the sentence containing the entity.\n",
    "  - `cluster_id`: The identifier of the cluster to which the entity belongs.\n",
    "  \n",
    "#### Initialization Details\n",
    "\n",
    "The `__init__` method initializes a `ClusterMember` by assigning values to its attributes based on the provided parameters.\n",
    "Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the `ClusterMember`, including the sentence index and a representation of its span.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97932254-c9ae-4c58-82f4-200ea937605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterMember:\n",
    "    def __init__(self, span, ner, sentence, cluster_id):\n",
    "        self.span = span\n",
    "        self.ner = ner\n",
    "        self.sentence = sentence\n",
    "        self.cluster_id = cluster_id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{self.sentence.sentence_ix}> \" + self.span.__repr__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8bb7fc-7a06-4058-9b64-0c87a0313500",
   "metadata": {},
   "source": [
    "### Sentence\n",
    "\n",
    "This class represents a sentence. It encapsulates information about a sentence, including its text and associated entities (NER, relations, events). It provides methods for accessing and manipulating this information.\n",
    "\n",
    "Let's go through each method:\n",
    "\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the `Sentence` class.\n",
    "- Takes an `entry`, `sentence_start` (index of the sentence start in the document), and `sentence_ix` (sentence index) as input.\n",
    "- Stores information about the sentence's start position, text, and index.\n",
    "- Parses gold entities (NER, relations, events) and predicted entities (NER, relations, events).\n",
    "- Stores top spans if available.\n",
    "\n",
    "#### `__repr__` method:\n",
    "\n",
    "- Returns a string representation of the sentence, including the text and token indices.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "-Returns the number of tokens in the sentence.\n",
    "\n",
    "#### `get_flavor` method:\n",
    "\n",
    "- Given an argument (presumably an entity), retrieves its flavor from the gold NER annotations.\n",
    "- If multiple NER annotations are found for the same span, prints a message (debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3030363c-9fab-41ec-a724-e5a7b404d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, entry, sentence_start, sentence_ix):\n",
    "        self.sentence_start = sentence_start\n",
    "        self.text = entry[\"sentences\"]\n",
    "        self.sentence_ix = sentence_ix\n",
    "        # Gold\n",
    "        if \"ner_flavor\" in entry:\n",
    "            self.ner = [NER(this_ner, self.text, sentence_start, flavor=this_flavor)\n",
    "                        for this_ner, this_flavor in zip(entry[\"ner\"], entry[\"ner_flavor\"])]\n",
    "        elif \"ner\" in entry:\n",
    "            self.ner = [NER(this_ner, self.text, sentence_start)\n",
    "                        for this_ner in entry[\"ner\"]]\n",
    "        if \"relations\" in entry:\n",
    "            self.relations = [Relation(this_relation, self.text, sentence_start) for\n",
    "                              this_relation in entry[\"relations\"]]\n",
    "        if \"events\" in entry:\n",
    "            self.events = Events(entry[\"events\"], self.text, sentence_start)\n",
    "\n",
    "        # Predicted\n",
    "        if \"predicted_ner\" in entry:\n",
    "            self.predicted_ner = [NER(this_ner, self.text, sentence_start, flavor=None) for\n",
    "                                  this_ner in entry[\"predicted_ner\"]]\n",
    "        if \"predicted_relations\" in entry:\n",
    "            self.predicted_relations = [Relation(this_relation, self.text, sentence_start) for\n",
    "                                        this_relation in entry[\"predicted_relations\"]]\n",
    "        if \"predicted_events\" in entry:\n",
    "            self.predicted_events = Events(entry[\"predicted_events\"], self.text, sentence_start)\n",
    "\n",
    "        # Top spans\n",
    "        if \"top_spans\" in entry:\n",
    "            self.top_spans = [NER(this_ner, self.text, sentence_start, flavor=None) for\n",
    "                                this_ner in entry[\"top_spans\"]]\n",
    "\n",
    "    def __repr__(self):\n",
    "        the_text = \" \".join(self.text)\n",
    "        the_lengths = np.array([len(x) for x in self.text])\n",
    "        tok_ixs = \"\"\n",
    "        for i, offset in enumerate(the_lengths):\n",
    "            true_offset = offset if i < 10 else offset - 1\n",
    "            tok_ixs += str(i)\n",
    "            tok_ixs += \" \" * true_offset\n",
    "\n",
    "        return the_text + \"\\n\" + tok_ixs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def get_flavor(self, argument):\n",
    "        the_ner = [x for x in self.ner if x.span == argument.span]\n",
    "        if len(the_ner) > 1:\n",
    "            print(\"Weird\")\n",
    "        if the_ner:\n",
    "            the_flavor = the_ner[0].flavor\n",
    "        else:\n",
    "            the_flavor = None\n",
    "        return the_flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a8171-da41-4415-8477-628cc48c8941",
   "metadata": {},
   "source": [
    "### NER\n",
    "\n",
    "The NER class represents a Named Entity Recognition annotation within a sentence. It encapsulates information about a named entity, providing methods for representation and equality checks. The `Span` (we'll get to it next) class is used to represent the span of the named entity within the context of the sentence.\n",
    "\n",
    "Here are some details about it:\n",
    "#### Initialization\n",
    "\n",
    "- Parameters:\n",
    "  - `ner`: A list containing information about the NER span, including start index, end index, and label.\n",
    "  - `text`: The text content of the sentence.\n",
    "  - `sentence_start`: The index of the sentence start in the document.\n",
    "  - `flavor`: An optional parameter representing the flavor or type of the named entity.\n",
    "  \n",
    "- Attributes:\n",
    "  - `span`: An instance of the Span class representing the span of the NER annotation.\n",
    "  - `label`: The label assigned to the NER entity.\n",
    "  - `flavor`: The flavor or type of the named entity.\n",
    "  \n",
    "- Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the NER annotation, including the span and label.\n",
    "Equality Check\n",
    "\n",
    "`__eq__` Method:\n",
    "Checks if two NER instances are equal by comparing their span, label, and flavor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d638650-dbb5-4289-99b5-52ff47bff05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER:\n",
    "    def __init__(self, ner, text, sentence_start, flavor=None):\n",
    "        self.span = Span(ner[0], ner[1], text, sentence_start)\n",
    "        self.label = ner[2]\n",
    "        self.flavor = flavor\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.span.__repr__() + \": \" + self.label\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.span == other.span and\n",
    "                self.label == other.label and\n",
    "                self.flavor == other.flavor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3757870-6e1c-4a41-9f6e-84ce7bcb6aff",
   "metadata": {},
   "source": [
    "### Span\n",
    "\n",
    "The `Span` class represents a span of text within a document. It encapsulate information about a text span, providing methods for representation, equality checks, and hashing. It ensures the proper handling of spans within the document and sentence contexts.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `start`: The starting index of the span in the entire document.\n",
    "  - `end`: The ending index of the span in the entire document.\n",
    "  - `text`: The text content of the entire document.\n",
    "  - `sentence_start`: The index of the sentence start in the document.\n",
    "  \n",
    "- Attributes\n",
    "  - `start_doc`, `end_doc`: The start and end indices of the span in the entire document.\n",
    "  - `span_doc`: A tuple representing the span in the entire document.\n",
    "  - `start_sent`, `end_sent`: The start and end indices of the span within the sentence.\n",
    "  - `span_sent`: A tuple representing the span within the sentence.\n",
    "  - `text`: The actual text content of the span.\n",
    "  \n",
    "#### Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the span, including start and end indices and the actual text content.\n",
    "Equality Check\n",
    "\n",
    "`__eq__` Method:\n",
    "Checks if two Span instances are equal by comparing their spans in both the document and the sentence, along with the text content.\n",
    "Hashing\n",
    "\n",
    "`__hash__` Method:\n",
    "Computes a hash value for the Span instance based on its document and sentence spans, as well as the text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bbea2e72-2d85-44e1-9de5-fa9f7d4d5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Span:\n",
    "    def __init__(self, start, end, text, sentence_start):\n",
    "        self.start_doc = start\n",
    "        self.end_doc = end\n",
    "        self.span_doc = (self.start_doc, self.end_doc)\n",
    "        self.start_sent = start - sentence_start\n",
    "        self.end_sent = end - sentence_start\n",
    "        self.span_sent = (self.start_sent, self.end_sent)\n",
    "        self.text = text[self.start_sent:self.end_sent + 1]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str((self.start_sent, self.end_sent, self.text))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.span_doc == other.span_doc and\n",
    "                self.span_sent == other.span_sent and\n",
    "                self.text == other.text)\n",
    "\n",
    "    def __hash__(self):\n",
    "        tup = self.span_doc + self.span_sent + (\" \".join(self.text),)\n",
    "        return hash(tup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6135ff-3aab-4f09-8292-7a4091f8466c",
   "metadata": {},
   "source": [
    "### Relation\n",
    "\n",
    "The Relation class is designed to represent a relation between two spans within a text. It encapsulates information about the spans, such as their start and end positions, the text they cover, and the label assigned to the relation. Here's a breakdown of the class:\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "- Parameters:\n",
    "\n",
    "  - `relation`: A tuple representing the start and end positions of the two spans and the label of the relation.\n",
    "  - `text`: The text containing the spans.\n",
    "  - `sentence_start`: The starting position of the sentence in the text.\n",
    "  \n",
    "- Attributes\n",
    "\n",
    "  - `pair`: A tuple containing two Span objects (span1 and span2) representing the spans of the relation.\n",
    "  - `label`: The label of the relation.\n",
    "  \n",
    "#### Representation\n",
    "`__repr__` Method: Returns a string representation of the Relation object, including the string representations of the two spans, the relation between them (\", \"), and the label.\n",
    "\n",
    "`__eq__` Method: Checks if two Relation objects are equal by comparing their span pairs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c87a147-2a87-4b2b-a7de-d0f14b5b84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relation:\n",
    "    def __init__(self, relation, text, sentence_start):\n",
    "        start1, end1 = relation[0], relation[1]\n",
    "        start2, end2 = relation[2], relation[3]\n",
    "        label = relation[4]\n",
    "        span1 = Span(start1, end1, text, sentence_start)\n",
    "        span2 = Span(start2, end2, text, sentence_start)\n",
    "        self.pair = (span1, span2)\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.pair[0].__repr__() + \", \" + self.pair[1].__repr__() + \": \" + self.label\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.pair == other.pair) and (self.label == other.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74418c55-1311-401e-ab9a-5fc7e700b0d5",
   "metadata": {},
   "source": [
    "### InputFeatures\n",
    "\n",
    "This class represents a single set of features for the relation model. It encapsulates the necessary information required for processing a single example during training or inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ecb42b4-7cfb-4739-b491-cd2f16529d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id, sub_idx, obj_idx):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.sub_idx = sub_idx\n",
    "        self.obj_idx = obj_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898aefe7-a29f-46dc-bf24-b5c5b5ffd80c",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "The authors have aslo implemented some utility functions. Let's go through them and understand what they do.\n",
    "\n",
    "### add_marker_tokens\n",
    "This function, as discussed by the authors, extends the tokenizer's vocabulary with special marker tokens.\n",
    "\n",
    "Therfore, providing additional information about the structure and types of entities in the input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c71fcf9-94fa-4453-b766-0052e7fc38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_marker_tokens(tokenizer, ner_labels):\n",
    "    new_tokens = ['<SUBJ_START>', '<SUBJ_END>', '<OBJ_START>', '<OBJ_END>']\n",
    "    for label in ner_labels:\n",
    "        new_tokens.append('<SUBJ_START=%s>'%label)\n",
    "        new_tokens.append('<SUBJ_END=%s>'%label)\n",
    "        new_tokens.append('<OBJ_START=%s>'%label)\n",
    "        new_tokens.append('<OBJ_END=%s>'%label)\n",
    "    for label in ner_labels:\n",
    "        new_tokens.append('<SUBJ=%s>'%label)\n",
    "        new_tokens.append('<OBJ=%s>'%label)\n",
    "    tokenizer.add_tokens(new_tokens)\n",
    "    logger.info('# vocab after adding markers: %d'%len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9af336-8c48-4545-a914-57f4e220fb36",
   "metadata": {},
   "source": [
    "### convert_examples_to_features\n",
    "\n",
    "The convert_examples_to_features function is responsible for converting the list of input examples into a list of InputFeatures objects, which can be used as input to the relation classification. It tokenizes the input examples, adds special markers for subject and object entities, handles token length constraints, and prepares the data for model input.\n",
    "\n",
    "**Let's break down the key components of this function:**\n",
    "\n",
    "#### Input Parameters:\n",
    "- `examples`: A list of input examples, where each example is a dictionary containing information about tokens, subject and object entities, and the relation.\n",
    "- `label2id`: A dictionary mapping relation labels to their corresponding integer IDs.\n",
    "- `max_seq_length`: The maximum sequence length allowed for the input tokens.\n",
    "- `tokenizer`: The tokenizer used to tokenize input sequences.\n",
    "- `special_tokens`: A dictionary used to keep track of special tokens introduced during processing.\n",
    "- `unused_tokens`: A boolean indicating whether tokens should be used as special tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0cdae56d-073e-4ca4-ba7f-4f71ff447acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=True):\n",
    "    \"\"\"\n",
    "    Loads a data file into a list of `InputBatch`s.\n",
    "    unused_tokens: whether use [unused1] [unused2] as special tokens\n",
    "    \"\"\"\n",
    "\n",
    "    def get_special_token(w):\n",
    "        if w not in special_tokens:\n",
    "            if unused_tokens:\n",
    "                special_tokens[w] = \"[unused%d]\" % (len(special_tokens) + 1)\n",
    "            else:\n",
    "                special_tokens[w] = ('<' + w + '>').lower()\n",
    "        return special_tokens[w]\n",
    "\n",
    "    num_tokens = 0\n",
    "    max_tokens = 0\n",
    "    num_fit_examples = 0\n",
    "    num_shown_examples = 0\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        tokens = [CLS]\n",
    "        SUBJECT_START = get_special_token(\"SUBJ_START\")\n",
    "        SUBJECT_END = get_special_token(\"SUBJ_END\")\n",
    "        OBJECT_START = get_special_token(\"OBJ_START\")\n",
    "        OBJECT_END = get_special_token(\"OBJ_END\")\n",
    "        SUBJECT_NER = get_special_token(\"SUBJ=%s\" % example['subj_type'])\n",
    "        OBJECT_NER = get_special_token(\"OBJ=%s\" % example['obj_type'])\n",
    "\n",
    "        SUBJECT_START_NER = get_special_token(\"SUBJ_START=%s\"%example['subj_type'])\n",
    "        SUBJECT_END_NER = get_special_token(\"SUBJ_END=%s\"%example['subj_type'])\n",
    "        OBJECT_START_NER = get_special_token(\"OBJ_START=%s\"%example['obj_type'])\n",
    "        OBJECT_END_NER = get_special_token(\"OBJ_END=%s\"%example['obj_type'])\n",
    "\n",
    "        for i, token in enumerate(example['token']):\n",
    "            if i == example['subj_start']:\n",
    "                sub_idx = len(tokens)\n",
    "                tokens.append(SUBJECT_START_NER)\n",
    "            if i == example['obj_start']:\n",
    "                obj_idx = len(tokens)\n",
    "                tokens.append(OBJECT_START_NER)\n",
    "            for sub_token in tokenizer.tokenize(token):\n",
    "                tokens.append(sub_token)\n",
    "            if i == example['subj_end']:\n",
    "                tokens.append(SUBJECT_END_NER)\n",
    "            if i == example['obj_end']:\n",
    "                tokens.append(OBJECT_END_NER)\n",
    "        tokens.append(SEP)\n",
    "\n",
    "        num_tokens += len(tokens)\n",
    "        max_tokens = max(max_tokens, len(tokens))\n",
    "\n",
    "        if len(tokens) > max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "            if sub_idx >= max_seq_length:\n",
    "                sub_idx = 0\n",
    "            if obj_idx >= max_seq_length:\n",
    "                obj_idx = 0\n",
    "        else:\n",
    "            num_fit_examples += 1\n",
    "\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        label_id = label2id[example['relation']]\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        if num_shown_examples < 20:\n",
    "            if (ex_index < 5) or (label_id > 0):\n",
    "                num_shown_examples += 1\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"guid: %s\" % (example['id']))\n",
    "                logger.info(\"tokens: %s\" % \" \".join(\n",
    "                        [str(x) for x in tokens]))\n",
    "                logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "                logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "                logger.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "                logger.info(\"label: %s (id = %d)\" % (example['relation'], label_id))\n",
    "                logger.info(\"sub_idx, obj_idx: %d, %d\" % (sub_idx, obj_idx))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id,\n",
    "                              sub_idx=sub_idx,\n",
    "                              obj_idx=obj_idx))\n",
    "    logger.info(\"Average #tokens: %.2f\" % (num_tokens * 1.0 / len(examples)))\n",
    "    logger.info(\"Max #tokens: %d\"%max_tokens)\n",
    "    logger.info(\"%d (%.2f %%) examples can fit max_seq_length = %d\" % (num_fit_examples,\n",
    "                num_fit_examples * 100.0 / len(examples), max_seq_length))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d47f0-8e66-434f-b4df-7e4819bc6f2c",
   "metadata": {},
   "source": [
    "### setseed\n",
    "The setseed function sets the random seed for various random number generators in the environment, specifically for the `random` module, `numpy` library, and the `PyTorch` library.\n",
    "\n",
    "Setting a random seed ensures reproducibility in the generation of random numbers, which is crucial for obtaining consistent results when running experiments or training machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3c0c604f-380e-4f41-a5b0-62b59ba851b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setseed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a1ca7-51f1-470f-8eba-488ece0fbe59",
   "metadata": {},
   "source": [
    "### simple_accuracy\n",
    "This function calculates the accuracy of a model's predictions by comparing the predicted labels (`preds`) with the actual ground truth labels (`labels`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8f309e0c-02b8-47ec-a482-62cb017c9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e76ab2-b1de-47d8-a63c-040e03d30d3f",
   "metadata": {},
   "source": [
    "### compute_f1\n",
    "\n",
    "This function is used to comute the F1 score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2e72b43a-4325-4eb3-90ce-091701eb3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(preds, labels, e2e_ngold):\n",
    "    n_gold = n_pred = n_correct = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        if pred != 0:\n",
    "            n_pred += 1\n",
    "        if label != 0:\n",
    "            n_gold += 1\n",
    "        if (pred != 0) and (label != 0) and (pred == label):\n",
    "            n_correct += 1\n",
    "    if n_correct == 0:\n",
    "        return {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
    "    else:\n",
    "        prec = n_correct * 1.0 / n_pred\n",
    "        recall = n_correct * 1.0 / n_gold\n",
    "        if prec + recall > 0:\n",
    "            f1 = 2.0 * prec * recall / (prec + recall)\n",
    "        else:\n",
    "            f1 = 0.0\n",
    "\n",
    "        if e2e_ngold is not None:\n",
    "            e2e_recall = n_correct * 1.0 / e2e_ngold\n",
    "            e2e_f1 = 2.0 * prec * e2e_recall / (prec + e2e_recall)\n",
    "        else:\n",
    "            e2e_recall = e2e_f1 = 0.0\n",
    "        return {'precision': prec, 'recall': e2e_recall, 'f1': e2e_f1, 'task_recall': recall, 'task_f1': f1, \n",
    "        'n_correct': n_correct, 'n_pred': n_pred, 'n_gold': e2e_ngold, 'task_ngold': n_gold}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a5c8c2-e94c-4402-b2bc-17cc9d21d5e8",
   "metadata": {},
   "source": [
    "### evaluate\n",
    "\n",
    "Evaluates a trained model on an evaluation dataset. It computes various evaluation metrics, including loss, F1 score, accuracy, and additional metrics provided by the compute_f1 function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1953e6e9-48cb-49e1-8494-77db5028f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, eval_dataloader, eval_label_ids, num_labels, e2e_ngold=None, verbose=True):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    preds = []\n",
    "    for input_ids, input_mask, segment_ids, label_ids, sub_idx, obj_idx in eval_dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        sub_idx = sub_idx.to(device)\n",
    "        obj_idx = obj_idx.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, segment_ids, input_mask, labels=None, sub_idx=sub_idx, obj_idx=obj_idx)\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if len(preds) == 0:\n",
    "            preds.append(logits.detach().cpu().numpy())\n",
    "        else:\n",
    "            preds[0] = np.append(\n",
    "                preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    logits = preds[0]\n",
    "    preds = np.argmax(preds[0], axis=1)\n",
    "    result = compute_f1(preds, eval_label_ids.numpy(), e2e_ngold=e2e_ngold)\n",
    "    result['accuracy'] = simple_accuracy(preds, eval_label_ids.numpy())\n",
    "    result['eval_loss'] = eval_loss\n",
    "    if verbose:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "    return preds, result, logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d65242-79df-4804-b930-960c0540aa5b",
   "metadata": {},
   "source": [
    "### print_pred_json\n",
    "\n",
    "This function is used for formatting and printing the predicted relations based on the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "39af037c-b43b-4006-aa64-29d4e0059140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred_json(eval_data, eval_examples, preds, id2label, output_file):\n",
    "    rels = dict()\n",
    "    for ex, pred in zip(eval_examples, preds):\n",
    "        doc_sent, sub, obj = decode_sample_id(ex['id'])\n",
    "        if doc_sent not in rels:\n",
    "            rels[doc_sent] = []\n",
    "        if pred != 0:\n",
    "            rels[doc_sent].append([sub[0], sub[1], obj[0], obj[1], id2label[pred]])\n",
    "\n",
    "    js = eval_data.js\n",
    "    for doc in js:\n",
    "        doc['predicted_relations'] = []\n",
    "        for sid in range(len(doc['sentences'])):\n",
    "            k = '%s@%d'%(doc['doc_key'], sid)\n",
    "            doc['predicted_relations'].append(rels.get(k, []))\n",
    "    \n",
    "    logger.info('Output predictions to %s..'%(output_file))\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('\\n'.join(json.dumps(doc) for doc in js))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb50b26-5267-4dc8-8dc0-1eb3bc19693a",
   "metadata": {},
   "source": [
    "### save_trained_model\n",
    "\n",
    "The save_trained_model function is responsible for saving the trained model, its configuration, and the associated tokenizer to the specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bba02b22-fe74-438e-86f1-5f9fa3c02f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(output_dir, model, tokenizer):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    logger.info('Saving model to %s'%output_dir)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "    output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    model_to_save.config.to_json_file(output_config_file)\n",
    "    tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010091f-2cdb-4b28-8f75-5eba00986786",
   "metadata": {},
   "source": [
    "### generate_relation_data\n",
    "The generate_relation_data function is designed to prepare data for the training or evaluation of the relation model. It takes an entity dataset (`entity_data`), generates samples for relation extraction, and returns the dataset, a list of samples, and the total number of relations in the dataset. Let's break down the key components of this function:\n",
    "\n",
    "#### Input Parameters:\n",
    "- `entity_data`: The entity dataset from which relation data will be generated.\n",
    "- `use_gold`: A boolean parameter indicating whether to use gold (true) or predicted (false) named entities and relations. Default is False.\n",
    "- `context_window`: An integer representing the size of the context window to consider around each sentence. Default is 0.\n",
    "\n",
    "This function processes the entity dataset, extracting named entities and relations. It then generates samples for relation extraction, considering optional context windows. The generated samples include information about document ID, sentence ID, relation labels, entity spans, and tokenized text. The function returns the processed dataset, the list of generated samples, and the total number of relations in the dataset. The generated samples can be used for training or evaluating a relation extraction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88c5f983-c388-42e4-97b7-0504ef40a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_relation_data(entity_data, use_gold=False, context_window=0):\n",
    "    \"\"\"\n",
    "    Prepare data for the relation model\n",
    "    If training: set use_gold = True\n",
    "    \"\"\"\n",
    "    logger.info('Generate relation data from %s'%(entity_data))\n",
    "    data = Dataset(entity_data)\n",
    "\n",
    "    nner, nrel = 0, 0\n",
    "    max_sentsample = 0\n",
    "    samples = []\n",
    "    for doc in data:\n",
    "        for i, sent in enumerate(doc):\n",
    "            sent_samples = []\n",
    "\n",
    "            nner += len(sent.ner)\n",
    "            nrel += len(sent.relations)\n",
    "            if use_gold:\n",
    "                sent_ner = sent.ner\n",
    "            else:\n",
    "                sent_ner = sent.predicted_ner\n",
    "            \n",
    "            gold_ner = {}\n",
    "            for ner in sent.ner:\n",
    "                gold_ner[ner.span] = ner.label\n",
    "            \n",
    "            gold_rel = {}\n",
    "            for rel in sent.relations:\n",
    "                gold_rel[rel.pair] = rel.label\n",
    "            \n",
    "            sent_start = 0\n",
    "            sent_end = len(sent.text)\n",
    "            tokens = sent.text\n",
    "\n",
    "            if context_window > 0:\n",
    "                add_left = (context_window-len(sent.text)) // 2\n",
    "                add_right = (context_window-len(sent.text)) - add_left\n",
    "\n",
    "                j = i - 1\n",
    "                while j >= 0 and add_left > 0:\n",
    "                    context_to_add = doc[j].text[-add_left:]\n",
    "                    tokens = context_to_add + tokens\n",
    "                    add_left -= len(context_to_add)\n",
    "                    sent_start += len(context_to_add)\n",
    "                    sent_end += len(context_to_add)\n",
    "                    j -= 1\n",
    "\n",
    "                j = i + 1\n",
    "                while j < len(doc) and add_right > 0:\n",
    "                    context_to_add = doc[j].text[:add_right]\n",
    "                    tokens = tokens + context_to_add\n",
    "                    add_right -= len(context_to_add)\n",
    "                    j += 1\n",
    "            \n",
    "            for x in range(len(sent_ner)):\n",
    "                for y in range(len(sent_ner)):\n",
    "                    if x == y:\n",
    "                        continue\n",
    "                    sub = sent_ner[x]\n",
    "                    obj = sent_ner[y]\n",
    "                    label = gold_rel.get((sub.span, obj.span), 'no_relation')\n",
    "                    sample = {}\n",
    "                    sample['docid'] = doc._doc_key\n",
    "                    sample['id'] = '%s@%d::(%d,%d)-(%d,%d)'%(doc._doc_key, sent.sentence_ix, sub.span.start_doc, sub.span.end_doc, obj.span.start_doc, obj.span.end_doc)\n",
    "                    sample['relation'] = label\n",
    "                    sample['subj_start'] = sub.span.start_sent + sent_start\n",
    "                    sample['subj_end'] = sub.span.end_sent + sent_start\n",
    "                    sample['subj_type'] = sub.label\n",
    "                    sample['obj_start'] = obj.span.start_sent + sent_start\n",
    "                    sample['obj_end'] = obj.span.end_sent + sent_start\n",
    "                    sample['obj_type'] = obj.label\n",
    "                    sample['token'] = tokens\n",
    "                    sample['sent_start'] = sent_start\n",
    "                    sample['sent_end'] = sent_end\n",
    "\n",
    "                    sent_samples.append(sample)\n",
    "\n",
    "            max_sentsample = max(max_sentsample, len(sent_samples))\n",
    "            samples += sent_samples\n",
    "    \n",
    "    tot = len(samples)\n",
    "    logger.info('#samples: %d, max #sent.samples: %d'%(tot, max_sentsample))\n",
    "\n",
    "    return data, samples, nrel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5149aaa-7830-44bb-a386-386340518e5e",
   "metadata": {},
   "source": [
    "### decode_sample_id\n",
    "\n",
    "Used to decode a sample identified by its ID into: document and sentence information (`doc_sent`), subject coordinates (`sub`), and object coordinates (`obj`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "98235e9b-c1d1-4dca-92b3-e146112e69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sample_id(sample_id):\n",
    "    doc_sent = sample_id.split('::')[0]\n",
    "    pair = sample_id.split('::')[1]\n",
    "    pair = pair.split('-')\n",
    "    sub = (int(pair[0][1:-1].split(',')[0]), int(pair[0][1:-1].split(',')[1]))\n",
    "    obj = (int(pair[1][1:-1].split(',')[0]), int(pair[1][1:-1].split(',')[1]))\n",
    "\n",
    "    return doc_sent, sub, obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98984a23-2b18-43ee-82ab-b5ab0df64fef",
   "metadata": {},
   "source": [
    "### get_sentence_of_span\n",
    "\n",
    "determine the index of the sentence to which a given span (represented as a pair of indices) belongs, and returns that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5f0452b4-e30b-4b14-986c-1ba8cc0f4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_of_span(span, sentence_starts, doc_tokens):\n",
    "    \"\"\"\n",
    "    Return the index of the sentence that the span is part of.\n",
    "    \"\"\"\n",
    "    # Inclusive sentence ends\n",
    "    sentence_ends = [x - 1 for x in sentence_starts[1:]] + [doc_tokens - 1]\n",
    "    in_between = [span[0] >= start and span[1] <= end\n",
    "                  for start, end in zip(sentence_starts, sentence_ends)]\n",
    "    assert sum(in_between) == 1\n",
    "    the_sentence = in_between.index(True)\n",
    "    return the_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f3a955b1-2bcb-45d0-96ee-9389635d7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fields_to_batches(d, keys_to_ignore=[]):\n",
    "    keys = [key for key in d.keys() if key not in keys_to_ignore]\n",
    "    lengths = [len(d[k]) for k in keys]\n",
    "    assert len(set(lengths)) == 1\n",
    "    length = lengths[0]\n",
    "    res = [{k: d[k][i] for k in keys} for i in range(length)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad931ef-cf57-47c7-9cfd-0ab3db015747",
   "metadata": {},
   "source": [
    "### Running and evaluationg the model\n",
    "\n",
    "Now that the setup is out of the way. We can actually run the model and evaluate it with a pre-trained BERT-based model on the SciERC dataset.\n",
    "\n",
    "Let's perform the training, evaluating, and predicting of the relation model using the SciBERT model.\n",
    "\n",
    "Configuration Parameters:\n",
    "- model_name: The name the pre-trained SciBERT model.\n",
    "- add_new_tokens: A boolean indicating whether to add new task-specific tokens to the tokenizer.\n",
    "- no_cuda: A boolean indicating whether to use CPU instead of GPU.\n",
    "- do_train, do_eval, eval_test: Boolean flags to control whether to perform training, evaluation, and evaluation on the test set.\n",
    "- do_lower_case: A boolean indicating whether to convert text to lowercase during tokenization.\n",
    "- entity_output_dir: The directory containing output from the entity recognition model.\n",
    "- entity_predictions_dev, entity_predictions_test: The filenames for entity predictions on the development and test sets.\n",
    "- eval_with_gold: A boolean indicating whether to use gold standard entities during evaluation.\n",
    "- context_window: The size of the context window around each sentence.\n",
    "- max_seq_length: The maximum sequence length for tokenized input.\n",
    "- seed: The random seed for reproducibility.\n",
    "- output_dir: The directory to save the trained model and evaluation logs.\n",
    "- negative_label: The label for negative relations.\n",
    "- task: The specific relation extraction task (assumed to be \"scierc\").\n",
    "- train_mode: The training mode, assumed to be \"random_sorted\".\n",
    "- train_batch_size, eval_batch_size: Batch sizes for training and evaluation.\n",
    "- num_train_epochs: The number of training epochs.\n",
    "- train_file: The file containing training data.\n",
    "- eval_per_epoch: The frequency of evaluation per epoch.\n",
    "- learning_rate: The learning rate for training.\n",
    "- prediction_file: The filename for saving predictions.\n",
    "- BertLayerNorm: The LayerNorm class to be used (assumed to be from torch.nn).\n",
    "- CLS, SEP: Special tokens for [CLS] (classification) and [SEP] (separator).\n",
    "- RelationModel: The model class for relation extraction (assumed to be BertForRelation).\n",
    "- device: The computing device (CPU or GPU).\n",
    "- n_gpu: The number of available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8b14b727-39e4-4328-a96f-6a10b50e65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'allenai/scibert_scivocab_uncased'\n",
    "add_new_tokens = False\n",
    "no_cuda = False\n",
    "do_train = False\n",
    "do_eval = True\n",
    "eval_test = True\n",
    "do_lower_case = True\n",
    "entity_output_dir = os.getcwd() + '/scierc_models/ent-scib-ctx0/'\n",
    "entity_predictions_dev = 'ent_pred_dev.json'\n",
    "eval_with_gold = True\n",
    "context_window = 0\n",
    "max_seq_length = 128\n",
    "entity_predictions_test = 'ent_pred_test.json'\n",
    "seed = 0\n",
    "output_dir = os.getcwd() + '/scierc_models/rel_approx-scib-ctx0/'\n",
    "negative_label = 'no_relation'\n",
    "task = 'scierc'\n",
    "train_mode = 'random_sorted'\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 8\n",
    "num_train_epochs = 3.0\n",
    "train_file = None\n",
    "eval_per_epoch = 10\n",
    "learning_rate = None\n",
    "prediction_file = 'predictions.json'\n",
    "BertLayerNorm = torch.nn.LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d198d-b4de-49a8-bc2e-ccdaea283483",
   "metadata": {},
   "source": [
    "#### Special Tokens and Model Initialization:\n",
    "\n",
    "- `CLS` and `SEP` are special tokens used in BERT-like models, where [CLS] denotes the start of a sequence, and [SEP] separates segments or sentences.\n",
    "- `RelationModel` is set to the BertForRelation model, since that's the model we will useCLS = \"[CLS]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "963d6af7-d127-4478-9a90-a1efb83c0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS = \"[CLS]\"\n",
    "SEP = \"[SEP]\"\n",
    "\n",
    "RelationModel = BertForRelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d25e0-90d5-4655-afc6-bbab5ba70fab",
   "metadata": {},
   "source": [
    "#### Device and GPU Configuration:\n",
    "\n",
    "- `device`: It checks if a GPU is available. If available, it uses GPU; otherwise, it falls back to CPU.\n",
    "- `n_gpu`: It counts the number of available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e820beaf-9bfd-407d-933e-4fa2a400272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9fe93-f05f-4b92-b0c1-3bde4ed340b3",
   "metadata": {},
   "source": [
    "#### Data Preparation:\n",
    "\n",
    "Let's prepare the data for the training, development (dev), and test sets using the generate_relation_data function.\n",
    "- `train_dataset`, `eval_dataset`, and `test_dataset` hold the generated datasets.\n",
    "- `train_examples`, `eval_examples`, and `test_examples` contain examples from the respective datasets.\n",
    "- `train_nrel`, `eval_nrel`, and `test_nrel` store the number of relations in the corresponding sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c87d6bac-ffdc-448b-8f58-f03929827dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:29 - INFO - run_relation - Generate relation data from C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0/ent_pred_test.json\n",
      "11/21/2023 15:53:30 - INFO - run_relation - #samples: 5062, max #sent.samples: 156\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "if do_train:\n",
    "    train_dataset, train_examples, train_nrel = generate_relation_data(train_file, use_gold=True, context_window=context_window)\n",
    "# dev set\n",
    "if (do_eval and do_train) or (do_eval and not(eval_test)):\n",
    "    eval_dataset, eval_examples, eval_nrel = generate_relation_data(os.path.join(entity_output_dir, entity_predictions_dev), use_gold=eval_with_gold, context_window=context_window)\n",
    "# test set\n",
    "if eval_test:\n",
    "    test_dataset, test_examples, test_nrel = generate_relation_data(os.path.join(entity_output_dir, entity_predictions_test), use_gold=eval_with_gold, context_window=context_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b9e86-1ab6-401e-884c-015c1b52c4e4",
   "metadata": {},
   "source": [
    "#### Random Seed Setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "146f7485-4459-4c99-8624-ea7dd497e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "setseed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dacfb4-a261-4aa4-a5a5-12c55df05ec1",
   "metadata": {},
   "source": [
    "#### Directory and Logging Setup:\n",
    "\n",
    "- Ensuring that at least one of `do_train` or `do_eval` is set to True.\n",
    "- We also create the output directory if it doesn't exist and set up logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88ccfb8f-e50c-4399-961d-341f7a4229eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_train and not do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if do_train:\n",
    "    logger.addHandler(logging.FileHandler(os.path.join(output_dir, \"train.log\"), 'w'))\n",
    "else:\n",
    "    logger.addHandler(logging.FileHandler(os.path.join(output_dir, \"eval.log\"), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28721e51-b916-46cf-b317-72d3003746de",
   "metadata": {},
   "source": [
    "#### Label List and Mappings:\n",
    "\n",
    "- Loading/creating a list of relation labels (`label_list`) and saving it to a file.\n",
    "- Again, we create the mappings (`label2id` and `id2label`) and calculate the number of labels (`num_labels`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fadd1860-e68a-4518-87bf-06c26b8774c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label_list\n",
    "if os.path.exists(os.path.join(output_dir, 'label_list.json')):\n",
    "    with open(os.path.join(output_dir, 'label_list.json'), 'r') as f:\n",
    "        label_list = json.load(f)\n",
    "else:\n",
    "    label_list = [negative_label] + task_rel_labels[task]\n",
    "    with open(os.path.join(output_dir, 'label_list.json'), 'w') as f:\n",
    "        json.dump(label_list, f)\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051a95a-905e-4c9f-86c5-e71572709c2e",
   "metadata": {},
   "source": [
    "#### Tokenizer and Special Tokens:\n",
    "\n",
    "- It initializes the tokenizer using the specified pre-trained model (`model_name`).\n",
    "- If `add_new_tokens` is set to True, it adds task-specific marker tokens using the `add_marker_tokens` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f898f08f-3d56-4cc2-8092-79c478be88bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "11/21/2023 15:53:36 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/21/2023 15:53:36 - INFO - transformers.tokenization_utils_base - Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/vocab.txt from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\e3debd8fbdf40874753724814ee0520f612b577b26c8755bca485103b47cd3bc.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/added_tokens.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/special_tokens_map.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer_config.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer.json from cache at None\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=do_lower_case)\n",
    "if add_new_tokens:\n",
    "    add_marker_tokens(tokenizer, task_ner_labels[task])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9cbe2-81c3-4020-93a6-a53d166eb015",
   "metadata": {},
   "source": [
    "#### Special Tokens Saving/Loading:\n",
    "\n",
    "It loads or initializes a dictionary for special tokens (`special_tokens`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6554cd01-60d3-4ab8-a9c4-0bee2501761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(output_dir, 'special_tokens.json')):\n",
    "    with open(os.path.join(output_dir, 'special_tokens.json'), 'r') as f:\n",
    "        special_tokens = json.load(f)\n",
    "else:\n",
    "    special_tokens = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc7210-7735-48c8-aca5-81fc2d073e06",
   "metadata": {},
   "source": [
    "#### Evaluation Data Preparation:\n",
    "\n",
    "- It converts evaluation examples (eval_examples) to features using the convert_examples_to_features function.\n",
    "- It logs information about the evaluation dataset, such as the number of examples and the batch size.\n",
    "- It creates PyTorch tensors for input features (all_input_ids, all_input_mask, etc.).\n",
    "- It constructs a PyTorch TensorDataset and a corresponding DataLoader for the evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5dc1cc5d-b61a-4052-b9d7-309d1d9b4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_eval and (do_train or not(eval_test)):\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "    logger.info(\"***** Dev *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    all_sub_idx = torch.tensor([f.sub_idx for f in eval_features], dtype=torch.long)\n",
    "    all_obj_idx = torch.tensor([f.obj_idx for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "    eval_dataloader = DataLoader(eval_data, batch_size=eval_batch_size)\n",
    "    eval_label_ids = all_label_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5dd61b-c99f-4372-96dd-717f43891147",
   "metadata": {},
   "source": [
    "#### Save Special Tokens\n",
    "\n",
    "It saves the `special_tokens` dictionary to a JSON file named 'special_tokens.json' in the output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000703a-a771-4def-92be-c61540ad6e13",
   "metadata": {},
   "source": [
    "with open(os.path.join(output_dir, 'special_tokens.json'), 'w') as f:\n",
    "    json.dump(special_tokens, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659fa904-1fe5-4b16-bafd-0d44625a1092",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "- It logs the `special_tokens` dictionary.\n",
    "- If `eval_test` is True, it uses the test dataset (`test_dataset`, `test_examples`) for evaluation; otherwise, it uses the previously loaded dev dataset.\n",
    "- It converts the evaluation examples to features and constructs a PyTorch TensorDataset and a corresponding DataLoader for the evaluation set.\n",
    "- It loads the pre-trained relation extraction model (RelationModel) from the output directory.\n",
    "- It evaluates the model on the evaluation set and logs the results.\n",
    "- It prints the predictions to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e80d3b70-f753-45a1-b06d-ba7404ddc275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:45 - INFO - run_relation - {'SUBJ_START': '[unused1]', 'SUBJ_END': '[unused2]', 'OBJ_START': '[unused3]', 'OBJ_END': '[unused4]', 'SUBJ=Generic': '[unused5]', 'OBJ=OtherScientificTerm': '[unused6]', 'SUBJ_START=Generic': '[unused7]', 'SUBJ_END=Generic': '[unused8]', 'OBJ_START=OtherScientificTerm': '[unused9]', 'OBJ_END=OtherScientificTerm': '[unused10]', 'OBJ=Material': '[unused11]', 'OBJ_START=Material': '[unused12]', 'OBJ_END=Material': '[unused13]', 'SUBJ=OtherScientificTerm': '[unused14]', 'OBJ=Generic': '[unused15]', 'SUBJ_START=OtherScientificTerm': '[unused16]', 'SUBJ_END=OtherScientificTerm': '[unused17]', 'OBJ_START=Generic': '[unused18]', 'OBJ_END=Generic': '[unused19]', 'SUBJ=Material': '[unused20]', 'SUBJ_START=Material': '[unused21]', 'SUBJ_END=Material': '[unused22]', 'OBJ=Task': '[unused23]', 'OBJ_START=Task': '[unused24]', 'OBJ_END=Task': '[unused25]', 'SUBJ=Task': '[unused26]', 'SUBJ_START=Task': '[unused27]', 'SUBJ_END=Task': '[unused28]', 'OBJ=Method': '[unused29]', 'OBJ_START=Method': '[unused30]', 'OBJ_END=Method': '[unused31]', 'SUBJ=Method': '[unused32]', 'SUBJ_START=Method': '[unused33]', 'SUBJ_END=Method': '[unused34]', 'OBJ=Metric': '[unused35]', 'OBJ_START=Metric': '[unused36]', 'OBJ_END=Metric': '[unused37]', 'SUBJ=Metric': '[unused38]', 'SUBJ_START=Metric': '[unused39]', 'SUBJ_END=Metric': '[unused40]'}\n",
      "11/21/2023 15:53:45 - INFO - run_relation - Writing example 0 of 5062\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(2,3)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of [unused9] proper nouns [unused28] [unused10] in japanese text has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 10 1193 24748 29 11 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 4\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(5,6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in [unused12] japanese text [unused13] has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 13 9155 3267 14 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 8\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(19,20)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in japanese text has been studied as a part of the more general problem of [unused24] morphological analysis [unused25] in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 25 6893 669 26 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 22\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(22,24)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in japanese text has been studied as a part of the more general problem of morphological analysis in [unused24] japanese text processing [unused25] - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 25 9155 3267 2307 26 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 25\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(2,3)-(0,3)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused24] recognition of [unused16] proper nouns [unused17] [unused25] in japanese text has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 25 3512 131 17 1193 24748 18 26 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 4, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(2,3)-(5,6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] recognition of [unused16] proper nouns [unused17] in [unused12] japanese text [unused13] has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 3512 131 17 1193 24748 18 121 13 9155 3267 14 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 3, 8\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(19,20)-(22,24)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] recognition of proper nouns in japanese text has been studied as a part of the more general problem of [unused27] morphological analysis [unused28] in [unused24] japanese text processing [unused25] - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 3512 131 1193 24748 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 28 6893 669 29 121 25 9155 3267 2307 26 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 20, 25\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@1::(43,45)-(34,34)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused18] it [unused19] has also been studied in the framework of [unused27] japanese information extraction [unused28] - lr ##b - - ls ##b - 3 - rs ##b - - rr ##b - in recent years . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 19 256 20 434 469 528 2580 121 111 2641 131 28 9155 776 4220 29 579 8295 30125 579 579 6208 30125 579 239 579 3102 30125 579 579 5058 30125 579 121 2151 1320 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 12, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(56,56)-(59,64)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our [unused7] approach [unused8] to the [unused24] multi - lingu ##al evaluation task - lr ##b - met - rr ##b - [unused25] for japanese text is to consider the given task as a morphological analysis problem in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 8 1139 9 147 111 25 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 26 168 9155 3267 165 147 1129 111 906 2188 188 106 6893 669 1167 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 2, 7\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(59,64)-(66,67)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the [unused27] multi - lingu ##al evaluation task - lr ##b - met - rr ##b - [unused28] for [unused12] japanese text [unused13] is to consider the given task as a morphological analysis problem in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 28 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 29 168 13 9155 3267 14 165 147 1129 111 906 2188 188 106 6893 669 1167 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 5, 23\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(76,78)-(73,73)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the multi - lingu ##al evaluation task - lr ##b - met - rr ##b - for japanese text is to consider the given [unused18] task [unused19] as a [unused27] morphological analysis problem [unused28] in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 168 9155 3267 165 147 1129 111 906 19 2188 20 188 106 28 6893 669 1167 29 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 33, 28\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(80,80)-(76,78)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the multi - lingu ##al evaluation task - lr ##b - met - rr ##b - for japanese text is to consider the given task as a [unused24] morphological analysis problem [unused25] in [unused21] japanese [unused22] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 168 9155 3267 165 147 1129 111 906 2188 188 106 25 6893 669 1167 26 121 22 9155 23 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 37, 31\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(83,84)-(93,103)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our [unused33] morphological analyzer [unused34] has done all the necessary work for the [unused24] recognition and classification of proper names , numerical and temporal expressions [unused25] , i . e . named entity - lr ##b - ne - rr ##b - items in the japanese text . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 34 6893 12951 35 434 2992 355 111 2538 697 168 111 25 3512 137 2998 131 1193 8541 422 4058 137 3930 6370 26 422 259 205 139 205 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 121 111 9155 3267 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 2, 14\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(106,111)-(97,103)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our morphological analyzer has done all the necessary work for the recognition and classification of [unused9] proper names , numerical and temporal expressions [unused10] , i . e . [unused16] named entity - lr ##b - ne - rr ##b - items [unused17] in the japanese text . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 6893 12951 434 2992 355 111 2538 697 168 111 3512 137 2998 131 10 1193 8541 422 4058 137 3930 6370 11 422 259 205 139 205 17 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 18 121 111 9155 3267 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: HYPONYM-OF (id = 6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 30, 16\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(106,111)-(114,115)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i . e . [unused16] named entity - lr ##b - ne - rr ##b - items [unused17] in the [unused12] japanese text [unused13] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 6893 12951 434 2992 355 111 2538 697 168 111 3512 137 2998 131 1193 8541 422 4058 137 3930 6370 422 259 205 139 205 17 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 18 121 111 13 9155 3267 14 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 28, 44\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(125,125)-(127,128)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused33] amorph [unused34] recognizes [unused9] ne items [unused10] in two stages : dictionary lookup and rule application . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 34 15291 35 20269 10 287 3945 11 121 502 4303 862 13050 22474 137 3346 1836 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 5\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(133,134)-(125,125)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused30] amorph [unused31] recognizes ne items in two stages : [unused33] dictionary lookup [unused34] and rule application . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 31 15291 32 20269 287 3945 121 502 4303 862 34 13050 22474 35 137 3346 1836 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 11, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(133,134)-(136,137)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] amorph recognizes ne items in two stages : [unused33] dictionary lookup [unused34] and [unused30] rule application [unused31] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 15291 20269 287 3945 121 502 4303 862 34 13050 22474 35 137 31 3346 1836 32 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: CONJUNCTION (id = 4)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 9, 14\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(136,137)-(125,125)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused30] amorph [unused31] recognizes ne items in two stages : dictionary lookup and [unused33] rule application [unused34] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 31 15291 32 20269 287 3945 121 502 4303 862 13050 22474 137 34 3346 1836 35 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 14, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@6::(146,146)-(141,141)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] first , [unused18] it [unused19] uses several kinds of [unused16] diction ##aries [unused17] to segment and tag japanese character strings . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 705 422 19 256 20 3294 1323 7337 131 17 11618 2881 18 147 3197 137 5374 9155 954 13408 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 10, 3\n",
      "11/21/2023 15:53:54 - INFO - run_relation - Average #tokens: 44.54\n",
      "11/21/2023 15:53:54 - INFO - run_relation - Max #tokens: 131\n",
      "11/21/2023 15:53:54 - INFO - run_relation - 4906 (96.92 %) examples can fit max_seq_length = 128\n",
      "11/21/2023 15:53:54 - INFO - run_relation - {'SUBJ_START': '[unused1]', 'SUBJ_END': '[unused2]', 'OBJ_START': '[unused3]', 'OBJ_END': '[unused4]', 'SUBJ=Generic': '[unused5]', 'OBJ=OtherScientificTerm': '[unused6]', 'SUBJ_START=Generic': '[unused7]', 'SUBJ_END=Generic': '[unused8]', 'OBJ_START=OtherScientificTerm': '[unused9]', 'OBJ_END=OtherScientificTerm': '[unused10]', 'OBJ=Material': '[unused11]', 'OBJ_START=Material': '[unused12]', 'OBJ_END=Material': '[unused13]', 'SUBJ=OtherScientificTerm': '[unused14]', 'OBJ=Generic': '[unused15]', 'SUBJ_START=OtherScientificTerm': '[unused16]', 'SUBJ_END=OtherScientificTerm': '[unused17]', 'OBJ_START=Generic': '[unused18]', 'OBJ_END=Generic': '[unused19]', 'SUBJ=Material': '[unused20]', 'SUBJ_START=Material': '[unused21]', 'SUBJ_END=Material': '[unused22]', 'OBJ=Task': '[unused23]', 'OBJ_START=Task': '[unused24]', 'OBJ_END=Task': '[unused25]', 'SUBJ=Task': '[unused26]', 'SUBJ_START=Task': '[unused27]', 'SUBJ_END=Task': '[unused28]', 'OBJ=Method': '[unused29]', 'OBJ_START=Method': '[unused30]', 'OBJ_END=Method': '[unused31]', 'SUBJ=Method': '[unused32]', 'SUBJ_START=Method': '[unused33]', 'SUBJ_END=Method': '[unused34]', 'OBJ=Metric': '[unused35]', 'OBJ_START=Metric': '[unused36]', 'OBJ_END=Metric': '[unused37]', 'SUBJ=Metric': '[unused38]', 'SUBJ_START=Metric': '[unused39]', 'SUBJ_END=Metric': '[unused40]'}\n",
      "11/21/2023 15:53:54 - INFO - run_relation - ***** Test *****\n",
      "11/21/2023 15:53:54 - INFO - run_relation -   Num examples = 5062\n",
      "11/21/2023 15:53:54 - INFO - run_relation -   Batch size = 8\n",
      "11/21/2023 15:53:54 - INFO - transformers.configuration_utils - loading configuration file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/config.json\n",
      "11/21/2023 15:53:54 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/21/2023 15:53:54 - INFO - transformers.modeling_utils - loading weights file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/pytorch_model.bin\n",
      "11/21/2023 15:53:57 - INFO - transformers.modeling_utils - All model checkpoint weights were used when initializing BertForRelation.\n",
      "\n",
      "11/21/2023 15:53:57 - INFO - transformers.modeling_utils - All the weights of BertForRelation were initialized from the model checkpoint at C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForRelation for predictions without further training.\n",
      "11/21/2023 15:56:58 - INFO - run_relation - ***** Eval results *****\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   accuracy = 0.8557882259976294\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   eval_loss = 0.4450051788046462\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_correct = 651\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_gold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_pred = 1124\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   precision = 0.5791814946619217\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_ngold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation - *** Evaluation Results ***\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   accuracy = 0.8557882259976294\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   eval_loss = 0.4450051788046462\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_correct = 651\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_gold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_pred = 1124\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   precision = 0.5791814946619217\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_ngold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation - Output predictions to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/predictions.json..\n"
     ]
    }
   ],
   "source": [
    "if do_eval:\n",
    "    logger.info(special_tokens)\n",
    "    if eval_test:\n",
    "        eval_dataset = test_dataset\n",
    "        eval_examples = test_examples\n",
    "        eval_features = convert_examples_to_features(\n",
    "            test_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "        eval_nrel = test_nrel\n",
    "        logger.info(special_tokens)\n",
    "        logger.info(\"***** Test *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(test_examples))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "        all_sub_idx = torch.tensor([f.sub_idx for f in eval_features], dtype=torch.long)\n",
    "        all_obj_idx = torch.tensor([f.obj_idx for f in eval_features], dtype=torch.long)\n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "        eval_dataloader = DataLoader(eval_data, batch_size=eval_batch_size)\n",
    "        eval_label_ids = all_label_ids\n",
    "    model = RelationModel.from_pretrained(output_dir, num_rel_labels=num_labels)\n",
    "    model.to(device)\n",
    "    preds, result, logits = evaluate(model, device, eval_dataloader, eval_label_ids, num_labels, e2e_ngold=eval_nrel)\n",
    "\n",
    "    logger.info('*** Evaluation Results ***')\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "\n",
    "    print_pred_json(eval_dataset, eval_examples, preds, id2label, os.path.join(output_dir, prediction_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
