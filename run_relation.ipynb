{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7145ef96-18f7-4c97-ba26-a3d20df5fcda",
   "metadata": {},
   "source": [
    "# Running the relation model\n",
    "In this notebook we will run and evalute the relation model proposed in the research paper [A Frustratingly Easy Approach for Entity and Relation Extraction](https://arxiv.org/pdf/2010.12812.pdf).\n",
    "\n",
    "This is a reproduction based on the instructions left by the authors in their [GitHub repo](https://github.com/princeton-nlp/PURE)\n",
    "\n",
    "**Environment information**\n",
    "\n",
    "- Windows 11\n",
    "- Python 3.6.13\n",
    "- pip 21.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c0e8b-76a1-468e-b48a-9b473be65ca7",
   "metadata": {},
   "source": [
    "## Basic setup\n",
    "Firstly, we setup our notebook by importing needed libraries and modules.\n",
    "\n",
    "And we initialize a logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c9995f-df21-4e6c-bed8-d759200ef493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odaim\\anaconda3\\envs\\PUREReprodcution\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers import AlbertModel, AlbertPreTrainedModel\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.file_utils import PYTORCH_PRETRAINED_BERT_CACHE, WEIGHTS_NAME, CONFIG_NAME\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger('run_relation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51decb14-3791-4e74-affc-f40cf2917b08",
   "metadata": {},
   "source": [
    "## Main classes\n",
    "The authors have implemented their system in an OOP style. Let's go through the defined classes and understand what they do.\n",
    "\n",
    "### BertForRelation\n",
    "This Python class is a custom implementation of a relation classification model based on the BERT (Bidirectional Encoder Representations from Transformers) architecture. Let me break down the key components:\n",
    "This class inherits from BertPreTrainedModel. Therefore, it's building on top of an existing BERT model. This is done to leverage th pre-trained BERT model's weights and then fine-tune it for our specific task.\n",
    "\n",
    "The BertForRelation class is designed for relation classification tasks, where the goal is to predict the relationship between entities in a given text. It leverages the BERT (Bidirectional Encoder Representations from Transformers) architecture and extends the BertPreTrainedModel class, building upon a pre-trained BERT model.\n",
    "\n",
    "The constructor initializes various components of the model:\n",
    "\n",
    "- config: BERT model configuration.\n",
    "- num_rel_labels: Number of distinct relation labels.\n",
    "\n",
    "The setup includes:\n",
    "\n",
    "- bert: The BERT model initialized with the provided configuration.\n",
    "- dropout: A dropout layer with a dropout probability specified in the BERT configuration.\n",
    "- layer_norm: Layer normalization applied to the concatenated output of the subject and object representations.\n",
    "- classifier: A linear layer for classification, mapping the concatenated representation to the output logits.\n",
    "- init_weights(): Initialization of the model's weights.\n",
    "\n",
    "We must note the setup of the model:\n",
    "\n",
    "```python\n",
    "self.classifier = nn.Linear(config.hidden_size * 2, self.num_labels)\n",
    "```\n",
    "\n",
    "The model is a linear layer that takes the concatenated representation of subject and object entities as input and produces logits for each possible relation label.\n",
    "\n",
    "\n",
    "- It's defined using nn.Linear and consists of two layers.\n",
    "- Input dimension (input_dim) is set to the sum of the following:\n",
    "  - config.hidden_size: corresponds to the hidden size of the BERT model. In BERT, each token in the input sequence is associated with a hidden vector of this size.\n",
    "  - * 2: The * 2 indicates that the representations of the subject and object entities are concatenated. So, the input dimension is twice the hidden size. This is likely because the model wants to capture information from both the start and end embeddings of the entities.\n",
    "\n",
    "Output Layer:\n",
    "\n",
    "`self.num_labels` is the number of distinct relation labels that the model is designed to classify. Each output neuron in the linear layer corresponds to a specific relation label.\n",
    "\n",
    "The overall architecture is a simple linear transformation that maps the concatenated representation of subject and object entities to a vector of logits, where each element of the vector corresponds to the model's prediction for a specific relation label. This linear layer is typically followed by a softmax activation during training to convert the logits into probabilities and compute the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3a60c06-d042-4fa9-a2a0-8daba9d62f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForRelation(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_rel_labels):\n",
    "        super(BertForRelation, self).__init__(config)\n",
    "        self.num_labels = num_rel_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.layer_norm = BertLayerNorm(config.hidden_size * 2)\n",
    "        self.classifier = nn.Linear(config.hidden_size * 2, self.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, sub_idx=None, obj_idx=None, input_position=None):\n",
    "        outputs = self.bert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, output_hidden_states=False, output_attentions=False, position_ids=input_position)\n",
    "        sequence_output = outputs[0]\n",
    "        sub_output = torch.cat([a[i].unsqueeze(0) for a, i in zip(sequence_output, sub_idx)])\n",
    "        obj_output = torch.cat([a[i].unsqueeze(0) for a, i in zip(sequence_output, obj_idx)])\n",
    "        rep = torch.cat((sub_output, obj_output), dim=1)\n",
    "        rep = self.layer_norm(rep)\n",
    "        rep = self.dropout(rep)\n",
    "        logits = self.classifier(rep)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba491f0-3343-4ccf-9d62-820f4794881f",
   "metadata": {},
   "source": [
    "### AlbertForRelation\n",
    "\n",
    "There's also the class AlbertForEntity. Which is very similar to the BertForEntity with a key difference in the underlying transformer architecture they use: BertForRelation is based on BERT, while AlbertForRelation is based on ALBERT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33aafec3-d7f0-4a7c-9472-1a574176cfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbertForRelation(AlbertPreTrainedModel):\n",
    "    def __init__(self, config, num_rel_labels):\n",
    "        super(AlbertForRelation, self).__init__(config)\n",
    "        self.num_labels = num_rel_labels\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.layer_norm = BertLayerNorm(config.hidden_size * 2)\n",
    "        self.classifier = nn.Linear(config.hidden_size * 2, self.num_labels)\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None, labels=None, sub_idx=None, obj_idx=None):\n",
    "        outputs = self.albert(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask, output_hidden_states=False, output_attentions=False)\n",
    "        sequence_output = outputs[0]\n",
    "        sub_output = torch.cat([a[i].unsqueeze(0) for a, i in zip(sequence_output, sub_idx)])\n",
    "        obj_output = torch.cat([a[i].unsqueeze(0) for a, i in zip(sequence_output, obj_idx)])\n",
    "        rep = torch.cat((sub_output, obj_output), dim=1)\n",
    "        rep = self.layer_norm(rep)\n",
    "        rep = self.dropout(rep)\n",
    "        logits = self.classifier(rep)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            return loss\n",
    "        else:\n",
    "            return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f081a11b-3e18-4310-bf9c-2cbb163685e1",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Represents a dataset. It's a convenient wrapper for handling datasets, reading data from JSON files, and creating Document objects.\n",
    "\n",
    "Let's break down its components:\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the Dataset class.\n",
    "- Takes three parameters: `json_file`, `pred_file` **(default is `None`)**, and `doc_range` **(default is `None`)**.\n",
    "- Reads data from the specified JSON files (`json_file` and `pred_file`).\n",
    "- If a document range (`doc_range`) is provided, it selects a subset of documents within that range.\n",
    "- Creates a list of Document objects based on the read data.\n",
    "\n",
    "#### `update_from_js` method:\n",
    "\n",
    "- Updates the dataset with new data (`js`).\n",
    "- Re-creates the list of `Document` objects based on the updated data.\n",
    "\n",
    "#### \\`_read method`:\n",
    "\n",
    "- Reads data from JSON files (`json_file` and optionally `pred_file`).\n",
    "If `pred_file` is provided, it merges the data from the gold (`gold_docs`) and predicted (`pred_docs`) files.\n",
    "- Returns the merged list of documents.\n",
    "\n",
    "#### `__getitem__` method:\n",
    "\n",
    "- Enables indexing of the dataset. Given an index `ix`, it returns the corresponding Document object.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "- Returns the length of the dataset, i.e., the number of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73432310-8161-4745-b55a-f93e909e4d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, json_file, pred_file=None, doc_range=None):\n",
    "        self.js = self._read(json_file, pred_file)\n",
    "        if doc_range is not None:\n",
    "            self.js = self.js[doc_range[0]:doc_range[1]]\n",
    "        self.documents = [Document(js) for js in self.js]\n",
    "\n",
    "    def update_from_js(self, js):\n",
    "        self.js = js\n",
    "        self.documents = [Document(js) for js in self.js]\n",
    "\n",
    "    def _read(self, json_file, pred_file=None):\n",
    "        gold_docs = [json.loads(line) for line in open(json_file)]\n",
    "        if pred_file is None:\n",
    "            return gold_docs\n",
    "\n",
    "        pred_docs = [json.loads(line) for line in open(pred_file)]\n",
    "        merged_docs = []\n",
    "        for gold, pred in zip(gold_docs, pred_docs):\n",
    "            assert gold[\"doc_key\"] == pred[\"doc_key\"]\n",
    "            assert gold[\"sentences\"] == pred[\"sentences\"]\n",
    "            merged = copy.deepcopy(gold)\n",
    "            for k, v in pred.items():\n",
    "                if \"predicted\" in k:\n",
    "                    merged[k] = v\n",
    "            merged_docs.append(merged)\n",
    "\n",
    "        return merged_docs\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.documents[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1f5272-c06f-454b-a090-6598218876b0",
   "metadata": {},
   "source": [
    "### Document\n",
    "\n",
    "This class represents a document. It encapsulates information about a document, its sentences, and any associated clusters. It provides methods for accessing and manipulating this information.\n",
    "\n",
    "Let's go through each part:\n",
    "\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the Document class.\n",
    "- Takes a JSON object (`js`) as input.\n",
    "- Extracts the document key (`_doc_key`) from the JSON object.\n",
    "- Uses the `fields_to_batches` function to extract specific fields from the JSON and create a list of entries.\n",
    "- Computes sentence lengths and starts to facilitate sentence indexing.\n",
    "- Creates a list of Sentence objects based on the entries.\n",
    "- If \"`clusters`\" or \"`predicted_clusters`\" are present in the JSON, creates lists of Cluster objects for clusters and predicted clusters.\n",
    "\n",
    "#### `__repr__` method:\n",
    "\n",
    "- Returns a string representation of the document, including sentence indices and their corresponding text.\n",
    "\n",
    "#### `__getitem__` method:\n",
    "\n",
    "- Enables indexing of the document. Given an index ix, it returns the corresponding `Sentence` object.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "- Returns the number of sentences in the document.\n",
    "\n",
    "#### `print_plaintext method`:\n",
    "\n",
    "- Prints the plaintext representation of the document, sentence by sentence.\n",
    "\n",
    "#### `find_cluster` method:\n",
    "\n",
    "- Searches through reference clusters (either predicted or actual) to find the one containing a specified entity.\n",
    "- Returns the found cluster or None if no match is found.\n",
    "\n",
    "#### `n_tokens property`:\n",
    "\n",
    "- Returns the total number of tokens in the document by summing the number of tokens in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd3ebedd-f439-4d22-a812-560ca07efe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, js):\n",
    "        self._doc_key = js[\"doc_key\"]\n",
    "        entries = fields_to_batches(js, [\"doc_key\", \"clusters\", \"predicted_clusters\", \"section_starts\"])\n",
    "        sentence_lengths = [len(entry[\"sentences\"]) for entry in entries]\n",
    "        sentence_starts = np.cumsum(sentence_lengths)\n",
    "        sentence_starts = np.roll(sentence_starts, 1)\n",
    "        sentence_starts[0] = 0\n",
    "        self.sentence_starts = sentence_starts\n",
    "        self.sentences = [Sentence(entry, sentence_start, sentence_ix)\n",
    "                          for sentence_ix, (entry, sentence_start)\n",
    "                          in enumerate(zip(entries, sentence_starts))]\n",
    "        if \"clusters\" in js:\n",
    "            self.clusters = [Cluster(entry, i, self)\n",
    "                             for i, entry in enumerate(js[\"clusters\"])]\n",
    "        if \"predicted_clusters\" in js:\n",
    "            self.predicted_clusters = [Cluster(entry, i, self)\n",
    "                                       for i, entry in enumerate(js[\"predicted_clusters\"])]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([str(i) + \": \" + \" \".join(sent.text) for i, sent in enumerate(self.sentences)])\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.sentences[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def print_plaintext(self):\n",
    "        for sent in self:\n",
    "            print(\" \".join(sent.text))\n",
    "\n",
    "\n",
    "    def find_cluster(self, entity, predicted=True):\n",
    "        \"\"\"\n",
    "        Search through erence clusters and return the one containing the query entity, if it's\n",
    "        part of a cluster. If we don't find a match, return None.\n",
    "        \"\"\"\n",
    "        clusters = self.predicted_clusters if predicted else self.clusters\n",
    "        for clust in clusters:\n",
    "            for entry in clust:\n",
    "                if entry.span == entity.span:\n",
    "                    return clust\n",
    "\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def n_tokens(self):\n",
    "        return sum([len(sent) for sent in self.sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e81cad-9a62-40fb-b427-6958a22f4759",
   "metadata": {},
   "source": [
    "### Cluster\n",
    "\n",
    "The `Cluster` class represents a cluster of entities within a document. It is used to group together entities that belong to the same cluster, providing information about the members of the cluster.\n",
    "This class is designed to encapsulate information about a cluster of entities within a document. It facilitates the organization and representation of entities belonging to the same cluster.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `cluster`: A list of entries representing the entities in the cluster.\n",
    "  - `cluster_id`: An identifier for the cluster.\n",
    "  - `document`: The document object to which the cluster belongs.\n",
    "- Attributes\n",
    "  - `members`: A list of ClusterMember instances, each representing an entity in the cluster.\n",
    "  - `cluster_id`: The identifier for the cluster.\n",
    "  \n",
    "#### Initialization Details\n",
    "- The `__init__` method initializes the cluster by extracting information about each entity in the cluster.\n",
    "- For each entry in the cluster, it determines the corresponding sentence and span in the document.\n",
    "- It creates `ClusterMember` instances for each entity and appends them to the members list.\n",
    "\n",
    "#### Representation\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the cluster, including the cluster identifier and a representation of its members.\n",
    "Accessing Members\n",
    "\n",
    "`__getitem__` Method:\n",
    "Allows accessing individual members of the cluster using indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf27b5db-6ece-4a9e-9e13-24e60c57ad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self, cluster, cluster_id, document):\n",
    "        members = []\n",
    "        for entry in cluster:\n",
    "            sentence_ix = get_sentence_of_span(entry, document.sentence_starts, document.n_tokens)\n",
    "            sentence = document[sentence_ix]\n",
    "            span = Span(entry[0], entry[1], sentence.text, sentence.sentence_start)\n",
    "            ners = [x for x in sentence.ner if x.span == span]\n",
    "            assert len(ners) <= 1\n",
    "            ner = ners[0] if len(ners) == 1 else None\n",
    "            to_append = ClusterMember(span, ner, sentence, cluster_id)\n",
    "            members.append(to_append)\n",
    "\n",
    "        self.members = members\n",
    "        self.cluster_id = cluster_id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.cluster_id}: \" + self.members.__repr__()\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.members[ix]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6784f412-5c4f-486c-bcd8-1b3294e894af",
   "metadata": {},
   "source": [
    "### ClusterMember\n",
    "\n",
    "Represents an individual entity within a cluster. It provides information about the entity's span, associated named entity recognition (NER) information, the sentence it belongs to, and the identifier of the cluster to which it is assigned. The class serves as a container for information about an individual entity within a cluster. It encapsulates details such as the span, NER information, sentence context, and the cluster to which the entity is assigned.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `span`: A Span instance representing the span of the entity in the document.\n",
    "  - `ner`: A NER instance representing the NER information for the entity.\n",
    "  - `sentence`: A Sentence instance representing the sentence containing the entity.\n",
    "  - `cluster_id`: The identifier of the cluster to which the entity belongs.\n",
    "- Attributes\n",
    "  - `span`: A Span instance representing the span of the entity.\n",
    "  - `ner`: A NER instance representing the NER information for the entity.\n",
    "  - `sentence`: A Sentence instance representing the sentence containing the entity.\n",
    "  - `cluster_id`: The identifier of the cluster to which the entity belongs.\n",
    "  \n",
    "#### Initialization Details\n",
    "\n",
    "The `__init__` method initializes a `ClusterMember` by assigning values to its attributes based on the provided parameters.\n",
    "Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the `ClusterMember`, including the sentence index and a representation of its span.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97932254-c9ae-4c58-82f4-200ea937605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterMember:\n",
    "    def __init__(self, span, ner, sentence, cluster_id):\n",
    "        self.span = span\n",
    "        self.ner = ner\n",
    "        self.sentence = sentence\n",
    "        self.cluster_id = cluster_id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{self.sentence.sentence_ix}> \" + self.span.__repr__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8bb7fc-7a06-4058-9b64-0c87a0313500",
   "metadata": {},
   "source": [
    "### Sentence\n",
    "\n",
    "This class represents a sentence. It encapsulates information about a sentence, including its text and associated entities (NER, relations, events). It provides methods for accessing and manipulating this information.\n",
    "\n",
    "Let's go through each method:\n",
    "\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the `Sentence` class.\n",
    "- Takes an `entry`, `sentence_start` (index of the sentence start in the document), and `sentence_ix` (sentence index) as input.\n",
    "- Stores information about the sentence's start position, text, and index.\n",
    "- Parses gold entities (NER, relations, events) and predicted entities (NER, relations, events).\n",
    "- Stores top spans if available.\n",
    "\n",
    "#### `__repr__` method:\n",
    "\n",
    "- Returns a string representation of the sentence, including the text and token indices.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "-Returns the number of tokens in the sentence.\n",
    "\n",
    "#### `get_flavor` method:\n",
    "\n",
    "- Given an argument (presumably an entity), retrieves its flavor from the gold NER annotations.\n",
    "- If multiple NER annotations are found for the same span, prints a message (debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3030363c-9fab-41ec-a724-e5a7b404d484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, entry, sentence_start, sentence_ix):\n",
    "        self.sentence_start = sentence_start\n",
    "        self.text = entry[\"sentences\"]\n",
    "        self.sentence_ix = sentence_ix\n",
    "        # Gold\n",
    "        if \"ner_flavor\" in entry:\n",
    "            self.ner = [NER(this_ner, self.text, sentence_start, flavor=this_flavor)\n",
    "                        for this_ner, this_flavor in zip(entry[\"ner\"], entry[\"ner_flavor\"])]\n",
    "        elif \"ner\" in entry:\n",
    "            self.ner = [NER(this_ner, self.text, sentence_start)\n",
    "                        for this_ner in entry[\"ner\"]]\n",
    "        if \"relations\" in entry:\n",
    "            self.relations = [Relation(this_relation, self.text, sentence_start) for\n",
    "                              this_relation in entry[\"relations\"]]\n",
    "        if \"events\" in entry:\n",
    "            self.events = Events(entry[\"events\"], self.text, sentence_start)\n",
    "\n",
    "        # Predicted\n",
    "        if \"predicted_ner\" in entry:\n",
    "            self.predicted_ner = [NER(this_ner, self.text, sentence_start, flavor=None) for\n",
    "                                  this_ner in entry[\"predicted_ner\"]]\n",
    "        if \"predicted_relations\" in entry:\n",
    "            self.predicted_relations = [Relation(this_relation, self.text, sentence_start) for\n",
    "                                        this_relation in entry[\"predicted_relations\"]]\n",
    "        if \"predicted_events\" in entry:\n",
    "            self.predicted_events = Events(entry[\"predicted_events\"], self.text, sentence_start)\n",
    "\n",
    "        # Top spans\n",
    "        if \"top_spans\" in entry:\n",
    "            self.top_spans = [NER(this_ner, self.text, sentence_start, flavor=None) for\n",
    "                                this_ner in entry[\"top_spans\"]]\n",
    "\n",
    "    def __repr__(self):\n",
    "        the_text = \" \".join(self.text)\n",
    "        the_lengths = np.array([len(x) for x in self.text])\n",
    "        tok_ixs = \"\"\n",
    "        for i, offset in enumerate(the_lengths):\n",
    "            true_offset = offset if i < 10 else offset - 1\n",
    "            tok_ixs += str(i)\n",
    "            tok_ixs += \" \" * true_offset\n",
    "\n",
    "        return the_text + \"\\n\" + tok_ixs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def get_flavor(self, argument):\n",
    "        the_ner = [x for x in self.ner if x.span == argument.span]\n",
    "        if len(the_ner) > 1:\n",
    "            print(\"Weird\")\n",
    "        if the_ner:\n",
    "            the_flavor = the_ner[0].flavor\n",
    "        else:\n",
    "            the_flavor = None\n",
    "        return the_flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97a8171-da41-4415-8477-628cc48c8941",
   "metadata": {},
   "source": [
    "### NER\n",
    "\n",
    "The NER class represents a Named Entity Recognition annotation within a sentence. It encapsulates information about a named entity, providing methods for representation and equality checks. The `Span` (we'll get to it next) class is used to represent the span of the named entity within the context of the sentence.\n",
    "\n",
    "Here are some details about it:\n",
    "#### Initialization\n",
    "\n",
    "- Parameters:\n",
    "  - `ner`: A list containing information about the NER span, including start index, end index, and label.\n",
    "  - `text`: The text content of the sentence.\n",
    "  - `sentence_start`: The index of the sentence start in the document.\n",
    "  - `flavor`: An optional parameter representing the flavor or type of the named entity.\n",
    "  \n",
    "- Attributes:\n",
    "  - `span`: An instance of the Span class representing the span of the NER annotation.\n",
    "  - `label`: The label assigned to the NER entity.\n",
    "  - `flavor`: The flavor or type of the named entity.\n",
    "  \n",
    "- Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the NER annotation, including the span and label.\n",
    "Equality Check\n",
    "\n",
    "`__eq__` Method:\n",
    "Checks if two NER instances are equal by comparing their span, label, and flavor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d638650-dbb5-4289-99b5-52ff47bff05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER:\n",
    "    def __init__(self, ner, text, sentence_start, flavor=None):\n",
    "        self.span = Span(ner[0], ner[1], text, sentence_start)\n",
    "        self.label = ner[2]\n",
    "        self.flavor = flavor\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.span.__repr__() + \": \" + self.label\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.span == other.span and\n",
    "                self.label == other.label and\n",
    "                self.flavor == other.flavor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3757870-6e1c-4a41-9f6e-84ce7bcb6aff",
   "metadata": {},
   "source": [
    "### Span\n",
    "\n",
    "The `Span` class represents a span of text within a document. It encapsulate information about a text span, providing methods for representation, equality checks, and hashing. It ensures the proper handling of spans within the document and sentence contexts.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `start`: The starting index of the span in the entire document.\n",
    "  - `end`: The ending index of the span in the entire document.\n",
    "  - `text`: The text content of the entire document.\n",
    "  - `sentence_start`: The index of the sentence start in the document.\n",
    "  \n",
    "- Attributes\n",
    "  - `start_doc`, `end_doc`: The start and end indices of the span in the entire document.\n",
    "  - `span_doc`: A tuple representing the span in the entire document.\n",
    "  - `start_sent`, `end_sent`: The start and end indices of the span within the sentence.\n",
    "  - `span_sent`: A tuple representing the span within the sentence.\n",
    "  - `text`: The actual text content of the span.\n",
    "  \n",
    "#### Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the span, including start and end indices and the actual text content.\n",
    "Equality Check\n",
    "\n",
    "`__eq__` Method:\n",
    "Checks if two Span instances are equal by comparing their spans in both the document and the sentence, along with the text content.\n",
    "Hashing\n",
    "\n",
    "`__hash__` Method:\n",
    "Computes a hash value for the Span instance based on its document and sentence spans, as well as the text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbea2e72-2d85-44e1-9de5-fa9f7d4d5a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Span:\n",
    "    def __init__(self, start, end, text, sentence_start):\n",
    "        self.start_doc = start\n",
    "        self.end_doc = end\n",
    "        self.span_doc = (self.start_doc, self.end_doc)\n",
    "        self.start_sent = start - sentence_start\n",
    "        self.end_sent = end - sentence_start\n",
    "        self.span_sent = (self.start_sent, self.end_sent)\n",
    "        self.text = text[self.start_sent:self.end_sent + 1]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str((self.start_sent, self.end_sent, self.text))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.span_doc == other.span_doc and\n",
    "                self.span_sent == other.span_sent and\n",
    "                self.text == other.text)\n",
    "\n",
    "    def __hash__(self):\n",
    "        tup = self.span_doc + self.span_sent + (\" \".join(self.text),)\n",
    "        return hash(tup)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6135ff-3aab-4f09-8292-7a4091f8466c",
   "metadata": {},
   "source": [
    "### Relation\n",
    "\n",
    "The Relation class is designed to represent a relation between two spans within a text. It encapsulates information about the spans, such as their start and end positions, the text they cover, and the label assigned to the relation. Here's a breakdown of the class:\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "- Parameters:\n",
    "\n",
    "  - `relation`: A tuple representing the start and end positions of the two spans and the label of the relation.\n",
    "  - `text`: The text containing the spans.\n",
    "  - `sentence_start`: The starting position of the sentence in the text.\n",
    "  \n",
    "- Attributes\n",
    "\n",
    "  - `pair`: A tuple containing two Span objects (span1 and span2) representing the spans of the relation.\n",
    "  - `label`: The label of the relation.\n",
    "  \n",
    "#### Representation\n",
    "`__repr__` Method: Returns a string representation of the Relation object, including the string representations of the two spans, the relation between them (\", \"), and the label.\n",
    "\n",
    "`__eq__` Method: Checks if two Relation objects are equal by comparing their span pairs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c87a147-2a87-4b2b-a7de-d0f14b5b84bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relation:\n",
    "    def __init__(self, relation, text, sentence_start):\n",
    "        start1, end1 = relation[0], relation[1]\n",
    "        start2, end2 = relation[2], relation[3]\n",
    "        label = relation[4]\n",
    "        span1 = Span(start1, end1, text, sentence_start)\n",
    "        span2 = Span(start2, end2, text, sentence_start)\n",
    "        self.pair = (span1, span2)\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.pair[0].__repr__() + \", \" + self.pair[1].__repr__() + \": \" + self.label\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.pair == other.pair) and (self.label == other.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74418c55-1311-401e-ab9a-5fc7e700b0d5",
   "metadata": {},
   "source": [
    "### InputFeatures\n",
    "\n",
    "This class represents a single set of features for the relation model. It encapsulates the necessary information required for processing a single example during training or inference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ecb42b4-7cfb-4739-b491-cd2f16529d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self, input_ids, input_mask, segment_ids, label_id, sub_idx, obj_idx):\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        self.sub_idx = sub_idx\n",
    "        self.obj_idx = obj_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898aefe7-a29f-46dc-bf24-b5c5b5ffd80c",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "The authors have aslo implemented some utility functions. Let's go through them and understand what they do.\n",
    "\n",
    "### add_marker_tokens\n",
    "This function, as discussed by the authors, extends the tokenizer's vocabulary with special marker tokens.\n",
    "\n",
    "Therfore, providing additional information about the structure and types of entities in the input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c71fcf9-94fa-4453-b766-0052e7fc38e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_marker_tokens(tokenizer, ner_labels):\n",
    "    new_tokens = ['<SUBJ_START>', '<SUBJ_END>', '<OBJ_START>', '<OBJ_END>']\n",
    "    for label in ner_labels:\n",
    "        new_tokens.append('<SUBJ_START=%s>'%label)\n",
    "        new_tokens.append('<SUBJ_END=%s>'%label)\n",
    "        new_tokens.append('<OBJ_START=%s>'%label)\n",
    "        new_tokens.append('<OBJ_END=%s>'%label)\n",
    "    for label in ner_labels:\n",
    "        new_tokens.append('<SUBJ=%s>'%label)\n",
    "        new_tokens.append('<OBJ=%s>'%label)\n",
    "    tokenizer.add_tokens(new_tokens)\n",
    "    logger.info('# vocab after adding markers: %d'%len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9af336-8c48-4545-a914-57f4e220fb36",
   "metadata": {},
   "source": [
    "### convert_examples_to_features\n",
    "\n",
    "The convert_examples_to_features function is responsible for converting the list of input examples into a list of InputFeatures objects, which can be used as input to the relation classification. It tokenizes the input examples, adds special markers for subject and object entities, handles token length constraints, and prepares the data for model input.\n",
    "\n",
    "**Let's break down the key components of this function:**\n",
    "\n",
    "#### Input Parameters:\n",
    "- `examples`: A list of input examples, where each example is a dictionary containing information about tokens, subject and object entities, and the relation.\n",
    "- `label2id`: A dictionary mapping relation labels to their corresponding integer IDs.\n",
    "- `max_seq_length`: The maximum sequence length allowed for the input tokens.\n",
    "- `tokenizer`: The tokenizer used to tokenize input sequences.\n",
    "- `special_tokens`: A dictionary used to keep track of special tokens introduced during processing.\n",
    "- `unused_tokens`: A boolean indicating whether tokens should be used as special tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cdae56d-073e-4ca4-ba7f-4f71ff447acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_examples_to_features(examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=True):\n",
    "    \"\"\"\n",
    "    Loads a data file into a list of `InputBatch`s.\n",
    "    unused_tokens: whether use [unused1] [unused2] as special tokens\n",
    "    \"\"\"\n",
    "\n",
    "    def get_special_token(w):\n",
    "        if w not in special_tokens:\n",
    "            if unused_tokens:\n",
    "                special_tokens[w] = \"[unused%d]\" % (len(special_tokens) + 1)\n",
    "            else:\n",
    "                special_tokens[w] = ('<' + w + '>').lower()\n",
    "        return special_tokens[w]\n",
    "\n",
    "    num_tokens = 0\n",
    "    max_tokens = 0\n",
    "    num_fit_examples = 0\n",
    "    num_shown_examples = 0\n",
    "    features = []\n",
    "    for (ex_index, example) in enumerate(examples):\n",
    "        if ex_index % 10000 == 0:\n",
    "            logger.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n",
    "\n",
    "        tokens = [CLS]\n",
    "        SUBJECT_START = get_special_token(\"SUBJ_START\")\n",
    "        SUBJECT_END = get_special_token(\"SUBJ_END\")\n",
    "        OBJECT_START = get_special_token(\"OBJ_START\")\n",
    "        OBJECT_END = get_special_token(\"OBJ_END\")\n",
    "        SUBJECT_NER = get_special_token(\"SUBJ=%s\" % example['subj_type'])\n",
    "        OBJECT_NER = get_special_token(\"OBJ=%s\" % example['obj_type'])\n",
    "\n",
    "        SUBJECT_START_NER = get_special_token(\"SUBJ_START=%s\"%example['subj_type'])\n",
    "        SUBJECT_END_NER = get_special_token(\"SUBJ_END=%s\"%example['subj_type'])\n",
    "        OBJECT_START_NER = get_special_token(\"OBJ_START=%s\"%example['obj_type'])\n",
    "        OBJECT_END_NER = get_special_token(\"OBJ_END=%s\"%example['obj_type'])\n",
    "\n",
    "        for i, token in enumerate(example['token']):\n",
    "            if i == example['subj_start']:\n",
    "                sub_idx = len(tokens)\n",
    "                tokens.append(SUBJECT_START_NER)\n",
    "            if i == example['obj_start']:\n",
    "                obj_idx = len(tokens)\n",
    "                tokens.append(OBJECT_START_NER)\n",
    "            for sub_token in tokenizer.tokenize(token):\n",
    "                tokens.append(sub_token)\n",
    "            if i == example['subj_end']:\n",
    "                tokens.append(SUBJECT_END_NER)\n",
    "            if i == example['obj_end']:\n",
    "                tokens.append(OBJECT_END_NER)\n",
    "        tokens.append(SEP)\n",
    "\n",
    "        num_tokens += len(tokens)\n",
    "        max_tokens = max(max_tokens, len(tokens))\n",
    "\n",
    "        if len(tokens) > max_seq_length:\n",
    "            tokens = tokens[:max_seq_length]\n",
    "            if sub_idx >= max_seq_length:\n",
    "                sub_idx = 0\n",
    "            if obj_idx >= max_seq_length:\n",
    "                obj_idx = 0\n",
    "        else:\n",
    "            num_fit_examples += 1\n",
    "\n",
    "        segment_ids = [0] * len(tokens)\n",
    "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_mask = [1] * len(input_ids)\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "        label_id = label2id[example['relation']]\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        if num_shown_examples < 20:\n",
    "            if (ex_index < 5) or (label_id > 0):\n",
    "                num_shown_examples += 1\n",
    "                logger.info(\"*** Example ***\")\n",
    "                logger.info(\"guid: %s\" % (example['id']))\n",
    "                logger.info(\"tokens: %s\" % \" \".join(\n",
    "                        [str(x) for x in tokens]))\n",
    "                logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "                logger.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "                logger.info(\"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "                logger.info(\"label: %s (id = %d)\" % (example['relation'], label_id))\n",
    "                logger.info(\"sub_idx, obj_idx: %d, %d\" % (sub_idx, obj_idx))\n",
    "\n",
    "        features.append(\n",
    "                InputFeatures(input_ids=input_ids,\n",
    "                              input_mask=input_mask,\n",
    "                              segment_ids=segment_ids,\n",
    "                              label_id=label_id,\n",
    "                              sub_idx=sub_idx,\n",
    "                              obj_idx=obj_idx))\n",
    "    logger.info(\"Average #tokens: %.2f\" % (num_tokens * 1.0 / len(examples)))\n",
    "    logger.info(\"Max #tokens: %d\"%max_tokens)\n",
    "    logger.info(\"%d (%.2f %%) examples can fit max_seq_length = %d\" % (num_fit_examples,\n",
    "                num_fit_examples * 100.0 / len(examples), max_seq_length))\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9d47f0-8e66-434f-b4df-7e4819bc6f2c",
   "metadata": {},
   "source": [
    "### setseed\n",
    "The setseed function sets the random seed for various random number generators in the environment, specifically for the `random` module, `numpy` library, and the `PyTorch` library.\n",
    "\n",
    "Setting a random seed ensures reproducibility in the generation of random numbers, which is crucial for obtaining consistent results when running experiments or training machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c0c604f-380e-4f41-a5b0-62b59ba851b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setseed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a1ca7-51f1-470f-8eba-488ece0fbe59",
   "metadata": {},
   "source": [
    "### simple_accuracy\n",
    "This function calculates the accuracy of a model's predictions by comparing the predicted labels (`preds`) with the actual ground truth labels (`labels`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f309e0c-02b8-47ec-a482-62cb017c9bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_accuracy(preds, labels):\n",
    "    return (preds == labels).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e76ab2-b1de-47d8-a63c-040e03d30d3f",
   "metadata": {},
   "source": [
    "### compute_f1\n",
    "\n",
    "This function is used to comute the F1 score of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e72b43a-4325-4eb3-90ce-091701eb3529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(preds, labels, e2e_ngold):\n",
    "    n_gold = n_pred = n_correct = 0\n",
    "    for pred, label in zip(preds, labels):\n",
    "        if pred != 0:\n",
    "            n_pred += 1\n",
    "        if label != 0:\n",
    "            n_gold += 1\n",
    "        if (pred != 0) and (label != 0) and (pred == label):\n",
    "            n_correct += 1\n",
    "    if n_correct == 0:\n",
    "        return {'precision': 0.0, 'recall': 0.0, 'f1': 0.0}\n",
    "    else:\n",
    "        prec = n_correct * 1.0 / n_pred\n",
    "        recall = n_correct * 1.0 / n_gold\n",
    "        if prec + recall > 0:\n",
    "            f1 = 2.0 * prec * recall / (prec + recall)\n",
    "        else:\n",
    "            f1 = 0.0\n",
    "\n",
    "        if e2e_ngold is not None:\n",
    "            e2e_recall = n_correct * 1.0 / e2e_ngold\n",
    "            e2e_f1 = 2.0 * prec * e2e_recall / (prec + e2e_recall)\n",
    "        else:\n",
    "            e2e_recall = e2e_f1 = 0.0\n",
    "        return {'precision': prec, 'recall': e2e_recall, 'f1': e2e_f1, 'task_recall': recall, 'task_f1': f1, \n",
    "        'n_correct': n_correct, 'n_pred': n_pred, 'n_gold': e2e_ngold, 'task_ngold': n_gold}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a5c8c2-e94c-4402-b2bc-17cc9d21d5e8",
   "metadata": {},
   "source": [
    "### evaluate\n",
    "\n",
    "Evaluates a trained model on an evaluation dataset. It computes various evaluation metrics, including loss, F1 score, accuracy, and additional metrics provided by the compute_f1 function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1953e6e9-48cb-49e1-8494-77db5028f16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, device, eval_dataloader, eval_label_ids, num_labels, e2e_ngold=None, verbose=True):\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    preds = []\n",
    "    for input_ids, input_mask, segment_ids, label_ids, sub_idx, obj_idx in eval_dataloader:\n",
    "        input_ids = input_ids.to(device)\n",
    "        input_mask = input_mask.to(device)\n",
    "        segment_ids = segment_ids.to(device)\n",
    "        label_ids = label_ids.to(device)\n",
    "        sub_idx = sub_idx.to(device)\n",
    "        obj_idx = obj_idx.to(device)\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_ids, segment_ids, input_mask, labels=None, sub_idx=sub_idx, obj_idx=obj_idx)\n",
    "        loss_fct = CrossEntropyLoss()\n",
    "        tmp_eval_loss = loss_fct(logits.view(-1, num_labels), label_ids.view(-1))\n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "        if len(preds) == 0:\n",
    "            preds.append(logits.detach().cpu().numpy())\n",
    "        else:\n",
    "            preds[0] = np.append(\n",
    "                preds[0], logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    logits = preds[0]\n",
    "    preds = np.argmax(preds[0], axis=1)\n",
    "    result = compute_f1(preds, eval_label_ids.numpy(), e2e_ngold=e2e_ngold)\n",
    "    result['accuracy'] = simple_accuracy(preds, eval_label_ids.numpy())\n",
    "    result['eval_loss'] = eval_loss\n",
    "    if verbose:\n",
    "        logger.info(\"***** Eval results *****\")\n",
    "        for key in sorted(result.keys()):\n",
    "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "    return preds, result, logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d65242-79df-4804-b930-960c0540aa5b",
   "metadata": {},
   "source": [
    "### print_pred_json\n",
    "\n",
    "This function is used for formatting and printing the predicted relations based on the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39af037c-b43b-4006-aa64-29d4e0059140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pred_json(eval_data, eval_examples, preds, id2label, output_file):\n",
    "    rels = dict()\n",
    "    for ex, pred in zip(eval_examples, preds):\n",
    "        doc_sent, sub, obj = decode_sample_id(ex['id'])\n",
    "        if doc_sent not in rels:\n",
    "            rels[doc_sent] = []\n",
    "        if pred != 0:\n",
    "            rels[doc_sent].append([sub[0], sub[1], obj[0], obj[1], id2label[pred]])\n",
    "\n",
    "    js = eval_data.js\n",
    "    for doc in js:\n",
    "        doc['predicted_relations'] = []\n",
    "        for sid in range(len(doc['sentences'])):\n",
    "            k = '%s@%d'%(doc['doc_key'], sid)\n",
    "            doc['predicted_relations'].append(rels.get(k, []))\n",
    "    \n",
    "    logger.info('Output predictions to %s..'%(output_file))\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('\\n'.join(json.dumps(doc) for doc in js))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb50b26-5267-4dc8-8dc0-1eb3bc19693a",
   "metadata": {},
   "source": [
    "### save_trained_model\n",
    "\n",
    "The save_trained_model function is responsible for saving the trained model, its configuration, and the associated tokenizer to the specified output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bba02b22-fe74-438e-86f1-5f9fa3c02f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_trained_model(output_dir, model, tokenizer):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    logger.info('Saving model to %s'%output_dir)\n",
    "    model_to_save = model.module if hasattr(model, 'module') else model\n",
    "    output_model_file = os.path.join(output_dir, WEIGHTS_NAME)\n",
    "    output_config_file = os.path.join(output_dir, CONFIG_NAME)\n",
    "    torch.save(model_to_save.state_dict(), output_model_file)\n",
    "    model_to_save.config.to_json_file(output_config_file)\n",
    "    tokenizer.save_vocabulary(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c010091f-2cdb-4b28-8f75-5eba00986786",
   "metadata": {},
   "source": [
    "### generate_relation_data\n",
    "The generate_relation_data function is designed to prepare data for the training or evaluation of the relation model. It takes an entity dataset (`entity_data`), generates samples for relation extraction, and returns the dataset, a list of samples, and the total number of relations in the dataset. Let's break down the key components of this function:\n",
    "\n",
    "#### Input Parameters:\n",
    "- `entity_data`: The entity dataset from which relation data will be generated.\n",
    "- `use_gold`: A boolean parameter indicating whether to use gold (true) or predicted (false) named entities and relations. Default is False.\n",
    "- `context_window`: An integer representing the size of the context window to consider around each sentence. Default is 0.\n",
    "\n",
    "This function processes the entity dataset, extracting named entities and relations. It then generates samples for relation extraction, considering optional context windows. The generated samples include information about document ID, sentence ID, relation labels, entity spans, and tokenized text. The function returns the processed dataset, the list of generated samples, and the total number of relations in the dataset. The generated samples can be used for training or evaluating a relation extraction model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "88c5f983-c388-42e4-97b7-0504ef40a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_relation_data(entity_data, use_gold=False, context_window=0):\n",
    "    \"\"\"\n",
    "    Prepare data for the relation model\n",
    "    If training: set use_gold = True\n",
    "    \"\"\"\n",
    "    logger.info('Generate relation data from %s'%(entity_data))\n",
    "    data = Dataset(entity_data)\n",
    "\n",
    "    nner, nrel = 0, 0\n",
    "    max_sentsample = 0\n",
    "    samples = []\n",
    "    for doc in data:\n",
    "        for i, sent in enumerate(doc):\n",
    "            sent_samples = []\n",
    "\n",
    "            nner += len(sent.ner)\n",
    "            nrel += len(sent.relations)\n",
    "            if use_gold:\n",
    "                sent_ner = sent.ner\n",
    "            else:\n",
    "                sent_ner = sent.predicted_ner\n",
    "            \n",
    "            gold_ner = {}\n",
    "            for ner in sent.ner:\n",
    "                gold_ner[ner.span] = ner.label\n",
    "            \n",
    "            gold_rel = {}\n",
    "            for rel in sent.relations:\n",
    "                gold_rel[rel.pair] = rel.label\n",
    "            \n",
    "            sent_start = 0\n",
    "            sent_end = len(sent.text)\n",
    "            tokens = sent.text\n",
    "\n",
    "            if context_window > 0:\n",
    "                add_left = (context_window-len(sent.text)) // 2\n",
    "                add_right = (context_window-len(sent.text)) - add_left\n",
    "\n",
    "                j = i - 1\n",
    "                while j >= 0 and add_left > 0:\n",
    "                    context_to_add = doc[j].text[-add_left:]\n",
    "                    tokens = context_to_add + tokens\n",
    "                    add_left -= len(context_to_add)\n",
    "                    sent_start += len(context_to_add)\n",
    "                    sent_end += len(context_to_add)\n",
    "                    j -= 1\n",
    "\n",
    "                j = i + 1\n",
    "                while j < len(doc) and add_right > 0:\n",
    "                    context_to_add = doc[j].text[:add_right]\n",
    "                    tokens = tokens + context_to_add\n",
    "                    add_right -= len(context_to_add)\n",
    "                    j += 1\n",
    "            \n",
    "            for x in range(len(sent_ner)):\n",
    "                for y in range(len(sent_ner)):\n",
    "                    if x == y:\n",
    "                        continue\n",
    "                    sub = sent_ner[x]\n",
    "                    obj = sent_ner[y]\n",
    "                    label = gold_rel.get((sub.span, obj.span), 'no_relation')\n",
    "                    sample = {}\n",
    "                    sample['docid'] = doc._doc_key\n",
    "                    sample['id'] = '%s@%d::(%d,%d)-(%d,%d)'%(doc._doc_key, sent.sentence_ix, sub.span.start_doc, sub.span.end_doc, obj.span.start_doc, obj.span.end_doc)\n",
    "                    sample['relation'] = label\n",
    "                    sample['subj_start'] = sub.span.start_sent + sent_start\n",
    "                    sample['subj_end'] = sub.span.end_sent + sent_start\n",
    "                    sample['subj_type'] = sub.label\n",
    "                    sample['obj_start'] = obj.span.start_sent + sent_start\n",
    "                    sample['obj_end'] = obj.span.end_sent + sent_start\n",
    "                    sample['obj_type'] = obj.label\n",
    "                    sample['token'] = tokens\n",
    "                    sample['sent_start'] = sent_start\n",
    "                    sample['sent_end'] = sent_end\n",
    "\n",
    "                    sent_samples.append(sample)\n",
    "\n",
    "            max_sentsample = max(max_sentsample, len(sent_samples))\n",
    "            samples += sent_samples\n",
    "    \n",
    "    tot = len(samples)\n",
    "    logger.info('#samples: %d, max #sent.samples: %d'%(tot, max_sentsample))\n",
    "\n",
    "    return data, samples, nrel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5149aaa-7830-44bb-a386-386340518e5e",
   "metadata": {},
   "source": [
    "### decode_sample_id\n",
    "\n",
    "Used to decode a sample identified by its ID into: document and sentence information (`doc_sent`), subject coordinates (`sub`), and object coordinates (`obj`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "98235e9b-c1d1-4dca-92b3-e146112e69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sample_id(sample_id):\n",
    "    doc_sent = sample_id.split('::')[0]\n",
    "    pair = sample_id.split('::')[1]\n",
    "    pair = pair.split('-')\n",
    "    sub = (int(pair[0][1:-1].split(',')[0]), int(pair[0][1:-1].split(',')[1]))\n",
    "    obj = (int(pair[1][1:-1].split(',')[0]), int(pair[1][1:-1].split(',')[1]))\n",
    "\n",
    "    return doc_sent, sub, obj\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98984a23-2b18-43ee-82ab-b5ab0df64fef",
   "metadata": {},
   "source": [
    "### get_sentence_of_span\n",
    "\n",
    "determine the index of the sentence to which a given span (represented as a pair of indices) belongs, and returns that index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f0452b4-e30b-4b14-986c-1ba8cc0f4f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_of_span(span, sentence_starts, doc_tokens):\n",
    "    \"\"\"\n",
    "    Return the index of the sentence that the span is part of.\n",
    "    \"\"\"\n",
    "    # Inclusive sentence ends\n",
    "    sentence_ends = [x - 1 for x in sentence_starts[1:]] + [doc_tokens - 1]\n",
    "    in_between = [span[0] >= start and span[1] <= end\n",
    "                  for start, end in zip(sentence_starts, sentence_ends)]\n",
    "    assert sum(in_between) == 1\n",
    "    the_sentence = in_between.index(True)\n",
    "    return the_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3a955b1-2bcb-45d0-96ee-9389635d7ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fields_to_batches(d, keys_to_ignore=[]):\n",
    "    keys = [key for key in d.keys() if key not in keys_to_ignore]\n",
    "    lengths = [len(d[k]) for k in keys]\n",
    "    assert len(set(lengths)) == 1\n",
    "    length = lengths[0]\n",
    "    res = [{k: d[k][i] for k in keys} for i in range(length)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad931ef-cf57-47c7-9cfd-0ab3db015747",
   "metadata": {},
   "source": [
    "## Running and evaluationg the pre-trained relation model\n",
    "\n",
    "Now that the setup is out of the way. We can actually run the model and evaluate it with a pre-trained BERT-based model on the SciERC dataset.\n",
    "\n",
    "Let's perform the training, evaluating, and predicting of the relation model using the SciBERT model.\n",
    "\n",
    "Configuration Parameters:\n",
    "- model_name: The name the pre-trained SciBERT model.\n",
    "- add_new_tokens: A boolean indicating whether to add new task-specific tokens to the tokenizer.\n",
    "- no_cuda: A boolean indicating whether to use CPU instead of GPU.\n",
    "- do_train, do_eval, eval_test: Boolean flags to control whether to perform training, evaluation, and evaluation on the test set.\n",
    "- do_lower_case: A boolean indicating whether to convert text to lowercase during tokenization.\n",
    "- entity_output_dir: The directory containing output from the entity recognition model.\n",
    "- entity_predictions_dev, entity_predictions_test: The filenames for entity predictions on the development and test sets.\n",
    "- eval_with_gold: A boolean indicating whether to use gold standard entities during evaluation.\n",
    "- context_window: The size of the context window around each sentence.\n",
    "- max_seq_length: The maximum sequence length for tokenized input.\n",
    "- seed: The random seed for reproducibility.\n",
    "- output_dir: The directory to save the trained model and evaluation logs.\n",
    "- negative_label: The label for negative relations.\n",
    "- task: The specific relation extraction task (assumed to be \"scierc\").\n",
    "- train_mode: The training mode, assumed to be \"random_sorted\".\n",
    "- train_batch_size, eval_batch_size: Batch sizes for training and evaluation.\n",
    "- num_train_epochs: The number of training epochs.\n",
    "- train_file: The file containing training data.\n",
    "- eval_per_epoch: The frequency of evaluation per epoch.\n",
    "- learning_rate: The learning rate for training.\n",
    "- prediction_file: The filename for saving predictions.\n",
    "- BertLayerNorm: The LayerNorm class to be used (assumed to be from torch.nn).\n",
    "- CLS, SEP: Special tokens for [CLS] (classification) and [SEP] (separator).\n",
    "- RelationModel: The model class for relation extraction.\n",
    "- device: The computing device (CPU or GPU).\n",
    "- n_gpu: The number of available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b14b727-39e4-4328-a96f-6a10b50e65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'allenai/scibert_scivocab_uncased'\n",
    "add_new_tokens = False\n",
    "no_cuda = False\n",
    "do_train = False\n",
    "do_eval = True\n",
    "eval_test = True\n",
    "do_lower_case = True\n",
    "entity_output_dir = os.getcwd() + '/scierc_models/ent-scib-ctx0/'\n",
    "entity_predictions_dev = 'ent_pred_dev.json'\n",
    "eval_with_gold = True\n",
    "context_window = 0\n",
    "max_seq_length = 128\n",
    "entity_predictions_test = 'ent_pred_test.json'\n",
    "seed = 0\n",
    "output_dir = os.getcwd() + '/scierc_models/rel_approx-scib-ctx0/'\n",
    "negative_label = 'no_relation'\n",
    "task = 'scierc'\n",
    "train_mode = 'random_sorted'\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 8\n",
    "num_train_epochs = 3.0\n",
    "train_file = None\n",
    "eval_per_epoch = 10\n",
    "learning_rate = None\n",
    "prediction_file = 'predictions.json'\n",
    "BertLayerNorm = torch.nn.LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d198d-b4de-49a8-bc2e-ccdaea283483",
   "metadata": {},
   "source": [
    "#### Special Tokens and Model Initialization:\n",
    "\n",
    "- `CLS` and `SEP` are special tokens used in BERT-like models, where [CLS] denotes the start of a sequence, and [SEP] separates segments or sentences.\n",
    "- `RelationModel` is set to the BertForRelation model, since that's the model we will useCLS = \"[CLS]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "963d6af7-d127-4478-9a90-a1efb83c0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS = \"[CLS]\"\n",
    "SEP = \"[SEP]\"\n",
    "\n",
    "RelationModel = BertForRelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d25e0-90d5-4655-afc6-bbab5ba70fab",
   "metadata": {},
   "source": [
    "#### Device and GPU Configuration:\n",
    "\n",
    "- `device`: It checks if a GPU is available. If available, it uses GPU; otherwise, it falls back to CPU.\n",
    "- `n_gpu`: It counts the number of available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e820beaf-9bfd-407d-933e-4fa2a400272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9fe93-f05f-4b92-b0c1-3bde4ed340b3",
   "metadata": {},
   "source": [
    "#### Data Preparation:\n",
    "\n",
    "The input data format of the relation model is almost the same as that of the entity model, except that there is one more filed .\"predicted_ner\" to store the predictions of the entity model.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"doc_key\": \"CNN_ENG_20030306_083604.6\",\n",
    "  \"sentences\": [...],\n",
    "  \"ner\": [...],\n",
    "  \"relations\": [...],\n",
    "  \"predicted_ner\": [\n",
    "    [...],\n",
    "    [...],\n",
    "    [[26, 26, \"LOC\"], [14, 15, \"PER\"], ...],\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Let's prepare the data for the training, development (dev), and test sets using the generate_relation_data function.\n",
    "- `train_dataset`, `eval_dataset`, and `test_dataset` hold the generated datasets.\n",
    "- `train_examples`, `eval_examples`, and `test_examples` contain examples from the respective datasets.\n",
    "- `train_nrel`, `eval_nrel`, and `test_nrel` store the number of relations in the corresponding sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c87d6bac-ffdc-448b-8f58-f03929827dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:29 - INFO - run_relation - Generate relation data from C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0/ent_pred_test.json\n",
      "11/21/2023 15:53:30 - INFO - run_relation - #samples: 5062, max #sent.samples: 156\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "if do_train:\n",
    "    train_dataset, train_examples, train_nrel = generate_relation_data(train_file, use_gold=True, context_window=context_window)\n",
    "# dev set\n",
    "if (do_eval and do_train) or (do_eval and not(eval_test)):\n",
    "    eval_dataset, eval_examples, eval_nrel = generate_relation_data(os.path.join(entity_output_dir, entity_predictions_dev), use_gold=eval_with_gold, context_window=context_window)\n",
    "# test set\n",
    "if eval_test:\n",
    "    test_dataset, test_examples, test_nrel = generate_relation_data(os.path.join(entity_output_dir, entity_predictions_test), use_gold=eval_with_gold, context_window=context_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b9e86-1ab6-401e-884c-015c1b52c4e4",
   "metadata": {},
   "source": [
    "#### Random Seed Setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "146f7485-4459-4c99-8624-ea7dd497e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "setseed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dacfb4-a261-4aa4-a5a5-12c55df05ec1",
   "metadata": {},
   "source": [
    "#### Directory and Logging Setup:\n",
    "\n",
    "- Ensuring that at least one of `do_train` or `do_eval` is set to True.\n",
    "- We also create the output directory if it doesn't exist and set up logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88ccfb8f-e50c-4399-961d-341f7a4229eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_train and not do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if do_train:\n",
    "    logger.addHandler(logging.FileHandler(os.path.join(output_dir, \"train.log\"), 'w'))\n",
    "else:\n",
    "    logger.addHandler(logging.FileHandler(os.path.join(output_dir, \"eval.log\"), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28721e51-b916-46cf-b317-72d3003746de",
   "metadata": {},
   "source": [
    "#### Label List and Mappings:\n",
    "\n",
    "- Loading/creating a list of relation labels (`label_list`) and saving it to a file.\n",
    "- Again, we create the mappings (`label2id` and `id2label`) and calculate the number of labels (`num_labels`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fadd1860-e68a-4518-87bf-06c26b8774c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label_list\n",
    "if os.path.exists(os.path.join(output_dir, 'label_list.json')):\n",
    "    with open(os.path.join(output_dir, 'label_list.json'), 'r') as f:\n",
    "        label_list = json.load(f)\n",
    "else:\n",
    "    label_list = [negative_label] + task_rel_labels[task]\n",
    "    with open(os.path.join(output_dir, 'label_list.json'), 'w') as f:\n",
    "        json.dump(label_list, f)\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051a95a-905e-4c9f-86c5-e71572709c2e",
   "metadata": {},
   "source": [
    "#### Tokenizer and Special Tokens:\n",
    "\n",
    "- It initializes the tokenizer using the specified pre-trained model (`model_name`).\n",
    "- If `add_new_tokens` is set to True, it adds task-specific marker tokens using the `add_marker_tokens` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f898f08f-3d56-4cc2-8092-79c478be88bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "11/21/2023 15:53:36 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/21/2023 15:53:36 - INFO - transformers.tokenization_utils_base - Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/vocab.txt from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\e3debd8fbdf40874753724814ee0520f612b577b26c8755bca485103b47cd3bc.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/added_tokens.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/special_tokens_map.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer_config.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer.json from cache at None\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=do_lower_case)\n",
    "if add_new_tokens:\n",
    "    add_marker_tokens(tokenizer, task_ner_labels[task])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9cbe2-81c3-4020-93a6-a53d166eb015",
   "metadata": {},
   "source": [
    "#### Special Tokens Saving/Loading:\n",
    "\n",
    "It loads or initializes a dictionary for special tokens (`special_tokens`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6554cd01-60d3-4ab8-a9c4-0bee2501761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(output_dir, 'special_tokens.json')):\n",
    "    with open(os.path.join(output_dir, 'special_tokens.json'), 'r') as f:\n",
    "        special_tokens = json.load(f)\n",
    "else:\n",
    "    special_tokens = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc7210-7735-48c8-aca5-81fc2d073e06",
   "metadata": {},
   "source": [
    "#### Evaluation Data Preparation:\n",
    "\n",
    "- It converts evaluation examples (eval_examples) to features using the convert_examples_to_features function.\n",
    "- It logs information about the evaluation dataset, such as the number of examples and the batch size.\n",
    "- It creates PyTorch tensors for input features (all_input_ids, all_input_mask, etc.).\n",
    "- It constructs a PyTorch TensorDataset and a corresponding DataLoader for the evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5dc1cc5d-b61a-4052-b9d7-309d1d9b4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_eval and (do_train or not(eval_test)):\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "    logger.info(\"***** Dev *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    all_sub_idx = torch.tensor([f.sub_idx for f in eval_features], dtype=torch.long)\n",
    "    all_obj_idx = torch.tensor([f.obj_idx for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "    eval_dataloader = DataLoader(eval_data, batch_size=eval_batch_size)\n",
    "    eval_label_ids = all_label_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5dd61b-c99f-4372-96dd-717f43891147",
   "metadata": {},
   "source": [
    "#### Save Special Tokens\n",
    "\n",
    "It saves the `special_tokens` dictionary to a JSON file named 'special_tokens.json' in the output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000703a-a771-4def-92be-c61540ad6e13",
   "metadata": {},
   "source": [
    "with open(os.path.join(output_dir, 'special_tokens.json'), 'w') as f:\n",
    "    json.dump(special_tokens, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659fa904-1fe5-4b16-bafd-0d44625a1092",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "- It logs the `special_tokens` dictionary.\n",
    "- If `eval_test` is True, it uses the test dataset (`test_dataset`, `test_examples`) for evaluation; otherwise, it uses the previously loaded dev dataset.\n",
    "- It converts the evaluation examples to features and constructs a PyTorch TensorDataset and a corresponding DataLoader for the evaluation set.\n",
    "- It loads the pre-trained relation extraction model (RelationModel) from the output directory.\n",
    "- It evaluates the model on the evaluation set and logs the results.\n",
    "- It prints the predictions to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e80d3b70-f753-45a1-b06d-ba7404ddc275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:45 - INFO - run_relation - {'SUBJ_START': '[unused1]', 'SUBJ_END': '[unused2]', 'OBJ_START': '[unused3]', 'OBJ_END': '[unused4]', 'SUBJ=Generic': '[unused5]', 'OBJ=OtherScientificTerm': '[unused6]', 'SUBJ_START=Generic': '[unused7]', 'SUBJ_END=Generic': '[unused8]', 'OBJ_START=OtherScientificTerm': '[unused9]', 'OBJ_END=OtherScientificTerm': '[unused10]', 'OBJ=Material': '[unused11]', 'OBJ_START=Material': '[unused12]', 'OBJ_END=Material': '[unused13]', 'SUBJ=OtherScientificTerm': '[unused14]', 'OBJ=Generic': '[unused15]', 'SUBJ_START=OtherScientificTerm': '[unused16]', 'SUBJ_END=OtherScientificTerm': '[unused17]', 'OBJ_START=Generic': '[unused18]', 'OBJ_END=Generic': '[unused19]', 'SUBJ=Material': '[unused20]', 'SUBJ_START=Material': '[unused21]', 'SUBJ_END=Material': '[unused22]', 'OBJ=Task': '[unused23]', 'OBJ_START=Task': '[unused24]', 'OBJ_END=Task': '[unused25]', 'SUBJ=Task': '[unused26]', 'SUBJ_START=Task': '[unused27]', 'SUBJ_END=Task': '[unused28]', 'OBJ=Method': '[unused29]', 'OBJ_START=Method': '[unused30]', 'OBJ_END=Method': '[unused31]', 'SUBJ=Method': '[unused32]', 'SUBJ_START=Method': '[unused33]', 'SUBJ_END=Method': '[unused34]', 'OBJ=Metric': '[unused35]', 'OBJ_START=Metric': '[unused36]', 'OBJ_END=Metric': '[unused37]', 'SUBJ=Metric': '[unused38]', 'SUBJ_START=Metric': '[unused39]', 'SUBJ_END=Metric': '[unused40]'}\n",
      "11/21/2023 15:53:45 - INFO - run_relation - Writing example 0 of 5062\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(2,3)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of [unused9] proper nouns [unused28] [unused10] in japanese text has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 10 1193 24748 29 11 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 4\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(5,6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in [unused12] japanese text [unused13] has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 13 9155 3267 14 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 8\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(19,20)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in japanese text has been studied as a part of the more general problem of [unused24] morphological analysis [unused25] in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 25 6893 669 26 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 22\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(22,24)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in japanese text has been studied as a part of the more general problem of morphological analysis in [unused24] japanese text processing [unused25] - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 25 9155 3267 2307 26 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 25\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(2,3)-(0,3)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused24] recognition of [unused16] proper nouns [unused17] [unused25] in japanese text has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 25 3512 131 17 1193 24748 18 26 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 4, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(2,3)-(5,6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] recognition of [unused16] proper nouns [unused17] in [unused12] japanese text [unused13] has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 3512 131 17 1193 24748 18 121 13 9155 3267 14 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 3, 8\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(19,20)-(22,24)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] recognition of proper nouns in japanese text has been studied as a part of the more general problem of [unused27] morphological analysis [unused28] in [unused24] japanese text processing [unused25] - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 3512 131 1193 24748 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 28 6893 669 29 121 25 9155 3267 2307 26 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 20, 25\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@1::(43,45)-(34,34)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused18] it [unused19] has also been studied in the framework of [unused27] japanese information extraction [unused28] - lr ##b - - ls ##b - 3 - rs ##b - - rr ##b - in recent years . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 19 256 20 434 469 528 2580 121 111 2641 131 28 9155 776 4220 29 579 8295 30125 579 579 6208 30125 579 239 579 3102 30125 579 579 5058 30125 579 121 2151 1320 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 12, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(56,56)-(59,64)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our [unused7] approach [unused8] to the [unused24] multi - lingu ##al evaluation task - lr ##b - met - rr ##b - [unused25] for japanese text is to consider the given task as a morphological analysis problem in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 8 1139 9 147 111 25 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 26 168 9155 3267 165 147 1129 111 906 2188 188 106 6893 669 1167 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 2, 7\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(59,64)-(66,67)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the [unused27] multi - lingu ##al evaluation task - lr ##b - met - rr ##b - [unused28] for [unused12] japanese text [unused13] is to consider the given task as a morphological analysis problem in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 28 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 29 168 13 9155 3267 14 165 147 1129 111 906 2188 188 106 6893 669 1167 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 5, 23\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(76,78)-(73,73)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the multi - lingu ##al evaluation task - lr ##b - met - rr ##b - for japanese text is to consider the given [unused18] task [unused19] as a [unused27] morphological analysis problem [unused28] in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 168 9155 3267 165 147 1129 111 906 19 2188 20 188 106 28 6893 669 1167 29 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 33, 28\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(80,80)-(76,78)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the multi - lingu ##al evaluation task - lr ##b - met - rr ##b - for japanese text is to consider the given task as a [unused24] morphological analysis problem [unused25] in [unused21] japanese [unused22] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 168 9155 3267 165 147 1129 111 906 2188 188 106 25 6893 669 1167 26 121 22 9155 23 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 37, 31\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(83,84)-(93,103)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our [unused33] morphological analyzer [unused34] has done all the necessary work for the [unused24] recognition and classification of proper names , numerical and temporal expressions [unused25] , i . e . named entity - lr ##b - ne - rr ##b - items in the japanese text . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 34 6893 12951 35 434 2992 355 111 2538 697 168 111 25 3512 137 2998 131 1193 8541 422 4058 137 3930 6370 26 422 259 205 139 205 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 121 111 9155 3267 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 2, 14\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(106,111)-(97,103)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our morphological analyzer has done all the necessary work for the recognition and classification of [unused9] proper names , numerical and temporal expressions [unused10] , i . e . [unused16] named entity - lr ##b - ne - rr ##b - items [unused17] in the japanese text . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 6893 12951 434 2992 355 111 2538 697 168 111 3512 137 2998 131 10 1193 8541 422 4058 137 3930 6370 11 422 259 205 139 205 17 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 18 121 111 9155 3267 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: HYPONYM-OF (id = 6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 30, 16\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(106,111)-(114,115)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i . e . [unused16] named entity - lr ##b - ne - rr ##b - items [unused17] in the [unused12] japanese text [unused13] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 6893 12951 434 2992 355 111 2538 697 168 111 3512 137 2998 131 1193 8541 422 4058 137 3930 6370 422 259 205 139 205 17 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 18 121 111 13 9155 3267 14 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 28, 44\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(125,125)-(127,128)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused33] amorph [unused34] recognizes [unused9] ne items [unused10] in two stages : dictionary lookup and rule application . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 34 15291 35 20269 10 287 3945 11 121 502 4303 862 13050 22474 137 3346 1836 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 5\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(133,134)-(125,125)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused30] amorph [unused31] recognizes ne items in two stages : [unused33] dictionary lookup [unused34] and rule application . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 31 15291 32 20269 287 3945 121 502 4303 862 34 13050 22474 35 137 3346 1836 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 11, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(133,134)-(136,137)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] amorph recognizes ne items in two stages : [unused33] dictionary lookup [unused34] and [unused30] rule application [unused31] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 15291 20269 287 3945 121 502 4303 862 34 13050 22474 35 137 31 3346 1836 32 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: CONJUNCTION (id = 4)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 9, 14\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(136,137)-(125,125)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused30] amorph [unused31] recognizes ne items in two stages : dictionary lookup and [unused33] rule application [unused34] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 31 15291 32 20269 287 3945 121 502 4303 862 13050 22474 137 34 3346 1836 35 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 14, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@6::(146,146)-(141,141)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] first , [unused18] it [unused19] uses several kinds of [unused16] diction ##aries [unused17] to segment and tag japanese character strings . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 705 422 19 256 20 3294 1323 7337 131 17 11618 2881 18 147 3197 137 5374 9155 954 13408 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 10, 3\n",
      "11/21/2023 15:53:54 - INFO - run_relation - Average #tokens: 44.54\n",
      "11/21/2023 15:53:54 - INFO - run_relation - Max #tokens: 131\n",
      "11/21/2023 15:53:54 - INFO - run_relation - 4906 (96.92 %) examples can fit max_seq_length = 128\n",
      "11/21/2023 15:53:54 - INFO - run_relation - {'SUBJ_START': '[unused1]', 'SUBJ_END': '[unused2]', 'OBJ_START': '[unused3]', 'OBJ_END': '[unused4]', 'SUBJ=Generic': '[unused5]', 'OBJ=OtherScientificTerm': '[unused6]', 'SUBJ_START=Generic': '[unused7]', 'SUBJ_END=Generic': '[unused8]', 'OBJ_START=OtherScientificTerm': '[unused9]', 'OBJ_END=OtherScientificTerm': '[unused10]', 'OBJ=Material': '[unused11]', 'OBJ_START=Material': '[unused12]', 'OBJ_END=Material': '[unused13]', 'SUBJ=OtherScientificTerm': '[unused14]', 'OBJ=Generic': '[unused15]', 'SUBJ_START=OtherScientificTerm': '[unused16]', 'SUBJ_END=OtherScientificTerm': '[unused17]', 'OBJ_START=Generic': '[unused18]', 'OBJ_END=Generic': '[unused19]', 'SUBJ=Material': '[unused20]', 'SUBJ_START=Material': '[unused21]', 'SUBJ_END=Material': '[unused22]', 'OBJ=Task': '[unused23]', 'OBJ_START=Task': '[unused24]', 'OBJ_END=Task': '[unused25]', 'SUBJ=Task': '[unused26]', 'SUBJ_START=Task': '[unused27]', 'SUBJ_END=Task': '[unused28]', 'OBJ=Method': '[unused29]', 'OBJ_START=Method': '[unused30]', 'OBJ_END=Method': '[unused31]', 'SUBJ=Method': '[unused32]', 'SUBJ_START=Method': '[unused33]', 'SUBJ_END=Method': '[unused34]', 'OBJ=Metric': '[unused35]', 'OBJ_START=Metric': '[unused36]', 'OBJ_END=Metric': '[unused37]', 'SUBJ=Metric': '[unused38]', 'SUBJ_START=Metric': '[unused39]', 'SUBJ_END=Metric': '[unused40]'}\n",
      "11/21/2023 15:53:54 - INFO - run_relation - ***** Test *****\n",
      "11/21/2023 15:53:54 - INFO - run_relation -   Num examples = 5062\n",
      "11/21/2023 15:53:54 - INFO - run_relation -   Batch size = 8\n",
      "11/21/2023 15:53:54 - INFO - transformers.configuration_utils - loading configuration file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/config.json\n",
      "11/21/2023 15:53:54 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/21/2023 15:53:54 - INFO - transformers.modeling_utils - loading weights file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/pytorch_model.bin\n",
      "11/21/2023 15:53:57 - INFO - transformers.modeling_utils - All model checkpoint weights were used when initializing BertForRelation.\n",
      "\n",
      "11/21/2023 15:53:57 - INFO - transformers.modeling_utils - All the weights of BertForRelation were initialized from the model checkpoint at C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForRelation for predictions without further training.\n",
      "11/21/2023 15:56:58 - INFO - run_relation - ***** Eval results *****\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   accuracy = 0.8557882259976294\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   eval_loss = 0.4450051788046462\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_correct = 651\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_gold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_pred = 1124\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   precision = 0.5791814946619217\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_ngold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation - *** Evaluation Results ***\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   accuracy = 0.8557882259976294\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   eval_loss = 0.4450051788046462\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_correct = 651\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_gold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_pred = 1124\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   precision = 0.5791814946619217\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_ngold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation - Output predictions to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/predictions.json..\n"
     ]
    }
   ],
   "source": [
    "if do_eval:\n",
    "    logger.info(special_tokens)\n",
    "    if eval_test:\n",
    "        eval_dataset = test_dataset\n",
    "        eval_examples = test_examples\n",
    "        eval_features = convert_examples_to_features(\n",
    "            test_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "        eval_nrel = test_nrel\n",
    "        logger.info(special_tokens)\n",
    "        logger.info(\"***** Test *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(test_examples))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "        all_sub_idx = torch.tensor([f.sub_idx for f in eval_features], dtype=torch.long)\n",
    "        all_obj_idx = torch.tensor([f.obj_idx for f in eval_features], dtype=torch.long)\n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "        eval_dataloader = DataLoader(eval_data, batch_size=eval_batch_size)\n",
    "        eval_label_ids = all_label_ids\n",
    "    model = RelationModel.from_pretrained(output_dir, num_rel_labels=num_labels)\n",
    "    model.to(device)\n",
    "    preds, result, logits = evaluate(model, device, eval_dataloader, eval_label_ids, num_labels, e2e_ngold=eval_nrel)\n",
    "\n",
    "    logger.info('*** Evaluation Results ***')\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "\n",
    "    print_pred_json(eval_dataset, eval_examples, preds, id2label, os.path.join(output_dir, prediction_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50470f7b-ef69-4d60-9242-d0a904d0e493",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "**Accuracy**: 0.8558\n",
    "\n",
    "**Evaluation Loss**: 0.4450\n",
    "\n",
    "**Precision**: 0.5792\\\n",
    "**Recall**: 0.6684\\\n",
    "**F1 Score**: 0.6206\n",
    "\n",
    "Implications:\n",
    "\n",
    "- The model achieved a relatively high overall accuracy, indicating strong performance in predicting entity relations.\n",
    "- The F1 score suggests a reasonable balance between precision and recall, with room for improvement.\n",
    "- The precision of 57.92% indicates that when the model predicts a relation, it is correct around 57.92% of the time.\n",
    "- The recall of 66.84% suggests that the model is capturing a substantial proportion of the actual relations.\n",
    "- The task-specific F1 score and recall metrics further emphasize the model's performance on the relation extraction task.\n",
    "\n",
    "In summary, the model is performing well in identifying entity relations, but there is still room for improvement, particularly in precision. The results provide insights into how well the model is generalizing to unseen data and its effectiveness in extracting relations between entities. Fine-tuning or adjusting the model architecture may be considered to further improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa672984-577c-4c9c-a214-b256ce534888",
   "metadata": {},
   "source": [
    "## Training and evaluating the relation model from scratch\n",
    "\n",
    "Now we train our own relation model from scratch on the same dataset. And then we will evaluate it using the test data nad compare its performance to the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc5523e5-6ffd-4b2c-91ba-0216ffd5503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'allenai/scibert_scivocab_uncased'\n",
    "add_new_tokens = False\n",
    "no_cuda = False\n",
    "do_train = True\n",
    "do_eval = True\n",
    "eval_test = True\n",
    "do_lower_case = True\n",
    "entity_output_dir = os.getcwd() + '/scierc_models/from-scratch/ent-scib-ctx0/'\n",
    "entity_predictions_dev = 'ent_pred_dev.json'\n",
    "eval_with_gold = True\n",
    "context_window = 0\n",
    "max_seq_length = 128\n",
    "entity_predictions_test = 'ent_pred_test.json'\n",
    "seed = 0\n",
    "output_dir = os.getcwd() + '/scierc_models/from-scratch/rel-scib-ctx0/'\n",
    "negative_label = 'no_relation'\n",
    "task = 'scierc'\n",
    "train_mode = 'random_sorted'\n",
    "train_batch_size = 8\n",
    "eval_batch_size = 8\n",
    "num_train_epochs = 10\n",
    "train_file = \"/scierc_data/processed_data/json/train.json\"\n",
    "eval_per_epoch = 10\n",
    "learning_rate = 2e-5\n",
    "prediction_file = 'predictions.json'\n",
    "BertLayerNorm = torch.nn.LayerNorm\n",
    "train_mode = 'random_sorted'\n",
    "bertadam = True\n",
    "warmup_proportion = 0.1\n",
    "eval_metric = 'f1'\n",
    "task_rel_labels = {\n",
    "    'ace04': ['PER-SOC', 'OTHER-AFF', 'ART', 'GPE-AFF', 'EMP-ORG', 'PHYS'],\n",
    "    'ace05': ['ART', 'ORG-AFF', 'GEN-AFF', 'PHYS', 'PER-SOC', 'PART-WHOLE'],\n",
    "    'scierc': ['PART-OF', 'USED-FOR', 'FEATURE-OF', 'CONJUNCTION', 'EVALUATE-FOR', 'HYPONYM-OF', 'COMPARE'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "192a1638-1eb6-4545-85b1-7de7ac71d2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/25/2023 19:32:21 - INFO - run_relation - Generate relation data from /scierc_data/processed_data/json/train.json\n",
      "11/25/2023 19:32:22 - INFO - run_relation - #samples: 16872, max #sent.samples: 156\n",
      "11/25/2023 19:32:22 - INFO - run_relation - Generate relation data from C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/ent_pred_dev.json\n",
      "11/25/2023 19:32:22 - INFO - run_relation - #samples: 2488, max #sent.samples: 110\n",
      "11/25/2023 19:32:22 - INFO - run_relation - Generate relation data from C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/ent_pred_test.json\n",
      "11/25/2023 19:32:22 - INFO - run_relation - #samples: 5062, max #sent.samples: 156\n",
      "11/25/2023 19:32:24 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "11/25/2023 19:32:24 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/25/2023 19:32:24 - INFO - transformers.tokenization_utils_base - Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/25/2023 19:32:27 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/vocab.txt from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\e3debd8fbdf40874753724814ee0520f612b577b26c8755bca485103b47cd3bc.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
      "11/25/2023 19:32:27 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/added_tokens.json from cache at None\n",
      "11/25/2023 19:32:27 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/special_tokens_map.json from cache at None\n",
      "11/25/2023 19:32:27 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer_config.json from cache at None\n",
      "11/25/2023 19:32:27 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer.json from cache at None\n",
      "11/25/2023 19:32:27 - INFO - run_relation - Writing example 0 of 2488\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@0::(4,4)-(6,17)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] this paper presents an [unused7] algorithm [unused8] for [unused9] computing optical flow , shape , motion , lighting , and alb ##ed ##o [unused10] from an image sequence of a rigid ##ly - moving lamb ##ert ##ian object under distant illumination . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 238 1203 4400 130 8 1172 9 168 10 3743 3451 1505 422 3540 422 3212 422 16703 422 137 6160 119 30112 11 263 130 1572 1733 131 106 9968 179 579 5492 16282 2813 1026 2567 604 11067 11566 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 5, 9\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@0::(4,4)-(20,21)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] this paper presents an [unused7] algorithm [unused8] for computing optical flow , shape , motion , lighting , and alb ##ed ##o from an [unused12] image sequence [unused13] of a rigid ##ly - moving lamb ##ert ##ian object under distant illumination . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 238 1203 4400 130 8 1172 9 168 3743 3451 1505 422 3540 422 3212 422 16703 422 137 6160 119 30112 263 130 13 1572 1733 14 131 106 9968 179 579 5492 16282 2813 1026 2567 604 11067 11566 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 5, 25\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@0::(4,4)-(24,26)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] this paper presents an [unused7] algorithm [unused8] for computing optical flow , shape , motion , lighting , and alb ##ed ##o from an image sequence of a [unused12] rigid ##ly - moving lamb ##ert ##ian object [unused13] under distant illumination . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 238 1203 4400 130 8 1172 9 168 3743 3451 1505 422 3540 422 3212 422 16703 422 137 6160 119 30112 263 130 1572 1733 131 106 13 9968 179 579 5492 16282 2813 1026 2567 14 604 11067 11566 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 5, 29\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@0::(4,4)-(28,29)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] this paper presents an [unused7] algorithm [unused8] for computing optical flow , shape , motion , lighting , and alb ##ed ##o from an image sequence of a rigid ##ly - moving lamb ##ert ##ian object under [unused15] distant illumination [unused16] . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 238 1203 4400 130 8 1172 9 168 3743 3451 1505 422 3540 422 3212 422 16703 422 137 6160 119 30112 263 130 1572 1733 131 106 9968 179 579 5492 16282 2813 1026 2567 604 16 11067 11566 17 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 5, 38\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@0::(6,17)-(4,4)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] this paper presents an [unused21] algorithm [unused22] for [unused19] computing optical flow , shape , motion , lighting , and alb ##ed ##o [unused20] from an image sequence of a rigid ##ly - moving lamb ##ert ##ian object under distant illumination . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 238 1203 4400 130 22 1172 23 168 20 3743 3451 1505 422 3540 422 3212 422 16703 422 137 6160 119 30112 21 263 130 1572 1733 131 106 9968 179 579 5492 16282 2813 1026 2567 604 11067 11566 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 9, 5\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@0::(20,21)-(4,4)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] this paper presents an [unused21] algorithm [unused22] for computing optical flow , shape , motion , lighting , and alb ##ed ##o from an [unused24] image sequence [unused25] of a rigid ##ly - moving lamb ##ert ##ian object under distant illumination . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 238 1203 4400 130 22 1172 23 168 3743 3451 1505 422 3540 422 3212 422 16703 422 137 6160 119 30112 263 130 25 1572 1733 26 131 106 9968 179 579 5492 16282 2813 1026 2567 604 11067 11566 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 25, 5\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@0::(24,26)-(20,21)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] this paper presents an algorithm for computing optical flow , shape , motion , lighting , and alb ##ed ##o from an [unused12] image sequence [unused13] of a [unused24] rigid ##ly - moving lamb ##ert ##ian object [unused25] under distant illumination . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 238 1203 4400 130 1172 168 3743 3451 1505 422 3540 422 3212 422 16703 422 137 6160 119 30112 263 130 13 1572 1733 14 131 106 25 9968 179 579 5492 16282 2813 1026 2567 26 604 11067 11566 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: FEATURE-OF (id = 3)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 29, 23\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@0::(28,29)-(24,26)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] this paper presents an algorithm for computing optical flow , shape , motion , lighting , and alb ##ed ##o from an image sequence of a [unused12] rigid ##ly - moving lamb ##ert ##ian object [unused13] under [unused27] distant illumination [unused28] . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 238 1203 4400 130 1172 168 3743 3451 1505 422 3540 422 3212 422 16703 422 137 6160 119 30112 263 130 1572 1733 131 106 13 9968 179 579 5492 16282 2813 1026 2567 14 604 28 11067 11566 29 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: FEATURE-OF (id = 3)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 38, 27\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@1::(42,42)-(44,45)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the problem is formulated in a manner that subs ##umes structure from [unused24] motion [unused25] , [unused12] multi - view stereo [unused13] , and photo - metric stereo as special cases . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 1167 165 10550 121 106 4328 198 1763 18117 1187 263 25 3212 26 422 13 869 579 1791 17052 14 422 137 8830 579 3947 17052 188 2618 1299 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: CONJUNCTION (id = 4)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 13, 17\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@1::(44,45)-(48,49)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the problem is formulated in a manner that subs ##umes structure from motion , [unused24] multi - view stereo [unused25] , and [unused12] photo - metric stereo [unused13] as special cases . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 1167 165 10550 121 106 4328 198 1763 18117 1187 263 3212 422 25 869 579 1791 17052 26 422 137 13 8830 579 3947 17052 14 188 2618 1299 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: CONJUNCTION (id = 4)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 15, 23\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@2::(58,62)-(55,55)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the [unused21] algorithm [unused22] utilizes both [unused27] spatial and temporal intensity variation [unused28] as cues : the former constrain ##s flow and the latter constrain ##s surface orientation ; combining both cues enables dense reconstruction of both texture ##d and texture - less surfaces . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 22 1172 23 15915 655 28 2829 137 3930 3165 2835 29 188 9190 862 111 6347 2273 30113 1505 137 111 4085 2273 30113 1437 5135 1814 6484 655 9190 7016 8505 5837 131 655 8690 30118 137 8690 579 1279 5347 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 7, 2\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@2::(67,67)-(64,64)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the algorithm utilizes both spatial and temporal intensity variation as [unused21] cues [unused22] : the [unused7] former [unused8] constrain ##s flow and the latter constrain ##s surface orientation ; combining both cues enables dense reconstruction of both texture ##d and texture - less surfaces . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 1172 15915 655 2829 137 3930 3165 2835 188 22 9190 23 862 111 8 6347 9 2273 30113 1505 137 111 4085 2273 30113 1437 5135 1814 6484 655 9190 7016 8505 5837 131 655 8690 30118 137 8690 579 1279 5347 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: HYPONYM-OF (id = 6)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 16, 11\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@2::(67,67)-(69,69)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the algorithm utilizes both spatial and temporal intensity variation as cues : the [unused7] former [unused8] constrain ##s [unused15] flow [unused16] and the latter constrain ##s surface orientation ; combining both cues enables dense reconstruction of both texture ##d and texture - less surfaces . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 1172 15915 655 2829 137 3930 3165 2835 188 9190 862 111 8 6347 9 2273 30113 16 1505 17 137 111 4085 2273 30113 1437 5135 1814 6484 655 9190 7016 8505 5837 131 655 8690 30118 137 8690 579 1279 5347 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 14, 19\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@2::(67,67)-(72,72)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the algorithm utilizes both spatial and temporal intensity variation as cues : the [unused7] former [unused8] constrain ##s flow and the [unused21] latter [unused22] constrain ##s surface orientation ; combining both cues enables dense reconstruction of both texture ##d and texture - less surfaces . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 1172 15915 655 2829 137 3930 3165 2835 188 9190 862 111 8 6347 9 2273 30113 1505 137 111 22 4085 23 2273 30113 1437 5135 1814 6484 655 9190 7016 8505 5837 131 655 8690 30118 137 8690 579 1279 5347 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: CONJUNCTION (id = 4)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 14, 22\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@2::(72,72)-(64,64)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the algorithm utilizes both spatial and temporal intensity variation as [unused21] cues [unused22] : the former constrain ##s flow and the [unused7] latter [unused8] constrain ##s surface orientation ; combining both cues enables dense reconstruction of both texture ##d and texture - less surfaces . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 1172 15915 655 2829 137 3930 3165 2835 188 22 9190 23 862 111 6347 2273 30113 1505 137 111 8 4085 9 2273 30113 1437 5135 1814 6484 655 9190 7016 8505 5837 131 655 8690 30118 137 8690 579 1279 5347 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: HYPONYM-OF (id = 6)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 22, 11\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@2::(72,72)-(74,75)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the algorithm utilizes both spatial and temporal intensity variation as cues : the former constrain ##s flow and the [unused7] latter [unused8] constrain ##s [unused15] surface orientation [unused16] ; combining both cues enables dense reconstruction of both texture ##d and texture - less surfaces . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 1172 15915 655 2829 137 3930 3165 2835 188 9190 862 111 6347 2273 30113 1505 137 111 8 4085 9 2273 30113 16 1437 5135 17 1814 6484 655 9190 7016 8505 5837 131 655 8690 30118 137 8690 579 1279 5347 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 20, 25\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@2::(79,79)-(81,88)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the algorithm utilizes both spatial and temporal intensity variation as cues : the former constrain ##s flow and the latter constrain ##s surface orientation ; combining both [unused7] cues [unused8] enables [unused9] dense reconstruction of both texture ##d and texture - less surfaces [unused10] . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 1172 15915 655 2829 137 3930 3165 2835 188 9190 862 111 6347 2273 30113 1505 137 111 4085 2273 30113 1437 5135 1814 6484 655 8 9190 9 7016 10 8505 5837 131 655 8690 30118 137 8690 579 1279 5347 11 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 28, 32\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: ICCV_2003_158_abs@3::(95,105)-(91,91)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] the [unused21] algorithm [unused22] works by iteratively [unused33] estimating affine camera parameters , illumination , shape , and alb ##ed ##o [unused34] in an alternating fashion . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 111 22 1172 23 4603 214 18755 34 8396 15010 5859 1496 422 11566 422 3540 422 137 6160 119 30112 35 121 130 15529 8813 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 8, 2\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: P84-1047@0::(1,2)-(4,5)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] an [unused33] entity - oriented approach [unused34] to [unused9] restricted - domain parsing [unused10] is proposed . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 130 34 8494 579 9077 1139 35 147 10 5807 579 2059 19248 11 165 1337 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 2, 9\n",
      "11/25/2023 19:32:27 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:27 - INFO - run_relation - guid: P84-1047@2::(32,32)-(37,39)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - tokens: [CLS] like semantic grammar , [unused7] this [unused8] allows easy exploitation of [unused15] limited domain semantics [unused16] . [SEP]\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_ids: 102 1967 5437 13436 422 8 238 9 2890 4578 17487 131 16 2379 2059 7816 17 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:27 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:27 - INFO - run_relation - sub_idx, obj_idx: 5, 12\n",
      "11/25/2023 19:32:31 - INFO - run_relation - Average #tokens: 45.18\n",
      "11/25/2023 19:32:31 - INFO - run_relation - Max #tokens: 114\n",
      "11/25/2023 19:32:31 - INFO - run_relation - 2488 (100.00 %) examples can fit max_seq_length = 128\n",
      "11/25/2023 19:32:31 - INFO - run_relation - ***** Dev *****\n",
      "11/25/2023 19:32:31 - INFO - run_relation -   Num examples = 2488\n",
      "11/25/2023 19:32:31 - INFO - run_relation -   Batch size = 8\n",
      "11/25/2023 19:32:31 - INFO - run_relation - Writing example 0 of 16872\n",
      "11/25/2023 19:32:31 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:31 - INFO - run_relation - guid: J87-1003@0::(0,0)-(10,10)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - tokens: [CLS] [unused24] english [unused25] is shown to be trans - context - free on the basis of [unused15] coordination ##s [unused16] of the respectively type that involve strictly syntactic cross - serial agreement . [SEP]\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_ids: 102 25 6170 26 165 817 147 195 428 579 2220 579 2159 191 111 2525 131 16 7395 30113 17 131 111 1222 1211 198 3862 8503 13510 2057 579 8595 4111 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - sub_idx, obj_idx: 1, 17\n",
      "11/25/2023 19:32:31 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:31 - INFO - run_relation - guid: J87-1003@0::(0,0)-(17,20)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - tokens: [CLS] [unused24] english [unused25] is shown to be trans - context - free on the basis of coordination ##s of the respectively type that involve [unused15] strictly syntactic cross - serial agreement [unused16] . [SEP]\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_ids: 102 25 6170 26 165 817 147 195 428 579 2220 579 2159 191 111 2525 131 7395 30113 131 111 1222 1211 198 3862 16 8503 13510 2057 579 8595 4111 17 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - sub_idx, obj_idx: 1, 25\n",
      "11/25/2023 19:32:31 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:31 - INFO - run_relation - guid: J87-1003@0::(10,10)-(0,0)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - tokens: [CLS] [unused12] english [unused13] is shown to be trans - context - free on the basis of [unused27] coordination ##s [unused28] of the respectively type that involve strictly syntactic cross - serial agreement . [SEP]\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_ids: 102 13 6170 14 165 817 147 195 428 579 2220 579 2159 191 111 2525 131 28 7395 30113 29 131 111 1222 1211 198 3862 8503 13510 2057 579 8595 4111 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - sub_idx, obj_idx: 17, 1\n",
      "11/25/2023 19:32:31 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:31 - INFO - run_relation - guid: J87-1003@0::(10,10)-(17,20)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - tokens: [CLS] english is shown to be trans - context - free on the basis of [unused27] coordination ##s [unused28] of the respectively type that involve [unused15] strictly syntactic cross - serial agreement [unused16] . [SEP]\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_ids: 102 6170 165 817 147 195 428 579 2220 579 2159 191 111 2525 131 28 7395 30113 29 131 111 1222 1211 198 3862 16 8503 13510 2057 579 8595 4111 17 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - sub_idx, obj_idx: 15, 25\n",
      "11/25/2023 19:32:31 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:31 - INFO - run_relation - guid: J87-1003@0::(17,20)-(0,0)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - tokens: [CLS] [unused12] english [unused13] is shown to be trans - context - free on the basis of coordination ##s of the respectively type that involve [unused27] strictly syntactic cross - serial agreement [unused28] . [SEP]\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_ids: 102 13 6170 14 165 817 147 195 428 579 2220 579 2159 191 111 2525 131 7395 30113 131 111 1222 1211 198 3862 28 8503 13510 2057 579 8595 4111 29 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - sub_idx, obj_idx: 25, 1\n",
      "11/25/2023 19:32:31 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:31 - INFO - run_relation - guid: J87-1003@1::(29,29)-(31,32)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - tokens: [CLS] the agreement in question involves number in [unused27] nouns [unused28] and [unused15] reflex ##ive pronoun ##s [unused16] and is syntactic rather than semantic in nature because grammatical number in english , like grammatical gender in languages such as french , is partly arbitrary . [SEP]\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_ids: 102 111 4111 121 2214 5185 649 121 28 24748 29 137 16 11229 1090 29213 30113 17 137 165 13510 2316 506 5437 121 2540 923 22956 649 121 6170 422 1967 22956 4703 121 6554 555 188 10282 422 165 9632 5765 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:31 - INFO - run_relation - label: CONJUNCTION (id = 4)\n",
      "11/25/2023 19:32:31 - INFO - run_relation - sub_idx, obj_idx: 8, 12\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: J87-1003@1::(48,49)-(51,51)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] the agreement in question involves number in nouns and reflex ##ive pronoun ##s and is syntactic rather than semantic in nature because grammatical number in english , like [unused27] grammatical gender [unused28] in [unused12] languages [unused13] such as french , is partly arbitrary . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 111 4111 121 2214 5185 649 121 24748 137 11229 1090 29213 30113 137 165 13510 2316 506 5437 121 2540 923 22956 649 121 6170 422 1967 28 22956 4703 29 121 13 6554 14 555 188 10282 422 165 9632 5765 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: FEATURE-OF (id = 3)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 29, 34\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: J87-1003@1::(54,54)-(51,51)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] the agreement in question involves number in nouns and reflex ##ive pronoun ##s and is syntactic rather than semantic in nature because grammatical number in english , like grammatical gender in [unused12] languages [unused13] such as [unused24] french [unused25] , is partly arbitrary . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 111 4111 121 2214 5185 649 121 24748 137 11229 1090 29213 30113 137 165 13510 2316 506 5437 121 2540 923 22956 649 121 6170 422 1967 22956 4703 121 13 6554 14 555 188 25 10282 26 422 165 9632 5765 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: HYPONYM-OF (id = 6)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 37, 32\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@0::(6,6)-(10,12)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] in this paper , a novel [unused33] method [unused34] to learn the [unused15] intrinsic object structure [unused16] for robust visual tracking is proposed . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 121 238 1203 422 106 3045 34 551 35 147 6714 111 16 7157 2567 1187 17 168 3701 2180 5472 165 1337 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 7, 13\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@0::(10,12)-(14,16)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] in this paper , a novel method to learn the [unused27] intrinsic object structure [unused28] for [unused9] robust visual tracking [unused10] is proposed . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 121 238 1203 422 106 3045 551 147 6714 111 28 7157 2567 1187 29 168 10 3701 2180 5472 11 165 1337 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 11, 17\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@1::(32,34)-(26,28)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] the basic assumption is that the [unused15] parameterized object state [unused16] lies on a [unused27] low dimensional manifold [unused28] and can be learned from training data . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 111 2886 3886 165 198 111 16 20197 2567 1098 17 8445 191 106 28 629 8176 11257 29 137 300 195 8709 263 2208 453 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: FEATURE-OF (id = 3)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 15, 7\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@2::(52,57)-(59,64)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] based on this assumption , firstly we derived the [unused33] dimensionality reduction and density estimation algorithm [unused34] for [unused9] unsupervised learning of object intrinsic representation [unused10] , the obtained non - rigid part of object state reduces even to 2 dimensions . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 791 191 238 3886 422 9693 185 2865 111 34 16092 2135 137 2027 3261 1172 35 168 10 18391 1904 131 2567 7157 3207 11 422 111 1151 699 579 9968 1188 131 2567 1098 5174 1390 147 170 4795 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 10, 19\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@3::(90,91)-(81,82)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] secondly the [unused30] dynamical model [unused31] is derived and trained based on this [unused33] intrinsic representation [unused34] . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 11310 111 31 10245 437 32 165 2865 137 7222 791 191 238 34 7157 3207 35 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 14, 3\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@4::(96,98)-(103,105)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] thirdly the learned [unused27] intrinsic object structure [unused28] is integrated into a [unused30] particle - filter style tracker [unused31] . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 27068 111 8709 28 7157 2567 1187 29 165 4240 690 106 31 4166 579 3499 9702 23745 32 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 4, 13\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@5::(126,127)-(129,131)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] we will show that this intrinsic object representation has some interesting properties and based on which the newly derived [unused33] dynamical model [unused34] makes [unused30] particle - filter style tracker [unused31] more robust and reliable . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 185 650 405 198 238 7157 2567 3207 434 693 3016 1784 137 791 191 334 111 7737 2865 34 10245 437 35 3740 31 4166 579 3499 9702 23745 32 475 3701 137 5504 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 20, 25\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@6::(142,142)-(148,148)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] experiments show that the learned [unused7] tracker [unused8] performs much better than existing [unused21] tracker ##s [unused22] on the tracking of complex non - rigid motions such as fish twist ##ing with self - occlusion and large inter - frame lip motion . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 1713 405 198 111 8709 8 23745 9 8629 1839 1883 506 3302 22 23745 30113 23 191 111 5472 131 1127 699 579 9968 13318 555 188 4450 18193 140 190 1968 579 10201 137 1135 357 579 4037 2266 3212 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: COMPARE (id = 7)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 6, 14\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@6::(142,142)-(151,155)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] experiments show that the learned [unused7] tracker [unused8] performs much better than existing tracker ##s on the [unused9] tracking of complex non - rigid motions [unused10] such as fish twist ##ing with self - occlusion and large inter - frame lip motion . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 1713 405 198 111 8709 8 23745 9 8629 1839 1883 506 3302 23745 30113 191 111 10 5472 131 1127 699 579 9968 13318 11 555 188 4450 18193 140 190 1968 579 10201 137 1135 357 579 4037 2266 3212 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 6, 18\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@6::(148,148)-(151,155)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] experiments show that the learned tracker performs much better than existing [unused7] tracker ##s [unused8] on the [unused9] tracking of complex non - rigid motions [unused10] such as fish twist ##ing with self - occlusion and large inter - frame lip motion . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 1713 405 198 111 8709 23745 8629 1839 1883 506 3302 8 23745 30113 9 191 111 10 5472 131 1127 699 579 9968 13318 11 555 188 4450 18193 140 190 1968 579 10201 137 1135 357 579 4037 2266 3212 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 12, 18\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@6::(158,159)-(153,155)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] experiments show that the learned tracker performs much better than existing tracker ##s on the tracking of [unused15] complex non - rigid motions [unused16] such as [unused27] fish twist ##ing [unused28] with self - occlusion and large inter - frame lip motion . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 1713 405 198 111 8709 23745 8629 1839 1883 506 3302 23745 30113 191 111 5472 131 16 1127 699 579 9968 13318 17 555 188 28 4450 18193 140 29 190 1968 579 10201 137 1135 357 579 4037 2266 3212 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: HYPONYM-OF (id = 6)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 27, 18\n",
      "11/25/2023 19:32:32 - INFO - run_relation - *** Example ***\n",
      "11/25/2023 19:32:32 - INFO - run_relation - guid: CVPR_2003_18_abs@6::(161,161)-(158,159)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - tokens: [CLS] experiments show that the learned tracker performs much better than existing tracker ##s on the tracking of complex non - rigid motions such as [unused15] fish twist ##ing [unused16] with [unused27] self - occlusion [unused28] and large inter - frame lip motion . [SEP]\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_ids: 102 1713 405 198 111 8709 23745 8629 1839 1883 506 3302 23745 30113 191 111 5472 131 1127 699 579 9968 13318 555 188 16 4450 18193 140 17 190 28 1968 579 10201 29 137 1135 357 579 4037 2266 3212 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/25/2023 19:32:32 - INFO - run_relation - label: FEATURE-OF (id = 3)\n",
      "11/25/2023 19:32:32 - INFO - run_relation - sub_idx, obj_idx: 31, 25\n",
      "11/25/2023 19:32:49 - INFO - run_relation - Writing example 10000 of 16872\n",
      "11/25/2023 19:33:01 - INFO - run_relation - Average #tokens: 44.61\n",
      "11/25/2023 19:33:01 - INFO - run_relation - Max #tokens: 120\n",
      "11/25/2023 19:33:01 - INFO - run_relation - 16872 (100.00 %) examples can fit max_seq_length = 128\n",
      "11/25/2023 19:33:02 - INFO - run_relation - ***** Training *****\n",
      "11/25/2023 19:33:02 - INFO - run_relation -   Num examples = 16872\n",
      "11/25/2023 19:33:02 - INFO - run_relation -   Batch size = 8\n",
      "11/25/2023 19:33:02 - INFO - run_relation -   Num steps = 21090\n",
      "11/25/2023 19:33:02 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "11/25/2023 19:33:02 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/25/2023 19:33:03 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/allenai/scibert_scivocab_uncased/pytorch_model.bin from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\54e18c298451d3195ba8359e7a3fa2bc04c70c730c5b6744928278e67940eacb.7587182ea55c40bf7fd0961c1176c31fa22558da2bf20c199874fa5a8ecb4613\n",
      "11/25/2023 19:33:06 - WARNING - transformers.modeling_utils - Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForRelation: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForRelation from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForRelation from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "11/25/2023 19:33:06 - WARNING - transformers.modeling_utils - Some weights of BertForRelation were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['layer_norm.weight', 'layer_norm.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "11/25/2023 19:33:11 - INFO - run_relation - Start epoch #0 (lr = 2e-05)...\n",
      "11/25/2023 19:36:21 - INFO - run_relation - Epoch: 0, Step: 210 / 2109, used_time = 189.58s, loss = 1.161151\n",
      "11/25/2023 19:37:50 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 19:37:50 - INFO - run_relation -   accuracy = 0.8155144694533762\n",
      "11/25/2023 19:37:50 - INFO - run_relation -   eval_loss = 0.7591630700508498\n",
      "11/25/2023 19:37:50 - INFO - run_relation -   f1 = 0.0\n",
      "11/25/2023 19:37:50 - INFO - run_relation -   precision = 0.0\n",
      "11/25/2023 19:37:50 - INFO - run_relation -   recall = 0.0\n",
      "11/25/2023 19:37:50 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=0): 0.00\n",
      "11/25/2023 19:37:50 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 19:40:59 - INFO - run_relation - Epoch: 0, Step: 420 / 2109, used_time = 467.36s, loss = 0.956502\n",
      "11/25/2023 19:42:26 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   accuracy = 0.8179260450160771\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   eval_loss = 0.6665025332349673\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   f1 = 0.08800000000000001\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   n_correct = 22\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   n_pred = 45\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   precision = 0.4888888888888889\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   recall = 0.04835164835164835\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   task_f1 = 0.08800000000000001\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 19:42:26 - INFO - run_relation -   task_recall = 0.04835164835164835\n",
      "11/25/2023 19:42:26 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=0): 8.80\n",
      "11/25/2023 19:42:26 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 19:45:33 - INFO - run_relation - Epoch: 0, Step: 630 / 2109, used_time = 741.51s, loss = 0.845186\n",
      "11/25/2023 19:47:01 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   accuracy = 0.8227491961414791\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   eval_loss = 0.6142383741508343\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   f1 = 0.09426229508196722\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   n_correct = 23\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   n_pred = 33\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   precision = 0.696969696969697\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   recall = 0.05054945054945055\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   task_f1 = 0.09426229508196722\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 19:47:01 - INFO - run_relation -   task_recall = 0.05054945054945055\n",
      "11/25/2023 19:47:01 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=0): 9.43\n",
      "11/25/2023 19:47:01 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 19:50:07 - INFO - run_relation - Epoch: 0, Step: 840 / 2109, used_time = 1015.98s, loss = 0.766845\n",
      "11/25/2023 19:51:34 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   accuracy = 0.8263665594855305\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   eval_loss = 0.5278660122700443\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   f1 = 0.3232628398791541\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   n_correct = 107\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   n_pred = 207\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   precision = 0.5169082125603864\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   recall = 0.23516483516483516\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   task_f1 = 0.3232628398791541\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 19:51:34 - INFO - run_relation -   task_recall = 0.23516483516483516\n",
      "11/25/2023 19:51:34 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=0): 32.33\n",
      "11/25/2023 19:51:34 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 19:54:41 - INFO - run_relation - Epoch: 0, Step: 1050 / 2109, used_time = 1289.82s, loss = 0.728330\n",
      "11/25/2023 19:56:08 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   accuracy = 0.842443729903537\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   eval_loss = 0.4889741634345131\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   f1 = 0.4944375772558715\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   n_correct = 200\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   n_pred = 354\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   precision = 0.5649717514124294\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   recall = 0.43956043956043955\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   task_f1 = 0.4944375772558715\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 19:56:08 - INFO - run_relation -   task_recall = 0.43956043956043955\n",
      "11/25/2023 19:56:08 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=0): 49.44\n",
      "11/25/2023 19:56:08 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 19:59:15 - INFO - run_relation - Epoch: 0, Step: 1260 / 2109, used_time = 1563.42s, loss = 0.691107\n",
      "11/25/2023 20:00:42 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   accuracy = 0.8436495176848875\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   eval_loss = 0.4789063580741453\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   f1 = 0.41799709724238027\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   n_correct = 144\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   n_pred = 234\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   precision = 0.6153846153846154\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   recall = 0.31648351648351647\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   task_f1 = 0.41799709724238027\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:00:42 - INFO - run_relation -   task_recall = 0.31648351648351647\n",
      "11/25/2023 20:03:48 - INFO - run_relation - Epoch: 0, Step: 1470 / 2109, used_time = 1836.27s, loss = 0.665789\n",
      "11/25/2023 20:05:15 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   accuracy = 0.8484726688102894\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   eval_loss = 0.44326661024062963\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   f1 = 0.5147783251231527\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   n_correct = 209\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   n_pred = 357\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   precision = 0.5854341736694678\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   recall = 0.4593406593406593\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   task_f1 = 0.5147783251231527\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:05:15 - INFO - run_relation -   task_recall = 0.4593406593406593\n",
      "11/25/2023 20:05:15 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=0): 51.48\n",
      "11/25/2023 20:05:15 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 20:08:22 - INFO - run_relation - Epoch: 0, Step: 1680 / 2109, used_time = 2110.76s, loss = 0.640178\n",
      "11/25/2023 20:09:49 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   accuracy = 0.829983922829582\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   eval_loss = 0.4961342557641854\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   f1 = 0.5641025641025641\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   n_correct = 297\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   n_pred = 598\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   precision = 0.49665551839464883\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   recall = 0.6527472527472528\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   task_f1 = 0.5641025641025641\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:09:49 - INFO - run_relation -   task_recall = 0.6527472527472528\n",
      "11/25/2023 20:09:49 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=0): 56.41\n",
      "11/25/2023 20:09:49 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 20:12:56 - INFO - run_relation - Epoch: 0, Step: 1890 / 2109, used_time = 2384.27s, loss = 0.620993\n",
      "11/25/2023 20:14:24 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   accuracy = 0.8613344051446945\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   eval_loss = 0.4051703550999571\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   f1 = 0.551640340218712\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   n_correct = 227\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   n_pred = 368\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   precision = 0.6168478260869565\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   recall = 0.4989010989010989\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   task_f1 = 0.551640340218712\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:14:24 - INFO - run_relation -   task_recall = 0.4989010989010989\n",
      "11/25/2023 20:17:30 - INFO - run_relation - Epoch: 0, Step: 2100 / 2109, used_time = 2658.46s, loss = 0.595332\n",
      "11/25/2023 20:18:57 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   accuracy = 0.8613344051446945\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   eval_loss = 0.3919891573225187\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   f1 = 0.5916760404949382\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   n_correct = 263\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   n_pred = 434\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   precision = 0.6059907834101382\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   recall = 0.578021978021978\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   task_f1 = 0.5916760404949382\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:18:57 - INFO - run_relation -   task_recall = 0.578021978021978\n",
      "11/25/2023 20:18:57 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=0): 59.17\n",
      "11/25/2023 20:18:57 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 20:19:05 - INFO - run_relation - Start epoch #1 (lr = 2e-05)...\n",
      "11/25/2023 20:22:11 - INFO - run_relation - Epoch: 1, Step: 210 / 2109, used_time = 2939.92s, loss = 0.573929\n",
      "11/25/2023 20:23:38 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   accuracy = 0.8822347266881029\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   eval_loss = 0.36569906828679455\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   f1 = 0.6172248803827752\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   n_correct = 258\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   n_pred = 381\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   precision = 0.6771653543307087\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   recall = 0.567032967032967\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   task_f1 = 0.6172248803827752\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:23:38 - INFO - run_relation -   task_recall = 0.567032967032967\n",
      "11/25/2023 20:23:38 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=1): 61.72\n",
      "11/25/2023 20:23:38 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 20:26:45 - INFO - run_relation - Epoch: 1, Step: 420 / 2109, used_time = 3213.34s, loss = 0.553159\n",
      "11/25/2023 20:28:12 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   accuracy = 0.8637459807073955\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   eval_loss = 0.4008679322874431\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   f1 = 0.6070287539936102\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   n_correct = 285\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   n_pred = 484\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   precision = 0.5888429752066116\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   recall = 0.6263736263736264\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   task_f1 = 0.6070287539936102\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:28:12 - INFO - run_relation -   task_recall = 0.6263736263736264\n",
      "11/25/2023 20:31:17 - INFO - run_relation - Epoch: 1, Step: 630 / 2109, used_time = 3486.15s, loss = 0.534946\n",
      "11/25/2023 20:32:44 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   accuracy = 0.8741961414790996\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   eval_loss = 0.37290721633426627\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   f1 = 0.6115107913669066\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   n_correct = 255\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   n_pred = 379\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   precision = 0.6728232189973615\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   recall = 0.5604395604395604\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   task_f1 = 0.6115107913669066\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:32:44 - INFO - run_relation -   task_recall = 0.5604395604395604\n",
      "11/25/2023 20:35:50 - INFO - run_relation - Epoch: 1, Step: 840 / 2109, used_time = 3758.93s, loss = 0.519789\n",
      "11/25/2023 20:37:17 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   accuracy = 0.8790192926045016\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   eval_loss = 0.36556825214260263\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   f1 = 0.6360505166475315\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   n_correct = 277\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   n_pred = 416\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   precision = 0.6658653846153846\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   recall = 0.6087912087912087\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   task_f1 = 0.6360505166475315\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:37:17 - INFO - run_relation -   task_recall = 0.6087912087912087\n",
      "11/25/2023 20:37:17 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=1): 63.61\n",
      "11/25/2023 20:37:17 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 20:40:23 - INFO - run_relation - Epoch: 1, Step: 1050 / 2109, used_time = 4032.10s, loss = 0.506070\n",
      "11/25/2023 20:41:50 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   accuracy = 0.8729903536977492\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   eval_loss = 0.36112412345562717\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   f1 = 0.6243032329988852\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   n_correct = 280\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   n_pred = 442\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   precision = 0.6334841628959276\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   recall = 0.6153846153846154\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   task_f1 = 0.6243032329988852\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:41:50 - INFO - run_relation -   task_recall = 0.6153846153846154\n",
      "11/25/2023 20:44:56 - INFO - run_relation - Epoch: 1, Step: 1260 / 2109, used_time = 4304.70s, loss = 0.492496\n",
      "11/25/2023 20:46:23 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   accuracy = 0.8810289389067524\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   eval_loss = 0.3793627021301214\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   f1 = 0.6025\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   n_correct = 241\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   n_pred = 345\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   precision = 0.6985507246376812\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   recall = 0.5296703296703297\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   task_f1 = 0.6025\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:46:23 - INFO - run_relation -   task_recall = 0.5296703296703297\n",
      "11/25/2023 20:49:29 - INFO - run_relation - Epoch: 1, Step: 1470 / 2109, used_time = 4577.24s, loss = 0.482698\n",
      "11/25/2023 20:50:55 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   accuracy = 0.8862540192926045\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   eval_loss = 0.3567043401995656\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   f1 = 0.6462264150943396\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   n_correct = 274\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   n_pred = 393\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   precision = 0.6972010178117048\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   recall = 0.6021978021978022\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   task_f1 = 0.6462264150943396\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:50:55 - INFO - run_relation -   task_recall = 0.6021978021978022\n",
      "11/25/2023 20:50:55 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=1): 64.62\n",
      "11/25/2023 20:50:55 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 20:54:02 - INFO - run_relation - Epoch: 1, Step: 1680 / 2109, used_time = 4850.34s, loss = 0.471880\n",
      "11/25/2023 20:55:29 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   accuracy = 0.8858520900321544\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   eval_loss = 0.36352751741838607\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   f1 = 0.6629955947136563\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   n_correct = 301\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   n_pred = 453\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   precision = 0.6644591611479028\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   recall = 0.6615384615384615\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   task_f1 = 0.6629955947136563\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 20:55:29 - INFO - run_relation -   task_recall = 0.6615384615384615\n",
      "11/25/2023 20:55:29 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=1): 66.30\n",
      "11/25/2023 20:55:29 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 20:58:35 - INFO - run_relation - Epoch: 1, Step: 1890 / 2109, used_time = 5123.40s, loss = 0.463244\n",
      "11/25/2023 21:00:02 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   accuracy = 0.8810289389067524\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   eval_loss = 0.33860889728812926\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   f1 = 0.6121437422552665\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   n_correct = 247\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   n_pred = 352\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   precision = 0.7017045454545454\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   recall = 0.5428571428571428\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   task_f1 = 0.6121437422552665\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:00:02 - INFO - run_relation -   task_recall = 0.5428571428571428\n",
      "11/25/2023 21:03:07 - INFO - run_relation - Epoch: 1, Step: 2100 / 2109, used_time = 5396.11s, loss = 0.453696\n",
      "11/25/2023 21:04:34 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   accuracy = 0.882636655948553\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   eval_loss = 0.3399859010406629\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   f1 = 0.6592674805771365\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   n_correct = 297\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   n_pred = 446\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   precision = 0.6659192825112108\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   recall = 0.6527472527472528\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   task_f1 = 0.6592674805771365\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:04:34 - INFO - run_relation -   task_recall = 0.6527472527472528\n",
      "11/25/2023 21:04:42 - INFO - run_relation - Start epoch #2 (lr = 2e-05)...\n",
      "11/25/2023 21:07:48 - INFO - run_relation - Epoch: 2, Step: 210 / 2109, used_time = 5676.76s, loss = 0.441050\n",
      "11/25/2023 21:09:15 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   accuracy = 0.8822347266881029\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   eval_loss = 0.36899637830985704\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   f1 = 0.6318289786223278\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   n_correct = 266\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   n_pred = 387\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   precision = 0.6873385012919897\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   recall = 0.5846153846153846\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   task_f1 = 0.6318289786223278\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:09:15 - INFO - run_relation -   task_recall = 0.5846153846153846\n",
      "11/25/2023 21:12:21 - INFO - run_relation - Epoch: 2, Step: 420 / 2109, used_time = 5949.59s, loss = 0.428928\n",
      "11/25/2023 21:13:48 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   accuracy = 0.8818327974276527\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   eval_loss = 0.3872766047716141\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   f1 = 0.648471615720524\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   n_correct = 297\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   n_pred = 461\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   precision = 0.6442516268980477\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   recall = 0.6527472527472528\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   task_f1 = 0.648471615720524\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:13:48 - INFO - run_relation -   task_recall = 0.6527472527472528\n",
      "11/25/2023 21:16:54 - INFO - run_relation - Epoch: 2, Step: 630 / 2109, used_time = 6222.28s, loss = 0.417150\n",
      "11/25/2023 21:18:20 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   accuracy = 0.8830385852090032\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   eval_loss = 0.3629020712670789\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   f1 = 0.6539325842696629\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   n_correct = 291\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   n_pred = 435\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   precision = 0.6689655172413793\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   recall = 0.6395604395604395\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   task_f1 = 0.6539325842696629\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:18:20 - INFO - run_relation -   task_recall = 0.6395604395604395\n",
      "11/25/2023 21:21:26 - INFO - run_relation - Epoch: 2, Step: 840 / 2109, used_time = 6494.89s, loss = 0.406683\n",
      "11/25/2023 21:22:53 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   accuracy = 0.8766077170418006\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   eval_loss = 0.3908298556061036\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   f1 = 0.6408839779005525\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   n_correct = 290\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   n_pred = 450\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   precision = 0.6444444444444445\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   recall = 0.6373626373626373\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   task_f1 = 0.6408839779005525\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:22:53 - INFO - run_relation -   task_recall = 0.6373626373626373\n",
      "11/25/2023 21:25:59 - INFO - run_relation - Epoch: 2, Step: 1050 / 2109, used_time = 6767.59s, loss = 0.397962\n",
      "11/25/2023 21:27:26 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   accuracy = 0.8830385852090032\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   eval_loss = 0.3886118945201494\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   f1 = 0.6548279689234184\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   n_correct = 295\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   n_pred = 446\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   precision = 0.6614349775784754\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   recall = 0.6483516483516484\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   task_f1 = 0.6548279689234184\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:27:26 - INFO - run_relation -   task_recall = 0.6483516483516484\n",
      "11/25/2023 21:30:32 - INFO - run_relation - Epoch: 2, Step: 1260 / 2109, used_time = 7040.58s, loss = 0.389875\n",
      "11/25/2023 21:31:59 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   accuracy = 0.8922829581993569\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   eval_loss = 0.34483626647777493\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   f1 = 0.6713124274099883\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   n_correct = 289\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   n_pred = 406\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   precision = 0.7118226600985221\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   recall = 0.6351648351648351\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   task_f1 = 0.6713124274099883\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:31:59 - INFO - run_relation -   task_recall = 0.6351648351648351\n",
      "11/25/2023 21:31:59 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=2): 67.13\n",
      "11/25/2023 21:31:59 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 21:35:05 - INFO - run_relation - Epoch: 2, Step: 1470 / 2109, used_time = 7313.67s, loss = 0.382421\n",
      "11/25/2023 21:36:32 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   accuracy = 0.889871382636656\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   eval_loss = 0.3650192854105468\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   f1 = 0.6674259681093393\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   n_correct = 293\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   n_pred = 423\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   precision = 0.6926713947990544\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   recall = 0.643956043956044\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   task_f1 = 0.6674259681093393\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:36:32 - INFO - run_relation -   task_recall = 0.643956043956044\n",
      "11/25/2023 21:39:38 - INFO - run_relation - Epoch: 2, Step: 1680 / 2109, used_time = 7586.31s, loss = 0.375035\n",
      "11/25/2023 21:41:05 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   accuracy = 0.8866559485530546\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   eval_loss = 0.3758834064773425\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   f1 = 0.6505190311418686\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   n_correct = 282\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   n_pred = 412\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   precision = 0.6844660194174758\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   recall = 0.6197802197802198\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   task_f1 = 0.6505190311418686\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:41:05 - INFO - run_relation -   task_recall = 0.6197802197802198\n",
      "11/25/2023 21:44:15 - INFO - run_relation - Epoch: 2, Step: 1890 / 2109, used_time = 7863.53s, loss = 0.369050\n",
      "11/25/2023 21:45:50 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   accuracy = 0.887459807073955\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   eval_loss = 0.370078640208367\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   f1 = 0.6717724288840263\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   n_correct = 307\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   n_pred = 459\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   precision = 0.6688453159041394\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   recall = 0.6747252747252748\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   task_f1 = 0.6717724288840263\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:45:50 - INFO - run_relation -   task_recall = 0.6747252747252748\n",
      "11/25/2023 21:45:50 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=2): 67.18\n",
      "11/25/2023 21:45:50 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 21:49:10 - INFO - run_relation - Epoch: 2, Step: 2100 / 2109, used_time = 8158.87s, loss = 0.362098\n",
      "11/25/2023 21:50:41 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   accuracy = 0.8834405144694534\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   eval_loss = 0.38925985210961467\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   f1 = 0.6645021645021645\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   n_correct = 307\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   n_pred = 469\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   precision = 0.6545842217484008\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   recall = 0.6747252747252748\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   task_f1 = 0.6645021645021645\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:50:41 - INFO - run_relation -   task_recall = 0.6747252747252748\n",
      "11/25/2023 21:50:50 - INFO - run_relation - Start epoch #3 (lr = 2e-05)...\n",
      "11/25/2023 21:54:05 - INFO - run_relation - Epoch: 3, Step: 210 / 2109, used_time = 8453.78s, loss = 0.353227\n",
      "11/25/2023 21:55:34 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   accuracy = 0.8914790996784566\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   eval_loss = 0.3689251360019304\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   f1 = 0.6740576496674059\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   n_correct = 304\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   n_pred = 447\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   precision = 0.680089485458613\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   recall = 0.6681318681318681\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   task_f1 = 0.6740576496674059\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 21:55:34 - INFO - run_relation -   task_recall = 0.6681318681318681\n",
      "11/25/2023 21:55:34 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=3): 67.41\n",
      "11/25/2023 21:55:34 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 21:58:51 - INFO - run_relation - Epoch: 3, Step: 420 / 2109, used_time = 8740.12s, loss = 0.344884\n",
      "11/25/2023 22:00:21 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   accuracy = 0.8870578778135049\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   eval_loss = 0.4143035408001621\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   f1 = 0.6552511415525114\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   n_correct = 287\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   n_pred = 421\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   precision = 0.6817102137767221\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   recall = 0.6307692307692307\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   task_f1 = 0.6552511415525114\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:00:21 - INFO - run_relation -   task_recall = 0.6307692307692307\n",
      "11/25/2023 22:03:39 - INFO - run_relation - Epoch: 3, Step: 630 / 2109, used_time = 9028.00s, loss = 0.337406\n",
      "11/25/2023 22:05:09 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   accuracy = 0.8886655948553055\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   eval_loss = 0.41605584194039225\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   f1 = 0.6651785714285715\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   n_correct = 298\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   n_pred = 441\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   precision = 0.6757369614512472\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   recall = 0.654945054945055\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   task_f1 = 0.6651785714285715\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:05:09 - INFO - run_relation -   task_recall = 0.654945054945055\n",
      "11/25/2023 22:08:27 - INFO - run_relation - Epoch: 3, Step: 840 / 2109, used_time = 9315.53s, loss = 0.329639\n",
      "11/25/2023 22:09:57 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   accuracy = 0.8890675241157556\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   eval_loss = 0.4280008789619066\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   f1 = 0.6739130434782609\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   n_correct = 310\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   n_pred = 465\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   precision = 0.6666666666666666\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   recall = 0.6813186813186813\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   task_f1 = 0.6739130434782609\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:09:57 - INFO - run_relation -   task_recall = 0.6813186813186813\n",
      "11/25/2023 22:13:10 - INFO - run_relation - Epoch: 3, Step: 1050 / 2109, used_time = 9598.64s, loss = 0.322785\n",
      "11/25/2023 22:14:37 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   accuracy = 0.887459807073955\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   eval_loss = 0.4155999682723901\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   f1 = 0.6350364963503649\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   n_correct = 261\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   n_pred = 367\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   precision = 0.7111716621253406\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   recall = 0.5736263736263736\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   task_f1 = 0.6350364963503649\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:14:37 - INFO - run_relation -   task_recall = 0.5736263736263736\n",
      "11/25/2023 22:17:43 - INFO - run_relation - Epoch: 3, Step: 1260 / 2109, used_time = 9871.54s, loss = 0.315972\n",
      "11/25/2023 22:19:10 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   accuracy = 0.8930868167202572\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   eval_loss = 0.4140931114410664\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   f1 = 0.6758938869665515\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   n_correct = 293\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   n_pred = 412\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   precision = 0.7111650485436893\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   recall = 0.643956043956044\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   task_f1 = 0.6758938869665515\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:19:10 - INFO - run_relation -   task_recall = 0.643956043956044\n",
      "11/25/2023 22:19:10 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=3): 67.59\n",
      "11/25/2023 22:19:10 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 22:22:16 - INFO - run_relation - Epoch: 3, Step: 1470 / 2109, used_time = 10144.62s, loss = 0.309857\n",
      "11/25/2023 22:23:43 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   accuracy = 0.8963022508038585\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   eval_loss = 0.40523992641754086\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   f1 = 0.6768149882903981\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   n_correct = 289\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   n_pred = 399\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   precision = 0.7243107769423559\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   recall = 0.6351648351648351\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   task_f1 = 0.6768149882903981\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:23:43 - INFO - run_relation -   task_recall = 0.6351648351648351\n",
      "11/25/2023 22:23:43 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=3): 67.68\n",
      "11/25/2023 22:23:43 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 22:26:49 - INFO - run_relation - Epoch: 3, Step: 1680 / 2109, used_time = 10417.64s, loss = 0.304903\n",
      "11/25/2023 22:28:16 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   accuracy = 0.8786173633440515\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   eval_loss = 0.4598124611799357\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   f1 = 0.6597294484911551\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   n_correct = 317\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   n_pred = 506\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   precision = 0.6264822134387352\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   recall = 0.6967032967032967\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   task_f1 = 0.6597294484911551\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:28:16 - INFO - run_relation -   task_recall = 0.6967032967032967\n",
      "11/25/2023 22:31:21 - INFO - run_relation - Epoch: 3, Step: 1890 / 2109, used_time = 10690.07s, loss = 0.299604\n",
      "11/25/2023 22:32:48 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   accuracy = 0.8830385852090032\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   eval_loss = 0.4274670516658826\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   f1 = 0.6572052401746725\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   n_correct = 301\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   n_pred = 461\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   precision = 0.6529284164859002\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   recall = 0.6615384615384615\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   task_f1 = 0.6572052401746725\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:32:48 - INFO - run_relation -   task_recall = 0.6615384615384615\n",
      "11/25/2023 22:35:50 - INFO - run_relation - Epoch: 3, Step: 2100 / 2109, used_time = 10959.08s, loss = 0.294191\n",
      "11/25/2023 22:37:17 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   accuracy = 0.885048231511254\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   eval_loss = 0.428038604581471\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   f1 = 0.6569506726457399\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   n_correct = 293\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   n_pred = 437\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   precision = 0.6704805491990846\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   recall = 0.643956043956044\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   task_f1 = 0.6569506726457399\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:37:17 - INFO - run_relation -   task_recall = 0.643956043956044\n",
      "11/25/2023 22:37:25 - INFO - run_relation - Start epoch #4 (lr = 2e-05)...\n",
      "11/25/2023 22:40:31 - INFO - run_relation - Epoch: 4, Step: 210 / 2109, used_time = 11239.61s, loss = 0.287764\n",
      "11/25/2023 22:41:58 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   accuracy = 0.8858520900321544\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   eval_loss = 0.4748404297223045\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   f1 = 0.671625929861849\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   n_correct = 316\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   n_pred = 486\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   precision = 0.6502057613168725\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   recall = 0.6945054945054945\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   task_f1 = 0.671625929861849\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:41:58 - INFO - run_relation -   task_recall = 0.6945054945054945\n",
      "11/25/2023 22:45:04 - INFO - run_relation - Epoch: 4, Step: 420 / 2109, used_time = 11512.24s, loss = 0.281947\n",
      "11/25/2023 22:46:30 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   accuracy = 0.8926848874598071\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   eval_loss = 0.4711945323315464\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   f1 = 0.6799557032115172\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   n_correct = 307\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   n_pred = 448\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   precision = 0.6852678571428571\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   recall = 0.6747252747252748\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   task_f1 = 0.6799557032115172\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:46:30 - INFO - run_relation -   task_recall = 0.6747252747252748\n",
      "11/25/2023 22:46:30 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=4): 68.00\n",
      "11/25/2023 22:46:30 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 22:49:37 - INFO - run_relation - Epoch: 4, Step: 630 / 2109, used_time = 11785.70s, loss = 0.276436\n",
      "11/25/2023 22:51:04 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   accuracy = 0.8926848874598071\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   eval_loss = 0.4551098296879955\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   f1 = 0.6666666666666666\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   n_correct = 287\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   n_pred = 406\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   precision = 0.7068965517241379\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   recall = 0.6307692307692307\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   task_f1 = 0.6666666666666666\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:51:04 - INFO - run_relation -   task_recall = 0.6307692307692307\n",
      "11/25/2023 22:54:10 - INFO - run_relation - Epoch: 4, Step: 840 / 2109, used_time = 12058.33s, loss = 0.271515\n",
      "11/25/2023 22:55:36 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   accuracy = 0.8910771704180064\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   eval_loss = 0.4495161025278821\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   f1 = 0.6768893756845564\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   n_correct = 309\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   n_pred = 458\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   precision = 0.6746724890829694\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   recall = 0.6791208791208792\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   task_f1 = 0.6768893756845564\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 22:55:36 - INFO - run_relation -   task_recall = 0.6791208791208792\n",
      "11/25/2023 22:58:42 - INFO - run_relation - Epoch: 4, Step: 1050 / 2109, used_time = 12331.00s, loss = 0.266669\n",
      "11/25/2023 23:00:09 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   accuracy = 0.8963022508038585\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   eval_loss = 0.46002244211469817\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   f1 = 0.6819747416762342\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   n_correct = 297\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   n_pred = 416\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   precision = 0.7139423076923077\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   recall = 0.6527472527472528\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   task_f1 = 0.6819747416762342\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:00:09 - INFO - run_relation -   task_recall = 0.6527472527472528\n",
      "11/25/2023 23:00:09 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=4): 68.20\n",
      "11/25/2023 23:00:09 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/25/2023 23:03:15 - INFO - run_relation - Epoch: 4, Step: 1260 / 2109, used_time = 12604.06s, loss = 0.261610\n",
      "11/25/2023 23:04:42 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   accuracy = 0.8942926045016077\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   eval_loss = 0.473919015126213\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   f1 = 0.6689814814814814\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   n_correct = 289\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   n_pred = 409\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   precision = 0.706601466992665\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   recall = 0.6351648351648351\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   task_f1 = 0.6689814814814814\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:04:42 - INFO - run_relation -   task_recall = 0.6351648351648351\n",
      "11/25/2023 23:07:48 - INFO - run_relation - Epoch: 4, Step: 1470 / 2109, used_time = 12876.63s, loss = 0.257037\n",
      "11/25/2023 23:09:15 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   accuracy = 0.8926848874598071\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   eval_loss = 0.4965694673191696\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   f1 = 0.6555423122765196\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   n_correct = 275\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   n_pred = 384\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   precision = 0.7161458333333334\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   recall = 0.6043956043956044\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   task_f1 = 0.6555423122765196\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:09:15 - INFO - run_relation -   task_recall = 0.6043956043956044\n",
      "11/25/2023 23:12:21 - INFO - run_relation - Epoch: 4, Step: 1680 / 2109, used_time = 13149.19s, loss = 0.252555\n",
      "11/25/2023 23:13:47 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   accuracy = 0.877411575562701\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   eval_loss = 0.5333042736988742\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   f1 = 0.6578140960163432\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   n_correct = 322\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   n_pred = 524\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   precision = 0.6145038167938931\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   recall = 0.7076923076923077\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   task_f1 = 0.6578140960163432\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:13:47 - INFO - run_relation -   task_recall = 0.7076923076923077\n",
      "11/25/2023 23:16:53 - INFO - run_relation - Epoch: 4, Step: 1890 / 2109, used_time = 13421.93s, loss = 0.248549\n",
      "11/25/2023 23:18:20 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   accuracy = 0.8810289389067524\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   eval_loss = 0.5216159517742046\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   f1 = 0.6494066882416396\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   n_correct = 301\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   n_pred = 472\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   precision = 0.6377118644067796\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   recall = 0.6615384615384615\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   task_f1 = 0.6494066882416396\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:18:20 - INFO - run_relation -   task_recall = 0.6615384615384615\n",
      "11/25/2023 23:21:26 - INFO - run_relation - Epoch: 4, Step: 2100 / 2109, used_time = 13694.68s, loss = 0.244574\n",
      "11/25/2023 23:22:53 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   accuracy = 0.8930868167202572\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   eval_loss = 0.5092761977500854\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   f1 = 0.6719278466741826\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   n_correct = 298\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   n_pred = 432\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   precision = 0.6898148148148148\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   recall = 0.654945054945055\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   task_f1 = 0.6719278466741826\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:22:53 - INFO - run_relation -   task_recall = 0.654945054945055\n",
      "11/25/2023 23:23:01 - INFO - run_relation - Start epoch #5 (lr = 2e-05)...\n",
      "11/25/2023 23:26:07 - INFO - run_relation - Epoch: 5, Step: 210 / 2109, used_time = 13975.41s, loss = 0.240199\n",
      "11/25/2023 23:27:34 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   accuracy = 0.8830385852090032\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   eval_loss = 0.5284986448057978\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   f1 = 0.6565874730021598\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   n_correct = 304\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   n_pred = 471\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   precision = 0.6454352441613588\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   recall = 0.6681318681318681\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   task_f1 = 0.6565874730021598\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:27:34 - INFO - run_relation -   task_recall = 0.6681318681318681\n",
      "11/25/2023 23:30:46 - INFO - run_relation - Epoch: 5, Step: 420 / 2109, used_time = 14255.06s, loss = 0.236084\n",
      "11/25/2023 23:32:16 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   accuracy = 0.8886655948553055\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   eval_loss = 0.5372878039956476\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   f1 = 0.6651835372636262\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   n_correct = 299\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   n_pred = 444\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   precision = 0.6734234234234234\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   recall = 0.6571428571428571\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   task_f1 = 0.6651835372636262\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:32:16 - INFO - run_relation -   task_recall = 0.6571428571428571\n",
      "11/25/2023 23:35:27 - INFO - run_relation - Epoch: 5, Step: 630 / 2109, used_time = 14535.85s, loss = 0.232167\n",
      "11/25/2023 23:36:57 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   accuracy = 0.887459807073955\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   eval_loss = 0.5344796231513621\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   f1 = 0.6681222707423581\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   n_correct = 306\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   n_pred = 461\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   precision = 0.6637744034707158\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   recall = 0.6725274725274726\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   task_f1 = 0.6681222707423581\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:36:57 - INFO - run_relation -   task_recall = 0.6725274725274726\n",
      "11/25/2023 23:40:07 - INFO - run_relation - Epoch: 5, Step: 840 / 2109, used_time = 14815.98s, loss = 0.228429\n",
      "11/25/2023 23:41:37 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   accuracy = 0.887459807073955\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   eval_loss = 0.5357007516542048\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   f1 = 0.6475315729047072\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   n_correct = 282\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   n_pred = 416\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   precision = 0.6778846153846154\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   recall = 0.6197802197802198\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   task_f1 = 0.6475315729047072\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:41:37 - INFO - run_relation -   task_recall = 0.6197802197802198\n",
      "11/25/2023 23:44:50 - INFO - run_relation - Epoch: 5, Step: 1050 / 2109, used_time = 15098.16s, loss = 0.224825\n",
      "11/25/2023 23:46:23 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   accuracy = 0.8890675241157556\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   eval_loss = 0.5516053993985583\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   f1 = 0.6703662597114318\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   n_correct = 302\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   n_pred = 446\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   precision = 0.6771300448430493\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   recall = 0.6637362637362637\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   task_f1 = 0.6703662597114318\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:46:23 - INFO - run_relation -   task_recall = 0.6637362637362637\n",
      "11/25/2023 23:49:45 - INFO - run_relation - Epoch: 5, Step: 1260 / 2109, used_time = 15393.34s, loss = 0.221357\n",
      "11/25/2023 23:51:27 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   accuracy = 0.8902733118971061\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   eval_loss = 0.5370786328982694\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   f1 = 0.6732456140350878\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   n_correct = 307\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   n_pred = 457\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   precision = 0.6717724288840262\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   recall = 0.6747252747252748\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   task_f1 = 0.6732456140350878\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:51:27 - INFO - run_relation -   task_recall = 0.6747252747252748\n",
      "11/25/2023 23:54:43 - INFO - run_relation - Epoch: 5, Step: 1470 / 2109, used_time = 15691.55s, loss = 0.217990\n",
      "11/25/2023 23:56:11 - INFO - run_relation - ***** Eval results *****\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   accuracy = 0.8938906752411575\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   eval_loss = 0.5312422967225409\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   f1 = 0.6807563959955506\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   n_correct = 306\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   n_gold = 455\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   n_pred = 444\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   precision = 0.6891891891891891\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   recall = 0.6725274725274726\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   task_f1 = 0.6807563959955506\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   task_ngold = 455\n",
      "11/25/2023 23:56:11 - INFO - run_relation -   task_recall = 0.6725274725274726\n",
      "11/25/2023 23:59:44 - INFO - run_relation - Epoch: 5, Step: 1680 / 2109, used_time = 15992.85s, loss = 0.214713\n",
      "11/26/2023 00:01:20 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   accuracy = 0.8910771704180064\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   eval_loss = 0.5619264315945542\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   f1 = 0.6811751904243744\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   n_correct = 313\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   n_pred = 464\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   precision = 0.6745689655172413\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   recall = 0.6879120879120879\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   task_f1 = 0.6811751904243744\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:01:20 - INFO - run_relation -   task_recall = 0.6879120879120879\n",
      "11/26/2023 00:04:27 - INFO - run_relation - Epoch: 5, Step: 1890 / 2109, used_time = 16275.80s, loss = 0.211490\n",
      "11/26/2023 00:05:54 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   accuracy = 0.8878617363344051\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   eval_loss = 0.5641211417901938\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   f1 = 0.6681081081081081\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   n_correct = 309\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   n_pred = 470\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   precision = 0.6574468085106383\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   recall = 0.6791208791208792\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   task_f1 = 0.6681081081081081\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:05:54 - INFO - run_relation -   task_recall = 0.6791208791208792\n",
      "11/26/2023 00:09:00 - INFO - run_relation - Epoch: 5, Step: 2100 / 2109, used_time = 16548.36s, loss = 0.208291\n",
      "11/26/2023 00:10:27 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   accuracy = 0.8834405144694534\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   eval_loss = 0.5629087045453369\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   f1 = 0.6701791359325605\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   n_correct = 318\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   n_pred = 494\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   precision = 0.6437246963562753\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   recall = 0.6989010989010989\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   task_f1 = 0.6701791359325605\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:10:27 - INFO - run_relation -   task_recall = 0.6989010989010989\n",
      "11/26/2023 00:10:35 - INFO - run_relation - Start epoch #6 (lr = 2e-05)...\n",
      "11/26/2023 00:13:42 - INFO - run_relation - Epoch: 6, Step: 210 / 2109, used_time = 16830.42s, loss = 0.205115\n",
      "11/26/2023 00:15:09 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   accuracy = 0.887459807073955\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   eval_loss = 0.5703961283830967\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   f1 = 0.6830309498399146\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   n_correct = 320\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   n_pred = 482\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   precision = 0.6639004149377593\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   recall = 0.7032967032967034\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   task_f1 = 0.6830309498399146\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:15:09 - INFO - run_relation -   task_recall = 0.7032967032967034\n",
      "11/26/2023 00:15:09 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=6): 68.30\n",
      "11/26/2023 00:15:09 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/26/2023 00:18:15 - INFO - run_relation - Epoch: 6, Step: 420 / 2109, used_time = 17103.54s, loss = 0.202002\n",
      "11/26/2023 00:19:42 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   accuracy = 0.8938906752411575\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   eval_loss = 0.5633605240433929\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   f1 = 0.6860335195530727\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   n_correct = 307\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   n_pred = 440\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   precision = 0.6977272727272728\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   recall = 0.6747252747252748\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   task_f1 = 0.6860335195530727\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:19:42 - INFO - run_relation -   task_recall = 0.6747252747252748\n",
      "11/26/2023 00:19:42 - INFO - run_relation - !!! Best dev f1 (lr=2e-05, epoch=6): 68.60\n",
      "11/26/2023 00:19:42 - INFO - run_relation - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/\n",
      "11/26/2023 00:22:48 - INFO - run_relation - Epoch: 6, Step: 630 / 2109, used_time = 17376.63s, loss = 0.199027\n",
      "11/26/2023 00:24:15 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   accuracy = 0.8906752411575563\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   eval_loss = 0.6010225148829617\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   f1 = 0.6659012629161882\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   n_correct = 290\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   n_pred = 416\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   precision = 0.6971153846153846\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   recall = 0.6373626373626373\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   task_f1 = 0.6659012629161882\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:24:15 - INFO - run_relation -   task_recall = 0.6373626373626373\n",
      "11/26/2023 00:27:21 - INFO - run_relation - Epoch: 6, Step: 840 / 2109, used_time = 17649.31s, loss = 0.196173\n",
      "11/26/2023 00:28:48 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   accuracy = 0.8870578778135049\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   eval_loss = 0.6057114030962205\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   f1 = 0.6724324324324324\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   n_correct = 311\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   n_pred = 470\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   precision = 0.6617021276595745\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   recall = 0.6835164835164835\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   task_f1 = 0.6724324324324324\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:28:48 - INFO - run_relation -   task_recall = 0.6835164835164835\n",
      "11/26/2023 00:31:53 - INFO - run_relation - Epoch: 6, Step: 1050 / 2109, used_time = 17922.03s, loss = 0.193344\n",
      "11/26/2023 00:33:20 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   accuracy = 0.8886655948553055\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   eval_loss = 0.6137956118277031\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   f1 = 0.6644295302013423\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   n_correct = 297\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   n_pred = 439\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   precision = 0.6765375854214123\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   recall = 0.6527472527472528\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   task_f1 = 0.6644295302013423\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:33:20 - INFO - run_relation -   task_recall = 0.6527472527472528\n",
      "11/26/2023 00:36:26 - INFO - run_relation - Epoch: 6, Step: 1260 / 2109, used_time = 18194.61s, loss = 0.190756\n",
      "11/26/2023 00:37:53 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   accuracy = 0.8862540192926045\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   eval_loss = 0.6085982779310447\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   f1 = 0.672322375397667\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   n_correct = 317\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   n_pred = 488\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   precision = 0.6495901639344263\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   recall = 0.6967032967032967\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   task_f1 = 0.672322375397667\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:37:53 - INFO - run_relation -   task_recall = 0.6967032967032967\n",
      "11/26/2023 00:40:59 - INFO - run_relation - Epoch: 6, Step: 1470 / 2109, used_time = 18467.22s, loss = 0.188152\n",
      "11/26/2023 00:42:25 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   accuracy = 0.8918810289389068\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   eval_loss = 0.6077031816125299\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   f1 = 0.6747252747252748\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   n_correct = 307\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   n_pred = 455\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   precision = 0.6747252747252748\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   recall = 0.6747252747252748\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   task_f1 = 0.6747252747252748\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:42:25 - INFO - run_relation -   task_recall = 0.6747252747252748\n",
      "11/26/2023 00:45:31 - INFO - run_relation - Epoch: 6, Step: 1680 / 2109, used_time = 18739.86s, loss = 0.185734\n",
      "11/26/2023 00:46:58 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   accuracy = 0.8918810289389068\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   eval_loss = 0.5847331106279441\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   f1 = 0.6775599128540304\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   n_correct = 311\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   n_pred = 463\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   precision = 0.67170626349892\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   recall = 0.6835164835164835\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   task_f1 = 0.6775599128540304\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:46:58 - INFO - run_relation -   task_recall = 0.6835164835164835\n",
      "11/26/2023 00:50:04 - INFO - run_relation - Epoch: 6, Step: 1890 / 2109, used_time = 19012.62s, loss = 0.183212\n",
      "11/26/2023 00:51:31 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   accuracy = 0.8922829581993569\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   eval_loss = 0.6115052092976125\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   f1 = 0.6790799561883899\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   n_correct = 310\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   n_pred = 458\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   precision = 0.6768558951965066\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   recall = 0.6813186813186813\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   task_f1 = 0.6790799561883899\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:51:31 - INFO - run_relation -   task_recall = 0.6813186813186813\n",
      "11/26/2023 00:54:37 - INFO - run_relation - Epoch: 6, Step: 2100 / 2109, used_time = 19285.35s, loss = 0.180791\n",
      "11/26/2023 00:56:04 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   accuracy = 0.8914790996784566\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   eval_loss = 0.5907639496962741\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   f1 = 0.6804347826086956\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   n_correct = 313\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   n_pred = 465\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   precision = 0.6731182795698925\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   recall = 0.6879120879120879\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   task_f1 = 0.6804347826086956\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 00:56:04 - INFO - run_relation -   task_recall = 0.6879120879120879\n",
      "11/26/2023 00:56:12 - INFO - run_relation - Start epoch #7 (lr = 2e-05)...\n",
      "11/26/2023 00:59:17 - INFO - run_relation - Epoch: 7, Step: 210 / 2109, used_time = 19566.04s, loss = 0.178363\n",
      "11/26/2023 01:00:44 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   accuracy = 0.895096463022508\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   eval_loss = 0.5841130553909437\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   f1 = 0.6815642458100558\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   n_correct = 305\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   n_pred = 440\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   precision = 0.6931818181818182\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   recall = 0.6703296703296703\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   task_f1 = 0.6815642458100558\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:00:44 - INFO - run_relation -   task_recall = 0.6703296703296703\n",
      "11/26/2023 01:03:50 - INFO - run_relation - Epoch: 7, Step: 420 / 2109, used_time = 19838.69s, loss = 0.176038\n",
      "11/26/2023 01:05:17 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   accuracy = 0.8963022508038585\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   eval_loss = 0.5886544762508662\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   f1 = 0.681766704416761\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   n_correct = 301\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   n_pred = 428\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   precision = 0.7032710280373832\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   recall = 0.6615384615384615\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   task_f1 = 0.681766704416761\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:05:17 - INFO - run_relation -   task_recall = 0.6615384615384615\n",
      "11/26/2023 01:08:23 - INFO - run_relation - Epoch: 7, Step: 630 / 2109, used_time = 20111.41s, loss = 0.173707\n",
      "11/26/2023 01:09:50 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   accuracy = 0.8954983922829582\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   eval_loss = 0.5953317591231736\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   f1 = 0.6858407079646017\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   n_correct = 310\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   n_pred = 449\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   precision = 0.6904231625835189\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   recall = 0.6813186813186813\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   task_f1 = 0.6858407079646017\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:09:50 - INFO - run_relation -   task_recall = 0.6813186813186813\n",
      "11/26/2023 01:12:55 - INFO - run_relation - Epoch: 7, Step: 840 / 2109, used_time = 20384.12s, loss = 0.171475\n",
      "11/26/2023 01:14:22 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   accuracy = 0.8946945337620579\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   eval_loss = 0.6154372026107702\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   f1 = 0.6815144766146993\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   n_correct = 306\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   n_pred = 443\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   precision = 0.690744920993228\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   recall = 0.6725274725274726\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   task_f1 = 0.6815144766146993\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:14:22 - INFO - run_relation -   task_recall = 0.6725274725274726\n",
      "11/26/2023 01:17:28 - INFO - run_relation - Epoch: 7, Step: 1050 / 2109, used_time = 20656.64s, loss = 0.169336\n",
      "11/26/2023 01:18:55 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   accuracy = 0.8902733118971061\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   eval_loss = 0.6176456118128307\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   f1 = 0.6703176341730559\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   n_correct = 306\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   n_pred = 458\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   precision = 0.6681222707423581\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   recall = 0.6725274725274726\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   task_f1 = 0.6703176341730559\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:18:55 - INFO - run_relation -   task_recall = 0.6725274725274726\n",
      "11/26/2023 01:22:01 - INFO - run_relation - Epoch: 7, Step: 1260 / 2109, used_time = 20929.32s, loss = 0.167208\n",
      "11/26/2023 01:23:27 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:23:27 - INFO - run_relation -   accuracy = 0.8886655948553055\n",
      "11/26/2023 01:23:27 - INFO - run_relation -   eval_loss = 0.6258857844343523\n",
      "11/26/2023 01:23:27 - INFO - run_relation -   f1 = 0.6737967914438503\n",
      "11/26/2023 01:23:27 - INFO - run_relation -   n_correct = 315\n",
      "11/26/2023 01:23:27 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:23:27 - INFO - run_relation -   n_pred = 480\n",
      "11/26/2023 01:23:27 - INFO - run_relation -   precision = 0.65625\n",
      "11/26/2023 01:23:28 - INFO - run_relation -   recall = 0.6923076923076923\n",
      "11/26/2023 01:23:28 - INFO - run_relation -   task_f1 = 0.6737967914438503\n",
      "11/26/2023 01:23:28 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:23:28 - INFO - run_relation -   task_recall = 0.6923076923076923\n",
      "11/26/2023 01:26:33 - INFO - run_relation - Epoch: 7, Step: 1470 / 2109, used_time = 21201.97s, loss = 0.165230\n",
      "11/26/2023 01:28:00 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   accuracy = 0.8930868167202572\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   eval_loss = 0.6029763461309231\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   f1 = 0.6806167400881058\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   n_correct = 309\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   n_pred = 453\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   precision = 0.6821192052980133\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   recall = 0.6791208791208792\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   task_f1 = 0.6806167400881058\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:28:00 - INFO - run_relation -   task_recall = 0.6791208791208792\n",
      "11/26/2023 01:31:06 - INFO - run_relation - Epoch: 7, Step: 1680 / 2109, used_time = 21474.61s, loss = 0.163204\n",
      "11/26/2023 01:32:33 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   accuracy = 0.8938906752411575\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   eval_loss = 0.6200248910491489\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   f1 = 0.6786114221724524\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   n_correct = 303\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   n_pred = 438\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   precision = 0.6917808219178082\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   recall = 0.6659340659340659\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   task_f1 = 0.6786114221724524\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:32:33 - INFO - run_relation -   task_recall = 0.6659340659340659\n",
      "11/26/2023 01:35:39 - INFO - run_relation - Epoch: 7, Step: 1890 / 2109, used_time = 21747.28s, loss = 0.161255\n",
      "11/26/2023 01:37:06 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   accuracy = 0.8866559485530546\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   eval_loss = 0.6431735228399755\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   f1 = 0.6695371367061357\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   n_correct = 311\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   n_pred = 474\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   precision = 0.6561181434599156\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   recall = 0.6835164835164835\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   task_f1 = 0.6695371367061357\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:37:06 - INFO - run_relation -   task_recall = 0.6835164835164835\n",
      "11/26/2023 01:40:11 - INFO - run_relation - Epoch: 7, Step: 2100 / 2109, used_time = 22020.01s, loss = 0.159442\n",
      "11/26/2023 01:41:38 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   accuracy = 0.885048231511254\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   eval_loss = 0.6354002834707978\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   f1 = 0.6666666666666667\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   n_correct = 310\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   n_pred = 475\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   precision = 0.6526315789473685\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   recall = 0.6813186813186813\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   task_f1 = 0.6666666666666667\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:41:38 - INFO - run_relation -   task_recall = 0.6813186813186813\n",
      "11/26/2023 01:41:46 - INFO - run_relation - Start epoch #8 (lr = 2e-05)...\n",
      "11/26/2023 01:44:52 - INFO - run_relation - Epoch: 8, Step: 210 / 2109, used_time = 22300.77s, loss = 0.157473\n",
      "11/26/2023 01:46:19 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   accuracy = 0.8894694533762058\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   eval_loss = 0.6364222241751251\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   f1 = 0.6739367502726281\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   n_correct = 309\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   n_pred = 462\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   precision = 0.6688311688311688\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   recall = 0.6791208791208792\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   task_f1 = 0.6739367502726281\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:46:19 - INFO - run_relation -   task_recall = 0.6791208791208792\n",
      "11/26/2023 01:49:25 - INFO - run_relation - Epoch: 8, Step: 420 / 2109, used_time = 22573.42s, loss = 0.155603\n",
      "11/26/2023 01:50:52 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   accuracy = 0.889871382636656\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   eval_loss = 0.6358263002906198\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   f1 = 0.6688888888888889\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   n_correct = 301\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   n_pred = 445\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   precision = 0.6764044943820224\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   recall = 0.6615384615384615\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   task_f1 = 0.6688888888888889\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:50:52 - INFO - run_relation -   task_recall = 0.6615384615384615\n",
      "11/26/2023 01:53:58 - INFO - run_relation - Epoch: 8, Step: 630 / 2109, used_time = 22846.22s, loss = 0.153775\n",
      "11/26/2023 01:55:24 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   accuracy = 0.8870578778135049\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   eval_loss = 0.6499113783575714\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   f1 = 0.6644736842105262\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   n_correct = 303\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   n_pred = 457\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   precision = 0.6630196936542669\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   recall = 0.6659340659340659\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   task_f1 = 0.6644736842105262\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:55:24 - INFO - run_relation -   task_recall = 0.6659340659340659\n",
      "11/26/2023 01:58:30 - INFO - run_relation - Epoch: 8, Step: 840 / 2109, used_time = 23118.89s, loss = 0.152037\n",
      "11/26/2023 01:59:57 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   accuracy = 0.8854501607717041\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   eval_loss = 0.6655522341513557\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   f1 = 0.6694915254237288\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   n_correct = 316\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   n_pred = 489\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   precision = 0.6462167689161554\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   recall = 0.6945054945054945\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   task_f1 = 0.6694915254237288\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 01:59:57 - INFO - run_relation -   task_recall = 0.6945054945054945\n",
      "11/26/2023 02:03:03 - INFO - run_relation - Epoch: 8, Step: 1050 / 2109, used_time = 23391.58s, loss = 0.150390\n",
      "11/26/2023 02:04:30 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   accuracy = 0.887459807073955\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   eval_loss = 0.6661344961146449\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   f1 = 0.66738894907909\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   n_correct = 308\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   n_pred = 468\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   precision = 0.6581196581196581\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   recall = 0.676923076923077\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   task_f1 = 0.66738894907909\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:04:30 - INFO - run_relation -   task_recall = 0.676923076923077\n",
      "11/26/2023 02:07:36 - INFO - run_relation - Epoch: 8, Step: 1260 / 2109, used_time = 23664.17s, loss = 0.148802\n",
      "11/26/2023 02:09:02 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   accuracy = 0.8878617363344051\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   eval_loss = 0.6513624763373776\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   f1 = 0.6629834254143646\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   n_correct = 300\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   n_pred = 450\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   precision = 0.6666666666666666\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   recall = 0.6593406593406593\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   task_f1 = 0.6629834254143646\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:09:02 - INFO - run_relation -   task_recall = 0.6593406593406593\n",
      "11/26/2023 02:12:08 - INFO - run_relation - Epoch: 8, Step: 1470 / 2109, used_time = 23936.77s, loss = 0.147222\n",
      "11/26/2023 02:13:35 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   accuracy = 0.887459807073955\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   eval_loss = 0.6385703982839247\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   f1 = 0.6681127982646421\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   n_correct = 308\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   n_pred = 467\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   precision = 0.6595289079229122\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   recall = 0.676923076923077\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   task_f1 = 0.6681127982646421\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:13:35 - INFO - run_relation -   task_recall = 0.676923076923077\n",
      "11/26/2023 02:16:41 - INFO - run_relation - Epoch: 8, Step: 1680 / 2109, used_time = 24209.35s, loss = 0.145601\n",
      "11/26/2023 02:18:08 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   accuracy = 0.8890675241157556\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   eval_loss = 0.6370010918359664\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   f1 = 0.6745945945945946\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   n_correct = 312\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   n_pred = 470\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   precision = 0.6638297872340425\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   recall = 0.6857142857142857\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   task_f1 = 0.6745945945945946\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:18:08 - INFO - run_relation -   task_recall = 0.6857142857142857\n",
      "11/26/2023 02:21:13 - INFO - run_relation - Epoch: 8, Step: 1890 / 2109, used_time = 24481.98s, loss = 0.144004\n",
      "11/26/2023 02:22:40 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   accuracy = 0.889871382636656\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   eval_loss = 0.6322410302146838\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   f1 = 0.6710963455149501\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   n_correct = 303\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   n_pred = 448\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   precision = 0.6763392857142857\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   recall = 0.6659340659340659\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   task_f1 = 0.6710963455149501\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:22:40 - INFO - run_relation -   task_recall = 0.6659340659340659\n",
      "11/26/2023 02:25:46 - INFO - run_relation - Epoch: 8, Step: 2100 / 2109, used_time = 24754.67s, loss = 0.142503\n",
      "11/26/2023 02:27:13 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   accuracy = 0.887459807073955\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   eval_loss = 0.6501281856532265\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   f1 = 0.6723768736616703\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   n_correct = 314\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   n_pred = 479\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   precision = 0.6555323590814196\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   recall = 0.6901098901098901\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   task_f1 = 0.6723768736616703\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:27:13 - INFO - run_relation -   task_recall = 0.6901098901098901\n",
      "11/26/2023 02:27:21 - INFO - run_relation - Start epoch #9 (lr = 2e-05)...\n",
      "11/26/2023 02:30:27 - INFO - run_relation - Epoch: 9, Step: 210 / 2109, used_time = 25035.37s, loss = 0.140926\n",
      "11/26/2023 02:31:54 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   accuracy = 0.8914790996784566\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   eval_loss = 0.6246372404780802\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   f1 = 0.6689113355780022\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   n_correct = 298\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   n_pred = 436\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   precision = 0.6834862385321101\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   recall = 0.654945054945055\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   task_f1 = 0.6689113355780022\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:31:54 - INFO - run_relation -   task_recall = 0.654945054945055\n",
      "11/26/2023 02:34:59 - INFO - run_relation - Epoch: 9, Step: 420 / 2109, used_time = 25308.06s, loss = 0.139447\n",
      "11/26/2023 02:36:26 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   accuracy = 0.8890675241157556\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   eval_loss = 0.6308743702637037\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   f1 = 0.6717557251908397\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   n_correct = 308\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   n_pred = 462\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   precision = 0.6666666666666666\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   recall = 0.676923076923077\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   task_f1 = 0.6717557251908397\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:36:26 - INFO - run_relation -   task_recall = 0.676923076923077\n",
      "11/26/2023 02:39:32 - INFO - run_relation - Epoch: 9, Step: 630 / 2109, used_time = 25580.79s, loss = 0.137980\n",
      "11/26/2023 02:40:59 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   accuracy = 0.8910771704180064\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   eval_loss = 0.629833255454275\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   f1 = 0.6741071428571428\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   n_correct = 302\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   n_pred = 441\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   precision = 0.6848072562358276\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   recall = 0.6637362637362637\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   task_f1 = 0.6741071428571428\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:40:59 - INFO - run_relation -   task_recall = 0.6637362637362637\n",
      "11/26/2023 02:44:05 - INFO - run_relation - Epoch: 9, Step: 840 / 2109, used_time = 25853.40s, loss = 0.136536\n",
      "11/26/2023 02:45:32 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   accuracy = 0.8918810289389068\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   eval_loss = 0.6326442972256823\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   f1 = 0.6763392857142857\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   n_correct = 303\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   n_pred = 441\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   precision = 0.6870748299319728\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   recall = 0.6659340659340659\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   task_f1 = 0.6763392857142857\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:45:32 - INFO - run_relation -   task_recall = 0.6659340659340659\n",
      "11/26/2023 02:48:37 - INFO - run_relation - Epoch: 9, Step: 1050 / 2109, used_time = 26126.06s, loss = 0.135128\n",
      "11/26/2023 02:50:04 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   accuracy = 0.8922829581993569\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   eval_loss = 0.6375887452406132\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   f1 = 0.675645342312009\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   n_correct = 301\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   n_pred = 436\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   precision = 0.6903669724770642\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   recall = 0.6615384615384615\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   task_f1 = 0.675645342312009\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:50:04 - INFO - run_relation -   task_recall = 0.6615384615384615\n",
      "11/26/2023 02:53:10 - INFO - run_relation - Epoch: 9, Step: 1260 / 2109, used_time = 26398.71s, loss = 0.133749\n",
      "11/26/2023 02:54:37 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   accuracy = 0.8922829581993569\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   eval_loss = 0.636088860092439\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   f1 = 0.6770949720670391\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   n_correct = 303\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   n_pred = 440\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   precision = 0.6886363636363636\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   recall = 0.6659340659340659\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   task_f1 = 0.6770949720670391\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:54:37 - INFO - run_relation -   task_recall = 0.6659340659340659\n",
      "11/26/2023 02:57:43 - INFO - run_relation - Epoch: 9, Step: 1470 / 2109, used_time = 26671.34s, loss = 0.132396\n",
      "11/26/2023 02:59:10 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   accuracy = 0.8906752411575563\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   eval_loss = 0.6392334625843636\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   f1 = 0.6748057713651497\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   n_correct = 304\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   n_pred = 446\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   precision = 0.6816143497757847\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   recall = 0.6681318681318681\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   task_f1 = 0.6748057713651497\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 02:59:10 - INFO - run_relation -   task_recall = 0.6681318681318681\n",
      "11/26/2023 03:02:16 - INFO - run_relation - Epoch: 9, Step: 1680 / 2109, used_time = 26944.26s, loss = 0.131064\n",
      "11/26/2023 03:03:42 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 03:03:42 - INFO - run_relation -   accuracy = 0.8918810289389068\n",
      "11/26/2023 03:03:42 - INFO - run_relation -   eval_loss = 0.6408782153842534\n",
      "11/26/2023 03:03:42 - INFO - run_relation -   f1 = 0.6770601336302895\n",
      "11/26/2023 03:03:42 - INFO - run_relation -   n_correct = 304\n",
      "11/26/2023 03:03:42 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 03:03:42 - INFO - run_relation -   n_pred = 443\n",
      "11/26/2023 03:03:43 - INFO - run_relation -   precision = 0.6862302483069977\n",
      "11/26/2023 03:03:43 - INFO - run_relation -   recall = 0.6681318681318681\n",
      "11/26/2023 03:03:43 - INFO - run_relation -   task_f1 = 0.6770601336302895\n",
      "11/26/2023 03:03:43 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 03:03:43 - INFO - run_relation -   task_recall = 0.6681318681318681\n",
      "11/26/2023 03:06:49 - INFO - run_relation - Epoch: 9, Step: 1890 / 2109, used_time = 27217.94s, loss = 0.129785\n",
      "11/26/2023 03:08:17 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   accuracy = 0.8918810289389068\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   eval_loss = 0.6427683757432404\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   f1 = 0.6770255271920088\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   n_correct = 305\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   n_pred = 446\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   precision = 0.6838565022421524\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   recall = 0.6703296703296703\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   task_f1 = 0.6770255271920088\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 03:08:17 - INFO - run_relation -   task_recall = 0.6703296703296703\n",
      "11/26/2023 03:11:23 - INFO - run_relation - Epoch: 9, Step: 2100 / 2109, used_time = 27492.05s, loss = 0.128535\n",
      "11/26/2023 03:12:50 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   accuracy = 0.8922829581993569\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   eval_loss = 0.6436730161357156\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   f1 = 0.6784922394678493\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   n_correct = 306\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   n_gold = 455\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   n_pred = 447\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   precision = 0.6845637583892618\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   recall = 0.6725274725274726\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   task_f1 = 0.6784922394678493\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   task_ngold = 455\n",
      "11/26/2023 03:12:50 - INFO - run_relation -   task_recall = 0.6725274725274726\n",
      "11/26/2023 03:12:58 - INFO - run_relation - {'SUBJ_START': '[unused1]', 'SUBJ_END': '[unused2]', 'OBJ_START': '[unused3]', 'OBJ_END': '[unused4]', 'SUBJ=Generic': '[unused5]', 'OBJ=Task': '[unused6]', 'SUBJ_START=Generic': '[unused7]', 'SUBJ_END=Generic': '[unused8]', 'OBJ_START=Task': '[unused9]', 'OBJ_END=Task': '[unused10]', 'OBJ=Material': '[unused11]', 'OBJ_START=Material': '[unused12]', 'OBJ_END=Material': '[unused13]', 'OBJ=OtherScientificTerm': '[unused14]', 'OBJ_START=OtherScientificTerm': '[unused15]', 'OBJ_END=OtherScientificTerm': '[unused16]', 'SUBJ=Task': '[unused17]', 'OBJ=Generic': '[unused18]', 'SUBJ_START=Task': '[unused19]', 'SUBJ_END=Task': '[unused20]', 'OBJ_START=Generic': '[unused21]', 'OBJ_END=Generic': '[unused22]', 'SUBJ=Material': '[unused23]', 'SUBJ_START=Material': '[unused24]', 'SUBJ_END=Material': '[unused25]', 'SUBJ=OtherScientificTerm': '[unused26]', 'SUBJ_START=OtherScientificTerm': '[unused27]', 'SUBJ_END=OtherScientificTerm': '[unused28]', 'OBJ=Method': '[unused29]', 'OBJ_START=Method': '[unused30]', 'OBJ_END=Method': '[unused31]', 'SUBJ=Method': '[unused32]', 'SUBJ_START=Method': '[unused33]', 'SUBJ_END=Method': '[unused34]', 'OBJ=Metric': '[unused35]', 'OBJ_START=Metric': '[unused36]', 'OBJ_END=Metric': '[unused37]', 'SUBJ=Metric': '[unused38]', 'SUBJ_START=Metric': '[unused39]', 'SUBJ_END=Metric': '[unused40]'}\n",
      "11/26/2023 03:12:58 - INFO - run_relation - Writing example 0 of 5062\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@0::(0,3)-(2,3)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] [unused19] recognition of [unused15] proper nouns [unused20] [unused16] in japanese text has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 20 3512 131 16 1193 24748 21 17 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 1, 4\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@0::(0,3)-(5,6)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] [unused19] recognition of proper nouns [unused20] in [unused12] japanese text [unused13] has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 20 3512 131 1193 24748 21 121 13 9155 3267 14 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 1, 8\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@0::(0,3)-(19,20)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] [unused19] recognition of proper nouns [unused20] in japanese text has been studied as a part of the more general problem of [unused9] morphological analysis [unused10] in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 20 3512 131 1193 24748 21 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 10 6893 669 11 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 1, 22\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@0::(0,3)-(22,24)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] [unused19] recognition of proper nouns [unused20] in japanese text has been studied as a part of the more general problem of morphological analysis in [unused9] japanese text processing [unused10] - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 20 3512 131 1193 24748 21 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 10 9155 3267 2307 11 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 1, 25\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@0::(2,3)-(0,3)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] [unused9] recognition of [unused27] proper nouns [unused28] [unused10] in japanese text has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 10 3512 131 28 1193 24748 29 11 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 4, 1\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@0::(2,3)-(5,6)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] recognition of [unused27] proper nouns [unused28] in [unused12] japanese text [unused13] has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 3512 131 28 1193 24748 29 121 13 9155 3267 14 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 3, 8\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@0::(19,20)-(22,24)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] recognition of proper nouns in japanese text has been studied as a part of the more general problem of [unused19] morphological analysis [unused20] in [unused9] japanese text processing [unused10] - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 3512 131 1193 24748 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 20 6893 669 21 121 10 9155 3267 2307 11 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 20, 25\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@1::(43,45)-(34,34)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] [unused21] it [unused22] has also been studied in the framework of [unused19] japanese information extraction [unused20] - lr ##b - - ls ##b - 3 - rs ##b - - rr ##b - in recent years . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 22 256 23 434 469 528 2580 121 111 2641 131 20 9155 776 4220 21 579 8295 30125 579 579 6208 30125 579 239 579 3102 30125 579 579 5058 30125 579 121 2151 1320 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 12, 1\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@2::(56,56)-(59,64)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] our [unused7] approach [unused8] to the [unused9] multi - lingu ##al evaluation task - lr ##b - met - rr ##b - [unused10] for japanese text is to consider the given task as a morphological analysis problem in japanese . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 580 8 1139 9 147 111 10 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 11 168 9155 3267 165 147 1129 111 906 2188 188 106 6893 669 1167 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 2, 7\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@2::(59,64)-(66,67)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] our approach to the [unused19] multi - lingu ##al evaluation task - lr ##b - met - rr ##b - [unused20] for [unused12] japanese text [unused13] is to consider the given task as a morphological analysis problem in japanese . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 580 1139 147 111 20 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 21 168 13 9155 3267 14 165 147 1129 111 906 2188 188 106 6893 669 1167 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 5, 23\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@2::(76,78)-(73,73)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] our approach to the multi - lingu ##al evaluation task - lr ##b - met - rr ##b - for japanese text is to consider the given [unused21] task [unused22] as a [unused19] morphological analysis problem [unused20] in japanese . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 580 1139 147 111 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 168 9155 3267 165 147 1129 111 906 22 2188 23 188 106 20 6893 669 1167 21 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 33, 28\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@2::(80,80)-(76,78)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] our approach to the multi - lingu ##al evaluation task - lr ##b - met - rr ##b - for japanese text is to consider the given task as a [unused9] morphological analysis problem [unused10] in [unused24] japanese [unused25] . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 580 1139 147 111 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 168 9155 3267 165 147 1129 111 906 2188 188 106 10 6893 669 1167 11 121 25 9155 26 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 37, 31\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@3::(83,84)-(93,103)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] our [unused33] morphological analyzer [unused34] has done all the necessary work for the [unused9] recognition and classification of proper names , numerical and temporal expressions [unused10] , i . e . named entity - lr ##b - ne - rr ##b - items in the japanese text . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 580 34 6893 12951 35 434 2992 355 111 2538 697 168 111 10 3512 137 2998 131 1193 8541 422 4058 137 3930 6370 11 422 259 205 139 205 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 121 111 9155 3267 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 2, 14\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@3::(106,111)-(97,103)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] our morphological analyzer has done all the necessary work for the recognition and classification of [unused15] proper names , numerical and temporal expressions [unused16] , i . e . [unused27] named entity - lr ##b - ne - rr ##b - items [unused28] in the japanese text . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 580 6893 12951 434 2992 355 111 2538 697 168 111 3512 137 2998 131 16 1193 8541 422 4058 137 3930 6370 17 422 259 205 139 205 28 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 29 121 111 9155 3267 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: HYPONYM-OF (id = 6)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 30, 16\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@3::(106,111)-(114,115)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i . e . [unused27] named entity - lr ##b - ne - rr ##b - items [unused28] in the [unused12] japanese text [unused13] . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 580 6893 12951 434 2992 355 111 2538 697 168 111 3512 137 2998 131 1193 8541 422 4058 137 3930 6370 422 259 205 139 205 28 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 29 121 111 13 9155 3267 14 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 28, 44\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@5::(125,125)-(127,128)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] [unused33] amorph [unused34] recognizes [unused15] ne items [unused16] in two stages : dictionary lookup and rule application . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 34 15291 35 20269 16 287 3945 17 121 502 4303 862 13050 22474 137 3346 1836 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 1, 5\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@5::(133,134)-(125,125)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] [unused30] amorph [unused31] recognizes ne items in two stages : [unused33] dictionary lookup [unused34] and rule application . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 31 15291 32 20269 287 3945 121 502 4303 862 34 13050 22474 35 137 3346 1836 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 11, 1\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:58 - INFO - run_relation - guid: X96-1059@5::(133,134)-(136,137)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - tokens: [CLS] amorph recognizes ne items in two stages : [unused33] dictionary lookup [unused34] and [unused30] rule application [unused31] . [SEP]\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_ids: 102 15291 20269 287 3945 121 502 4303 862 34 13050 22474 35 137 31 3346 1836 32 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:58 - INFO - run_relation - label: CONJUNCTION (id = 4)\n",
      "11/26/2023 03:12:58 - INFO - run_relation - sub_idx, obj_idx: 9, 14\n",
      "11/26/2023 03:12:58 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:59 - INFO - run_relation - guid: X96-1059@5::(136,137)-(125,125)\n",
      "11/26/2023 03:12:59 - INFO - run_relation - tokens: [CLS] [unused30] amorph [unused31] recognizes ne items in two stages : dictionary lookup and [unused33] rule application [unused34] . [SEP]\n",
      "11/26/2023 03:12:59 - INFO - run_relation - input_ids: 102 31 15291 32 20269 287 3945 121 502 4303 862 13050 22474 137 34 3346 1836 35 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:59 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:59 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:59 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/26/2023 03:12:59 - INFO - run_relation - sub_idx, obj_idx: 14, 1\n",
      "11/26/2023 03:12:59 - INFO - run_relation - *** Example ***\n",
      "11/26/2023 03:12:59 - INFO - run_relation - guid: X96-1059@6::(146,146)-(141,141)\n",
      "11/26/2023 03:12:59 - INFO - run_relation - tokens: [CLS] first , [unused21] it [unused22] uses several kinds of [unused27] diction ##aries [unused28] to segment and tag japanese character strings . [SEP]\n",
      "11/26/2023 03:12:59 - INFO - run_relation - input_ids: 102 705 422 22 256 23 3294 1323 7337 131 28 11618 2881 29 147 3197 137 5374 9155 954 13408 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:59 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:59 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/26/2023 03:12:59 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/26/2023 03:12:59 - INFO - run_relation - sub_idx, obj_idx: 10, 3\n",
      "11/26/2023 03:13:08 - INFO - run_relation - Average #tokens: 44.54\n",
      "11/26/2023 03:13:08 - INFO - run_relation - Max #tokens: 131\n",
      "11/26/2023 03:13:08 - INFO - run_relation - 4906 (96.92 %) examples can fit max_seq_length = 128\n",
      "11/26/2023 03:13:08 - INFO - run_relation - {'SUBJ_START': '[unused1]', 'SUBJ_END': '[unused2]', 'OBJ_START': '[unused3]', 'OBJ_END': '[unused4]', 'SUBJ=Generic': '[unused5]', 'OBJ=Task': '[unused6]', 'SUBJ_START=Generic': '[unused7]', 'SUBJ_END=Generic': '[unused8]', 'OBJ_START=Task': '[unused9]', 'OBJ_END=Task': '[unused10]', 'OBJ=Material': '[unused11]', 'OBJ_START=Material': '[unused12]', 'OBJ_END=Material': '[unused13]', 'OBJ=OtherScientificTerm': '[unused14]', 'OBJ_START=OtherScientificTerm': '[unused15]', 'OBJ_END=OtherScientificTerm': '[unused16]', 'SUBJ=Task': '[unused17]', 'OBJ=Generic': '[unused18]', 'SUBJ_START=Task': '[unused19]', 'SUBJ_END=Task': '[unused20]', 'OBJ_START=Generic': '[unused21]', 'OBJ_END=Generic': '[unused22]', 'SUBJ=Material': '[unused23]', 'SUBJ_START=Material': '[unused24]', 'SUBJ_END=Material': '[unused25]', 'SUBJ=OtherScientificTerm': '[unused26]', 'SUBJ_START=OtherScientificTerm': '[unused27]', 'SUBJ_END=OtherScientificTerm': '[unused28]', 'OBJ=Method': '[unused29]', 'OBJ_START=Method': '[unused30]', 'OBJ_END=Method': '[unused31]', 'SUBJ=Method': '[unused32]', 'SUBJ_START=Method': '[unused33]', 'SUBJ_END=Method': '[unused34]', 'OBJ=Metric': '[unused35]', 'OBJ_START=Metric': '[unused36]', 'OBJ_END=Metric': '[unused37]', 'SUBJ=Metric': '[unused38]', 'SUBJ_START=Metric': '[unused39]', 'SUBJ_END=Metric': '[unused40]'}\n",
      "11/26/2023 03:13:08 - INFO - run_relation - ***** Test *****\n",
      "11/26/2023 03:13:08 - INFO - run_relation -   Num examples = 5062\n",
      "11/26/2023 03:13:08 - INFO - run_relation -   Batch size = 8\n",
      "11/26/2023 03:13:08 - INFO - transformers.configuration_utils - loading configuration file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/config.json\n",
      "11/26/2023 03:13:08 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/26/2023 03:13:08 - INFO - transformers.modeling_utils - loading weights file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/pytorch_model.bin\n",
      "11/26/2023 03:13:10 - INFO - transformers.modeling_utils - All model checkpoint weights were used when initializing BertForRelation.\n",
      "\n",
      "11/26/2023 03:13:10 - INFO - transformers.modeling_utils - All the weights of BertForRelation were initialized from the model checkpoint at C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForRelation for predictions without further training.\n",
      "11/26/2023 03:16:07 - INFO - run_relation - ***** Eval results *****\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   accuracy = 0.8954958514421177\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   eval_loss = 0.5672574452564818\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   f1 = 0.6833688699360342\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   n_correct = 641\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   n_gold = 974\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   n_pred = 902\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   precision = 0.7106430155210643\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   recall = 0.6581108829568788\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   task_f1 = 0.6833688699360342\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   task_ngold = 974\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   task_recall = 0.6581108829568788\n",
      "11/26/2023 03:16:07 - INFO - run_relation - *** Evaluation Results ***\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   accuracy = 0.8954958514421177\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   eval_loss = 0.5672574452564818\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   f1 = 0.6833688699360342\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   n_correct = 641\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   n_gold = 974\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   n_pred = 902\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   precision = 0.7106430155210643\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   recall = 0.6581108829568788\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   task_f1 = 0.6833688699360342\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   task_ngold = 974\n",
      "11/26/2023 03:16:07 - INFO - run_relation -   task_recall = 0.6581108829568788\n",
      "11/26/2023 03:16:07 - INFO - run_relation - Output predictions to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/rel-scib-ctx0/predictions.json..\n"
     ]
    }
   ],
   "source": [
    "CLS = \"[CLS]\"\n",
    "SEP = \"[SEP]\"\n",
    "\n",
    "RelationModel = BertForRelation\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "# train set\n",
    "if do_train:\n",
    "    train_dataset, train_examples, train_nrel = generate_relation_data(train_file, use_gold=True, context_window=context_window)\n",
    "# dev set\n",
    "if (do_eval and do_train) or (do_eval and not(eval_test)):\n",
    "    eval_dataset, eval_examples, eval_nrel = generate_relation_data(os.path.join(entity_output_dir, entity_predictions_dev), use_gold=eval_with_gold, context_window=context_window)\n",
    "# test set\n",
    "if eval_test:\n",
    "    test_dataset, test_examples, test_nrel = generate_relation_data(os.path.join(entity_output_dir, entity_predictions_test), use_gold=eval_with_gold, context_window=context_window)\n",
    "    \n",
    "setseed(seed)\n",
    "\n",
    "if not do_train and not do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if do_train:\n",
    "    logger.addHandler(logging.FileHandler(os.path.join(output_dir, \"train.log\"), 'w'))\n",
    "else:\n",
    "    logger.addHandler(logging.FileHandler(os.path.join(output_dir, \"eval.log\"), 'w'))\n",
    "    \n",
    "# get label_list\n",
    "if os.path.exists(os.path.join(output_dir, 'label_list.json')):\n",
    "    with open(os.path.join(output_dir, 'label_list.json'), 'r') as f:\n",
    "        label_list = json.load(f)\n",
    "else:\n",
    "    label_list = [negative_label] + task_rel_labels[task]\n",
    "    with open(os.path.join(output_dir, 'label_list.json'), 'w') as f:\n",
    "        json.dump(label_list, f)\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "num_labels = len(label_list)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=do_lower_case)\n",
    "if add_new_tokens:\n",
    "    add_marker_tokens(tokenizer, task_ner_labels[task])\n",
    "\n",
    "if os.path.exists(os.path.join(output_dir, 'special_tokens.json')):\n",
    "    with open(os.path.join(output_dir, 'special_tokens.json'), 'r') as f:\n",
    "        special_tokens = json.load(f)\n",
    "else:\n",
    "    special_tokens = {}\n",
    "    \n",
    "if do_eval and (do_train or not(eval_test)):\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "    logger.info(\"***** Dev *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    all_sub_idx = torch.tensor([f.sub_idx for f in eval_features], dtype=torch.long)\n",
    "    all_obj_idx = torch.tensor([f.obj_idx for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "    eval_dataloader = DataLoader(eval_data, batch_size=eval_batch_size)\n",
    "    eval_label_ids = all_label_ids\n",
    "\n",
    "    \n",
    "if do_train:\n",
    "    train_features = convert_examples_to_features(\n",
    "        train_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "    if train_mode == 'sorted' or train_mode == 'random_sorted':\n",
    "        train_features = sorted(train_features, key=lambda f: np.sum(f.input_mask))\n",
    "    else:\n",
    "        random.shuffle(train_features)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
    "    all_sub_idx = torch.tensor([f.sub_idx for f in train_features], dtype=torch.long)\n",
    "    all_obj_idx = torch.tensor([f.obj_idx for f in train_features], dtype=torch.long)\n",
    "    train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "    train_dataloader = DataLoader(train_data, batch_size=train_batch_size)\n",
    "    train_batches = [batch for batch in train_dataloader]\n",
    "\n",
    "    num_train_optimization_steps = len(train_dataloader) * num_train_epochs\n",
    "\n",
    "    logger.info(\"***** Training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_examples))\n",
    "    logger.info(\"  Batch size = %d\", train_batch_size)\n",
    "    logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "\n",
    "    best_result = None\n",
    "    eval_step = max(1, len(train_batches) // eval_per_epoch)\n",
    "\n",
    "    lr = learning_rate\n",
    "    model = RelationModel.from_pretrained(\n",
    "        'allenai/scibert_scivocab_uncased', cache_dir=str(PYTORCH_PRETRAINED_BERT_CACHE), num_rel_labels=num_labels)\n",
    "    if hasattr(model, 'bert'):\n",
    "        model.bert.resize_token_embeddings(len(tokenizer))\n",
    "    elif hasattr(model, 'albert'):\n",
    "        model.albert.resize_token_embeddings(len(tokenizer))\n",
    "    else:\n",
    "        raise TypeError(\"Unknown model class\")\n",
    "\n",
    "    model.to(device)\n",
    "    if n_gpu > 1:\n",
    "        model = torch.nn.DataParallel(model)\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer\n",
    "                    if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer\n",
    "                    if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr, correct_bias=not(bertadam))\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, int(num_train_optimization_steps * warmup_proportion), num_train_optimization_steps)\n",
    "\n",
    "    start_time = time.time()\n",
    "    global_step = 0\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples = 0\n",
    "    nb_tr_steps = 0\n",
    "    for epoch in range(int(num_train_epochs)):\n",
    "        model.train()\n",
    "        logger.info(\"Start epoch #{} (lr = {})...\".format(epoch, lr))\n",
    "        if train_mode == 'random' or train_mode == 'random_sorted':\n",
    "            random.shuffle(train_batches)\n",
    "        for step, batch in enumerate(train_batches):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids, sub_idx, obj_idx = batch\n",
    "            loss = model(input_ids, segment_ids, input_mask, label_ids, sub_idx, obj_idx)\n",
    "            if n_gpu > 1:\n",
    "                loss = loss.mean()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            nb_tr_examples += input_ids.size(0)\n",
    "            nb_tr_steps += 1\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            global_step += 1\n",
    "\n",
    "            if (step + 1) % eval_step == 0:\n",
    "                logger.info('Epoch: {}, Step: {} / {}, used_time = {:.2f}s, loss = {:.6f}'.format(\n",
    "                            epoch, step + 1, len(train_batches),\n",
    "                            time.time() - start_time, tr_loss / nb_tr_steps))\n",
    "                save_model = False\n",
    "                if do_eval:\n",
    "                    preds, result, logits = evaluate(model, device, eval_dataloader, eval_label_ids, num_labels, e2e_ngold=eval_nrel)\n",
    "                    model.train()\n",
    "                    result['global_step'] = global_step\n",
    "                    result['epoch'] = epoch\n",
    "                    result['learning_rate'] = lr\n",
    "                    result['batch_size'] = train_batch_size\n",
    "\n",
    "                    if (best_result is None) or (result[eval_metric] > best_result[eval_metric]):\n",
    "                        best_result = result\n",
    "                        logger.info(\"!!! Best dev %s (lr=%s, epoch=%d): %.2f\" %\n",
    "                                    (eval_metric, str(lr), epoch, result[eval_metric] * 100.0))\n",
    "                        save_trained_model(output_dir, model, tokenizer)\n",
    "\n",
    "if do_eval:\n",
    "    logger.info(special_tokens)\n",
    "    if eval_test:\n",
    "        eval_dataset = test_dataset\n",
    "        eval_examples = test_examples\n",
    "        eval_features = convert_examples_to_features(\n",
    "            test_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "        eval_nrel = test_nrel\n",
    "        logger.info(special_tokens)\n",
    "        logger.info(\"***** Test *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(test_examples))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "        all_sub_idx = torch.tensor([f.sub_idx for f in eval_features], dtype=torch.long)\n",
    "        all_obj_idx = torch.tensor([f.obj_idx for f in eval_features], dtype=torch.long)\n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "        eval_dataloader = DataLoader(eval_data, batch_size=eval_batch_size)\n",
    "        eval_label_ids = all_label_ids\n",
    "    model = RelationModel.from_pretrained(output_dir, num_rel_labels=num_labels)\n",
    "    model.to(device)\n",
    "    preds, result, logits = evaluate(model, device, eval_dataloader, eval_label_ids, num_labels, e2e_ngold=eval_nrel)\n",
    "\n",
    "    logger.info('*** Evaluation Results ***')\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "\n",
    "    print_pred_json(eval_dataset, eval_examples, preds, id2label, os.path.join(output_dir, prediction_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dfa5fe-f827-4be4-a8da-26882facb535",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "**Accuracy**: 0.8954\n",
    "\n",
    "**Evaluation Loss**: 0.5672\n",
    "\n",
    "**Precision**: 0.7106\\\n",
    "**Recall**: 0.6581\\\n",
    "**F1 Score**: 0.6833\n",
    "\n",
    "Implications:\n",
    "\n",
    "- Our model has a higher accuracy, indicating that it makes correct predictions for a larger proportion of the test set.\n",
    "- The pre-trained model has a lower evaluation loss, suggesting better performance in terms of model fit.\n",
    "- Our model has a higher F1 score, indicating a better balance between precision and recall.\n",
    "- Our model has higher precision, suggesting that a larger proportion of its predicted positive instances are correct.\n",
    "- The pre-trained model has slightly higher recall, indicating that it identifies a larger proportion of actual positive instances.\n",
    "\n",
    "Our model generally outperforms the pre-trained model across most metrics. It has higher accuracy, a better F1 score, higher precision, and slightly lower recall. However, it's important to consider the specific requirements and goals of our application:\n",
    "\n",
    "- If precision is crucial (minimizing false positives), our model is more favorable.\n",
    "- If recall is crucial (minimizing false negatives), the pre-trained model has a slight edge.\n",
    "- The difference in evaluation loss suggests that the pre-trained model may have better overall model fit.\n",
    "\n",
    "In summary, the model is performing well in identifying entity relations, but there is still room for improvement, particularly in precision. The results provide insights into how well the model is generalizing to unseen data and its effectiveness in extracting relations between entities. Fine-tuning or adjusting the model architecture may be considered to further improve performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
