{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a36f482-69ce-456b-94df-b5b51ef7179b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (3.6.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: tqdm in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: click in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from click->nltk) (4.8.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from click->nltk) (0.4.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from importlib-metadata->click->nltk) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from importlib-metadata->click->nltk) (3.6.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from tqdm->nltk) (5.4.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40713b5a-48e9-4bc7-a1e2-b787a1e75f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\odaim\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a584feb3-b404-42f2-a0c3-f4ebf28df1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from unidecode import unidecode\n",
    "\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d9d94438-b724-4efc-97ad-00dd205675a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_nyt_sample(sample):\n",
    "    data = json.loads(sample)\n",
    "    sentence = data['sentText'].replace('Jr.', 'Jr')\n",
    "    sentence = sentence.replace('U.S.A.', 'U.S.A')\n",
    "    sentence = sentence.replace('P.M.', 'P.M')\n",
    "    tokens = word_tokenize(sentence)\n",
    "    norm = {}\n",
    "    norm['doc_key'] = data['articleId']\n",
    "    norm['sentences'] = [tokens]\n",
    "    norm['ner'] = []\n",
    "    norm['relations'] = []\n",
    "    norm['clusters'] = []\n",
    "    # print(tokens)\n",
    "    for entity in data['entityMentions']:\n",
    "        ent = entity['text'].replace('Jr.', 'Jr')\n",
    "        ent = ent.replace('U.S.A.', 'U.S.A')\n",
    "        ent = ent.replace('P.M.', 'P.M')\n",
    "        ner = word_tokenize(ent)\n",
    "        # print(ner)\n",
    "        label = entity['label'].title()\n",
    "        norm['ner'].append([tokens.index(ner[0]), tokens.index(ner[-1]), label])\n",
    "        \n",
    "    for relation in data['relationMentions']:\n",
    "        label = relation['label'].split('/')[-1].replace('_','-').upper()\n",
    "        source = unidecode(relation['em1Text'].replace('Jr.', 'Jr'))\n",
    "        source = word_tokenize(source)\n",
    "        # print(source)\n",
    "        target = unidecode(relation['em2Text'].replace('Jr.', 'Jr'))\n",
    "        target = word_tokenize(target)\n",
    "        # print(target)\n",
    "        norm['relations'].append([tokens.index(source[0]), tokens.index(source[-1]), tokens.index(target[0]), tokens.index(target[-1]), label])\n",
    "        \n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5ea99c6-0b94-4376-95cb-fb21a189e94d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_key': '/m/vinci8/data1/riedel/projects/relation/kb/nyt1/docstore/nyt-2005-2006.backup/1674506.xml.pb',\n",
       " 'sentences': [['Was',\n",
       "   'it',\n",
       "   'just',\n",
       "   'last',\n",
       "   'month',\n",
       "   'that',\n",
       "   'Wal-Mart',\n",
       "   \"'s\",\n",
       "   'chief',\n",
       "   'executive',\n",
       "   ',',\n",
       "   'H.',\n",
       "   'Lee',\n",
       "   'Scott',\n",
       "   'Jr',\n",
       "   ',',\n",
       "   'said',\n",
       "   'his',\n",
       "   'company',\n",
       "   'would',\n",
       "   'be',\n",
       "   'a',\n",
       "   'kinder',\n",
       "   ',',\n",
       "   'gentler',\n",
       "   'corporate',\n",
       "   'citizen',\n",
       "   'and',\n",
       "   'never',\n",
       "   'again',\n",
       "   'bulldoze',\n",
       "   'a',\n",
       "   'local',\n",
       "   'government',\n",
       "   'to',\n",
       "   'let',\n",
       "   'it',\n",
       "   'open',\n",
       "   'more',\n",
       "   'stores',\n",
       "   '?']],\n",
       " 'ner': [[6, 6, 'Organization'], [11, 14, 'Person']],\n",
       " 'relations': [[11, 14, 6, 6, 'COMPANY']],\n",
       " 'clusters': []}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samp = \"\"\"{\"sentText\": \"Was it just last month that Wal-Mart 's chief executive , H. Lee Scott Jr. , said his company would be a kinder , gentler corporate citizen and never again bulldoze a local government to let it open more stores ?\", \"articleId\": \"/m/vinci8/data1/riedel/projects/relation/kb/nyt1/docstore/nyt-2005-2006.backup/1674506.xml.pb\", \"relationMentions\": [{\"em1Text\": \"H. Lee Scott Jr.\", \"em2Text\": \"Wal-Mart\", \"label\": \"/business/person/company\"}], \"entityMentions\": [{\"start\": 0, \"label\": \"ORGANIZATION\", \"text\": \"Wal-Mart\"}, {\"start\": 1, \"label\": \"PERSON\", \"text\": \"H. Lee Scott Jr.\"}], \"sentId\": \"1\"}\"\"\"\n",
    "normalize_nyt_sample(samp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e0c3ec36-eec8-41b6-a602-710a085ae7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_data_dir = os.getcwd() + '/other_data/nyt_er_dataset/'\n",
    "\n",
    "def write_normal_data(in_dir, out_dir):\n",
    "    with open(in_dir) as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                maped_sample = normalize_nyt_sample(line)\n",
    "            except:\n",
    "                print(line)\n",
    "                break\n",
    "            with open(out_dir, 'a') as normalized:\n",
    "                normalized.write(json.dumps(maped_sample) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f268683e-e20d-4d8f-9680-18ca1f87f400",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_train_data_path = nyt_data_dir + 'train.json'\n",
    "nyt_train_norm_data_path = nyt_data_dir + 'norm_train.json'\n",
    "            \n",
    "write_normal_data(nyt_train_data_path, nyt_train_norm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cea0443f-7f01-4d13-9a0b-e453e2d655e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_valid_data_path = nyt_data_dir + 'valid.json'\n",
    "nyt_valid_norm_data_path = nyt_data_dir + 'norm_valid.json'\n",
    "\n",
    "write_normal_data(nyt_valid_data_path, nyt_valid_norm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4517c437-eba5-4e61-8e86-46551fca5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_test_data_path = nyt_data_dir + 'test.json'\n",
    "nyt_test_norm_data_path = nyt_data_dir + 'norm_test.json'\n",
    "\n",
    "write_normal_data(nyt_test_data_path, nyt_test_norm_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed663f8-4d07-4641-81ea-7105ca2abcb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
