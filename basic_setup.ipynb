{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73495d61",
   "metadata": {},
   "source": [
    "# PURE: Entity and Relation Extraction from Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048dd97",
   "metadata": {},
   "source": [
    "This is a reproduction of the results presnseted in the research paper [A Frustratingly Easy Approach for Entity and Relation Extraction](https://arxiv.org/pdf/2010.12812.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e7bd28",
   "metadata": {},
   "source": [
    "##### Environment information\n",
    "Windows 11\n",
    "\n",
    "Python 3.6.13\n",
    "\n",
    "pip 21.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665e2d3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770621e",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7994cfd",
   "metadata": {},
   "source": [
    "The authors first instruct us to run the following comand to install all the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c41f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from -r requirements.txt (line 1)) (4.64.1)\n",
      "Collecting allennlp==0.9.0\n",
      "  Downloading allennlp-0.9.0-py3-none-any.whl (7.6 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from versions: 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2)\n",
      "ERROR: No matching distribution found for torch==1.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828905df",
   "metadata": {},
   "source": [
    "But as you can see, that didn't really work. At least not in my environment. The requirements.text includes a quite older vaersion of PyTorch. Namely, version 1.4.0. Trying to install it with pip just didn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1c761",
   "metadata": {},
   "source": [
    "So I did some digging and found [this stackoverflow question](https://stackoverflow.com/questions/56239310/could-not-find-a-version-that-satisfies-the-requirement-torch-1-0-0), which had this comand in one of the answers by [Sandokan](https://stackoverflow.com/users/8168933/sandokan):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ce9ff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch===1.4.0\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.4.0-cp36-cp36m-win_amd64.whl (796.8 MB)\n",
      "Collecting torchvision===0.5.0\n",
      "  Downloading torchvision-0.5.0-cp36-cp36m-win_amd64.whl (1.2 MB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from torchvision===0.5.0) (1.16.0)\n",
      "Collecting pillow>=4.1.1\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-win_amd64.whl (3.2 MB)\n",
      "Installing collected packages: torch, pillow, numpy, torchvision\n",
      "Successfully installed numpy-1.19.5 pillow-8.4.0 torch-1.4.0 torchvision-0.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0fa89",
   "metadata": {},
   "source": [
    "That worked like a charm!\n",
    "\n",
    "No let's try isntalling the rest of the requirements with the same original comand: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9ddab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from -r requirements.txt (line 1)) (4.64.1)\n",
      "Collecting allennlp==0.9.0\n",
      "  Using cached allennlp-0.9.0-py3-none-any.whl (7.6 MB)\n",
      "Requirement already satisfied: torch==1.4.0 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Collecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "Collecting overrides==3.1.0\n",
      "  Downloading overrides-3.1.0.tar.gz (11 kB)\n",
      "Collecting requests==2.25.1\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting flask-cors>=3.0.7\n",
      "  Downloading Flask_Cors-4.0.1-py2.py3-none-any.whl (14 kB)\n",
      "Collecting numpydoc>=0.8.0\n",
      "  Downloading numpydoc-1.1.0-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: unidecode in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from allennlp==0.9.0->-r requirements.txt (line 2)) (1.3.8)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from allennlp==0.9.0->-r requirements.txt (line 2)) (2021.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from allennlp==0.9.0->-r requirements.txt (line 2)) (3.6.7)\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
      "Collecting pytorch-pretrained-bert>=0.6.0\n",
      "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Collecting flask>=1.0.2\n",
      "  Downloading Flask-2.0.3-py3-none-any.whl (95 kB)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.23.10-py3-none-any.whl (132 kB)\n",
      "Collecting gevent>=1.3.6\n",
      "  Downloading gevent-22.10.2-cp36-cp36m-win_amd64.whl (1.5 MB)\n",
      "Collecting parsimonious>=0.8.0\n",
      "  Downloading parsimonious-0.10.0-py3-none-any.whl (48 kB)\n",
      "Collecting conllu==1.3.1\n",
      "  Downloading conllu-1.3.1-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting spacy<2.2,>=2.1.0\n",
      "  Downloading spacy-2.1.9-cp36-cp36m-win_amd64.whl (30.0 MB)\n",
      "Collecting pytest\n",
      "  Downloading pytest-7.0.1-py3-none-any.whl (296 kB)\n",
      "Collecting h5py\n",
      "  Downloading h5py-3.1.0-cp36-cp36m-win_amd64.whl (2.7 MB)\n",
      "Collecting flaky\n",
      "  Downloading flaky-3.8.1-py2.py3-none-any.whl (19 kB)\n",
      "Collecting editdistance\n",
      "  Downloading editdistance-0.6.2-cp36-cp36m-win_amd64.whl (24 kB)\n",
      "Collecting jsonpickle\n",
      "  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting word2number>=1.1\n",
      "  Downloading word2number-1.1.zip (9.7 kB)\n",
      "Collecting matplotlib>=2.2.3\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-win_amd64.whl (8.5 MB)\n",
      "Collecting tensorboardX>=1.2\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Collecting pytorch-transformers==1.1.0\n",
      "  Downloading pytorch_transformers-1.1.0-py3-none-any.whl (158 kB)\n",
      "Collecting responses>=0.7\n",
      "  Downloading responses-0.17.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting scipy"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The candidate selected for download or install is a yanked version: 'protobuf' candidate (version 4.21.0 at https://files.pythonhosted.org/packages/27/82/986065ef305c0989c99d8ef3f29e58a03fac6e64bb2c36ffe64500cc6955/protobuf-4.21.0-py3-none-any.whl#sha256=4e78116673ba04e01e563f6a9cca2c72db0be8a3e1629094816357e81cc39d36 (from https://pypi.org/simple/protobuf/))\n",
      "Reason for being yanked: Required python version not configured correctly (https://github.com/protocolbuffers/protobuf/issues/10076)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Collecting sqlparse>=0.2.4\n",
      "  Downloading sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from allennlp==0.9.0->-r requirements.txt (line 2)) (1.19.5)\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1-cp36-cp36m-win_amd64.whl (1.9 MB)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from transformers==3.0.2->-r requirements.txt (line 4)) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from transformers==3.0.2->-r requirements.txt (line 4)) (2023.8.8)\n",
      "Requirement already satisfied: packaging in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from transformers==3.0.2->-r requirements.txt (line 4)) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Downloading sentencepiece-0.2.0-cp36-cp36m-win_amd64.whl (1.0 MB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from requests==2.25.1->-r requirements.txt (line 6)) (1.26.8)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from requests==2.25.1->-r requirements.txt (line 6)) (2021.5.30)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from tqdm->-r requirements.txt (line 1)) (5.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from tqdm->-r requirements.txt (line 1)) (0.4.4)\n",
      "Requirement already satisfied: click>=7.1.2 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from flask>=1.0.2->allennlp==0.9.0->-r requirements.txt (line 2)) (8.0.4)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Downloading itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from flask>=1.0.2->allennlp==0.9.0->-r requirements.txt (line 2)) (3.0.3)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from click>=7.1.2->flask>=1.0.2->allennlp==0.9.0->-r requirements.txt (line 2)) (4.8.1)\n",
      "Collecting zope.event\n",
      "  Downloading zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting zope.interface\n",
      "  Downloading zope.interface-5.5.2-cp36-cp36m-win_amd64.whl (211 kB)\n",
      "Requirement already satisfied: cffi>=1.12.2 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from gevent>=1.3.6->allennlp==0.9.0->-r requirements.txt (line 2)) (1.14.6)\n",
      "Collecting greenlet>=2.0.0\n",
      "  Downloading greenlet-2.0.2-cp36-cp36m-win_amd64.whl (197 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from gevent>=1.3.6->allennlp==0.9.0->-r requirements.txt (line 2)) (58.0.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from cffi>=1.12.2->gevent>=1.3.6->allennlp==0.9.0->-r requirements.txt (line 2)) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from Jinja2>=3.0->flask>=1.0.2->allennlp==0.9.0->-r requirements.txt (line 2)) (2.0.1)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from matplotlib>=2.2.3->allennlp==0.9.0->-r requirements.txt (line 2)) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from matplotlib>=2.2.3->allennlp==0.9.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-win_amd64.whl (51 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from matplotlib>=2.2.3->allennlp==0.9.0->-r requirements.txt (line 2)) (8.4.0)\n",
      "Collecting sphinx>=1.6.5\n",
      "  Downloading sphinx-5.3.0-py3-none-any.whl (3.2 MB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=2.2.3->allennlp==0.9.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Collecting blis<0.3.0,>=0.2.2\n",
      "  Downloading blis-0.2.4-cp36-cp36m-win_amd64.whl (3.1 MB)\n",
      "Collecting srsly<1.1.0,>=0.0.6\n",
      "  Downloading srsly-1.0.7-cp36-cp36m-win_amd64.whl (367 kB)\n",
      "Collecting wasabi<1.1.0,>=0.2.0\n",
      "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting thinc<7.1.0,>=7.0.8\n",
      "  Downloading thinc-7.0.8-cp36-cp36m-win_amd64.whl (1.9 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp36-cp36m-win_amd64.whl (46 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp36-cp36m-win_amd64.whl (27 kB)\n",
      "Collecting preshed<2.1.0,>=2.0.1\n",
      "  Downloading preshed-2.0.1-cp36-cp36m-win_amd64.whl (73 kB)\n",
      "Collecting plac<1.0.0,>=0.9.6\n",
      "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
      "  Downloading sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.5\n",
      "  Downloading sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
      "Collecting imagesize>=1.3\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting sphinxcontrib-qthelp\n",
      "  Downloading sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "Collecting Pygments>=2.12\n",
      "  Downloading Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting snowballstemmer>=2.0\n",
      "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting sphinxcontrib-jsmath\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting docutils<0.20,>=0.14\n",
      "  Downloading docutils-0.18.1-py2.py3-none-any.whl (570 kB)\n",
      "Collecting sphinxcontrib-devhelp\n",
      "  Downloading sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "Collecting colorama\n",
      "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Collecting alabaster<0.8,>=0.7\n",
      "  Downloading alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
      "Collecting sphinxcontrib-applehelp\n",
      "  Downloading sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: babel>=2.9 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp==0.9.0->-r requirements.txt (line 2)) (2.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from importlib-metadata->click>=7.1.2->flask>=1.0.2->allennlp==0.9.0->-r requirements.txt (line 2)) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from importlib-metadata->click>=7.1.2->flask>=1.0.2->allennlp==0.9.0->-r requirements.txt (line 2)) (3.6.0)\n",
      "Collecting protobuf>=3.20\n",
      "  Downloading protobuf-4.21.0-py3-none-any.whl (291 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Downloading s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.27.0,>=1.26.10\n",
      "  Downloading botocore-1.26.10-py3-none-any.whl (8.8 MB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from ftfy->allennlp==0.9.0->-r requirements.txt (line 2)) (0.2.5)\n",
      "Collecting cached-property\n",
      "  Downloading cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from nltk->allennlp==0.9.0->-r requirements.txt (line 2)) (1.1.1)\n",
      "Collecting py>=1.8.2\n",
      "  Downloading py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\odaim\\anaconda3\\envs\\pure\\lib\\site-packages (from pytest->allennlp==0.9.0->-r requirements.txt (line 2)) (21.4.0)\n",
      "Collecting atomicwrites>=1.0\n",
      "  Downloading atomicwrites-1.4.1.tar.gz (14 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Downloading tomli-1.2.3-py3-none-any.whl (12 kB)\n",
      "Collecting iniconfig\n",
      "  Downloading iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Downloading pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Building wheels for collected packages: overrides, word2number, ftfy, atomicwrites, sacremoses\n",
      "  Building wheel for overrides (setup.py): started\n",
      "  Building wheel for overrides (setup.py): finished with status 'done'\n",
      "  Created wheel for overrides: filename=overrides-3.1.0-py3-none-any.whl size=10187 sha256=1d6d8bc784bd511c4174ce2e1cf8a92b1200f93c9d1e816bb1adfabfbf0fc521\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\e6\\3b\\34\\ae59fc8d35c37f01099425ab73599e45e9b9b599a7ccc2c45f\n",
      "  Building wheel for word2number (setup.py): started\n",
      "  Building wheel for word2number (setup.py): finished with status 'done'\n",
      "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5582 sha256=3c8a5ac7a526ecaff214d93b8c1d76e461cf8e3837a65e687f5b6585a0aa5144\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\6c\\5e\\36\\8b922f014b64e2a45bac622008bc439281784eb1e09fe5d8d5\n",
      "  Building wheel for ftfy (setup.py): started\n",
      "  Building wheel for ftfy (setup.py): finished with status 'done'\n",
      "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=6a4edb8250e59ae54924e65b5cb7ae5d1ca9e5c3aaa9aa03e1e65b072aaecc59\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\ff\\2a\\24\\75041425faf3347ab146a4a3d0484f723b2c44a7966a06e3f0\n",
      "  Building wheel for atomicwrites (setup.py): started\n",
      "  Building wheel for atomicwrites (setup.py): finished with status 'done'\n",
      "  Created wheel for atomicwrites: filename=atomicwrites-1.4.1-py2.py3-none-any.whl size=6957 sha256=f64e1446e69e32816496ba50a48b85f98a1f2c32da218c2ef2df9990b1e1321d\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\a1\\e7\\28\\46d397595a418eb7ce1a8e6bbdfcea9e73753249bc824cc9cb\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=c978f318fe2b4724df9f4bf7a42370722609227700f15adcbe93ab5f8af6a083\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\4c\\64\\31\\e9900a234b23fb3e9dc565d6114a9d6ff84a72dbdd356502b4\n",
      "Successfully built overrides word2number ftfy atomicwrites sacremoses\n",
      "Installing collected packages: jmespath, idna, cymem, colorama, chardet, botocore, Werkzeug, wasabi, srsly, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, snowballstemmer, s3transfer, requests, Pygments, preshed, plac, murmurhash, itsdangerous, imagesize, docutils, blis, alabaster, zope.interface, zope.event, tomli, threadpoolctl, thinc, sphinx, sentencepiece, scipy, py, protobuf, pluggy, kiwisolver, iniconfig, greenlet, flask, cycler, cached-property, boto3, atomicwrites, word2number, tokenizers, tensorboardX, sqlparse, spacy, scikit-learn, sacremoses, responses, pytorch-transformers, pytorch-pretrained-bert, pytest, parsimonious, overrides, numpydoc, matplotlib, jsonpickle, h5py, gevent, ftfy, flask-cors, flaky, filelock, editdistance, conllu, transformers, allennlp\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.3\n",
      "    Uninstalling idna-3.3:\n",
      "      Successfully uninstalled idna-3.3\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.27.1\n",
      "    Uninstalling requests-2.27.1:\n",
      "      Successfully uninstalled requests-2.27.1\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed Pygments-2.14.0 Werkzeug-2.0.3 alabaster-0.7.13 allennlp-0.9.0 atomicwrites-1.4.1 blis-0.2.4 boto3-1.23.10 botocore-1.26.10 cached-property-1.5.2 chardet-4.0.0 colorama-0.4.5 conllu-1.3.1 cycler-0.11.0 cymem-2.0.8 docutils-0.18.1 editdistance-0.6.2 filelock-3.4.1 flaky-3.8.1 flask-2.0.3 flask-cors-4.0.1 ftfy-6.0.3 gevent-22.10.2 greenlet-2.0.2 h5py-3.1.0 idna-2.10 imagesize-1.4.1 iniconfig-1.1.1 itsdangerous-2.0.1 jmespath-0.10.0 jsonpickle-2.2.0 kiwisolver-1.3.1 matplotlib-3.3.4 murmurhash-1.0.10 numpydoc-1.1.0 overrides-3.1.0 parsimonious-0.10.0 plac-0.9.6 pluggy-1.0.0 preshed-2.0.1 protobuf-4.21.0 py-1.11.0 pytest-7.0.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 requests-2.25.1 responses-0.17.0 s3transfer-0.5.2 sacremoses-0.0.53 scikit-learn-0.24.2 scipy-1.5.4 sentencepiece-0.2.0 snowballstemmer-2.2.0 spacy-2.1.9 sphinx-5.3.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 sqlparse-0.4.4 srsly-1.0.7 tensorboardX-2.6.2.2 thinc-7.0.8 threadpoolctl-3.1.0 tokenizers-0.8.1rc1 tomli-1.2.3 transformers-3.0.2 wasabi-0.10.1 word2number-1.1 zope.event-4.6 zope.interface-5.5.2\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3bf34",
   "metadata": {},
   "source": [
    "There we go! There's a little warning, but let's pertend we didn't see that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b76ebf",
   "metadata": {},
   "source": [
    "### Download and preprocess the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18464cc9",
   "metadata": {},
   "source": [
    "Next, the authors ask us to download and process the datasets\n",
    "Their experiments are based on three datasets: ACE04, ACE05, and SciERC. Please find the links and pre-processing below:\n",
    "* ACE04/ACE05: We use the preprocessing code from [DyGIE repo](https://github.com/luanyi/DyGIE/tree/master/preprocessing). Please follow the instructions to preprocess the ACE05 and ACE04 datasets.\n",
    "* SciERC: The preprocessed SciERC dataset can be downloaded in their project [website](http://nlp.cs.washington.edu/sciIE/).\n",
    "\n",
    "Let's do that in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109dfd96",
   "metadata": {},
   "source": [
    "## Quick Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674b9ec",
   "metadata": {},
   "source": [
    "For this reproduction, we will use the pre-trained models provided by the authors. And we will start with the SciERC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a36392bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clint\n",
      "  Downloading clint-0.5.1.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting args\n",
      "  Downloading args-0.1.0.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: clint, args\n",
      "  Building wheel for clint (setup.py): started\n",
      "  Building wheel for clint (setup.py): finished with status 'done'\n",
      "  Created wheel for clint: filename=clint-0.5.1-py3-none-any.whl size=34458 sha256=362cf8d8bbfcf083639eb05965cfbbefd23e2defeb0d69747083d96324b38260\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\2c\\69\\16\\04ffdd2e6fbbf2b3aa97970ba8d01c36d09df025f19f25c57e\n",
      "  Building wheel for args (setup.py): started\n",
      "  Building wheel for args (setup.py): finished with status 'done'\n",
      "  Created wheel for args: filename=args-0.1.0-py3-none-any.whl size=3321 sha256=e53dc3c1bf6de0fcf15aacd97872c9b249ae6ab5600eb730aeb0af4a54920dcb\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\35\\22\\2d\\ee3fc491993d35adc89bcc8f558090cabefeff184a9537928d\n",
      "Successfully built clint args\n",
      "Installing collected packages: args, clint\n",
      "Successfully installed args-0.1.0 clint-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install clint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b6a1fd",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "Let's implenet some functions to help us\n",
    " - Dowanload files\n",
    " - Extract tar files\n",
    " - Unzip zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93da120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(file_name, url):\n",
    "    file_name = os.getcwd() + file_name\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    # Throw an error for bad status codes\n",
    "    r.raise_for_status()\n",
    "\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pbar = tqdm(unit=\"B\", total=int(r.headers['Content-Length']), position=0, leave=True, desc='Downloading')\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                pbar.update(len(chunk))\n",
    "                f.write(chunk)\n",
    "\n",
    "import tarfile \n",
    "\n",
    "def extract_tar_file(file_name, target_directory):\n",
    "    with tarfile.open(name=os.getcwd() + file_name) as tar:\n",
    "\n",
    "        # Go over each member\n",
    "        for member in tqdm(iterable=tar.getmembers(), total=len(tar.getmembers()), desc='Extracting'):\n",
    "            tar.extract(member=member, path=os.getcwd() + target_directory) \n",
    "\n",
    "import zipfile\n",
    "\n",
    "def unzip_file(file_name, target_directory):\n",
    "    with zipfile.ZipFile(os.getcwd() + file_name) as zf:\n",
    "        for member in tqdm(zf.infolist(), desc='Extracting'):\n",
    "            zf.extract(member, os.getcwd() + target_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cc5cc",
   "metadata": {},
   "source": [
    "### Download and extract the SciERC dataset\n",
    "This is the first step to get the data that we will run the pretrained models on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6f1941f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 695340151/695340151 [02:17<00:00, 5061976.13B/s] \n"
     ]
    }
   ],
   "source": [
    "# Downlaod the SciERC dataset\n",
    "download_file('/scierc_data/sciERC_processed.tar.gz', 'http://nlp.cs.washington.edu/sciIE/data/sciERC_processed.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d16fa281",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'extract_tar_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0aaf62fdd3b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Extract the SciERC dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mextract_tar_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/scierc_data/sciERC_processed.tar.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/scierc_data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'extract_tar_file' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the SciERC dataset\n",
    "extract_tar_file('/scierc_data/sciERC_processed.tar.gz', '/scierc_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db5100",
   "metadata": {},
   "source": [
    "### Download and extract the pre-trained entity model\n",
    "Now we will downlaod the pre-trained entity model to use it to extract entities from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f6bd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 409227718/409227718 [01:10<00:00, 5842408.54B/s] \n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained entity model\n",
    "download_file('/scierc_models/ent-scib-ctx0.zip', 'https://nlp.cs.princeton.edu/projects/pure/scierc_models/ent-scib-ctx0.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd43061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 6/6 [00:02<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "### Unzip the pre-trained entity model\n",
    "unzip_file('/scierc_models/ent-scib-ctx0.zip', '/scierc_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec19337",
   "metadata": {},
   "source": [
    "### Download and extract the pre-trained relation model\n",
    "Now we'll do the same for the relation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4553e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 408246037/408246037 [00:22<00:00, 17918528.12B/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained relation model\n",
    "download_file('/scierc_models/rel-scib-ctx0.zip', 'https://nlp.cs.princeton.edu/projects/pure/scierc_models/rel-scib-ctx0.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb74bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 6/6 [00:02<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Unzip the pre-trained relation model\n",
    "unzip_file('/scierc_models/rel-scib-ctx0.zip', '/scierc_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fe617",
   "metadata": {},
   "source": [
    "### Download and extract the pre-trained approximation relation model\n",
    "And one last time for the approximation relation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "196e179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 408248055/408248055 [00:31<00:00, 13067492.36B/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained approximation relation model\n",
    "download_file('/scierc_models/rel_approx-scib-ctx0.zip', 'https://nlp.cs.princeton.edu/projects/pure/scierc_models/rel_approx-scib-ctx0.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d4663ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 6/6 [00:02<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Unzip the pre-trained approximation relation model\n",
    "unzip_file('/scierc_models/rel_approx-scib-ctx0.zip', '/scierc_models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
