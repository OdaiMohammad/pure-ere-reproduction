{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73495d61",
   "metadata": {},
   "source": [
    "# PURE: Entity and Relation Extraction from Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048dd97",
   "metadata": {},
   "source": [
    "This is a reproduction of the results presnseted in the research paper [A Frustratingly Easy Approach for Entity and Relation Extraction](https://arxiv.org/pdf/2010.12812.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e7bd28",
   "metadata": {},
   "source": [
    "##### Environment information\n",
    "Windows 11\n",
    "\n",
    "Python 3.6.13\n",
    "\n",
    "pip 21.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f665e2d3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1770621e",
   "metadata": {},
   "source": [
    "### Install dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7994cfd",
   "metadata": {},
   "source": [
    "The authors first instruct us to run the following comand to install all the requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c41f869",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement torch==1.4.0 (from versions: 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting allennlp==0.9.0\n",
      "  Using cached allennlp-0.9.0-py3-none-any.whl (7.6 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "ERROR: No matching distribution found for torch==1.4.0\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828905df",
   "metadata": {},
   "source": [
    "But as you can see, that didn't really work. At least not in my environment. The requirements.text includes a quite older vaersion of PyTorch. Namely, version 1.4.0. Trying to install it with pip just didn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d1c761",
   "metadata": {},
   "source": [
    "So I did some digging and found [this stackoverflow question](https://stackoverflow.com/questions/56239310/could-not-find-a-version-that-satisfies-the-requirement-torch-1-0-0), which had this comand in one of the answers by [Sandokan](https://stackoverflow.com/users/8168933/sandokan):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ce9ff25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch===1.4.0\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.4.0-cp36-cp36m-win_amd64.whl (796.8 MB)\n",
      "Collecting torchvision===0.5.0\n",
      "  Using cached torchvision-0.5.0-cp36-cp36m-win_amd64.whl (1.2 MB)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.19.5-cp36-cp36m-win_amd64.whl (13.2 MB)\n",
      "Requirement already satisfied: six in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from torchvision===0.5.0) (1.16.0)\n",
      "Collecting pillow>=4.1.1\n",
      "  Using cached Pillow-8.4.0-cp36-cp36m-win_amd64.whl (3.2 MB)\n",
      "Installing collected packages: torch, pillow, numpy, torchvision\n",
      "Successfully installed numpy-1.19.5 pillow-8.4.0 torch-1.4.0 torchvision-0.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install torch===1.4.0 torchvision===0.5.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a0fa89",
   "metadata": {},
   "source": [
    "That worked like a charm!\n",
    "\n",
    "No let's try isntalling the rest of the requirements with the same original comand: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ddab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Using cached tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
      "Collecting allennlp==0.9.0\n",
      "  Using cached allennlp-0.9.0-py3-none-any.whl (7.6 MB)\n",
      "Requirement already satisfied: torch==1.4.0 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from -r requirements.txt (line 3)) (1.4.0)\n",
      "Collecting transformers==3.0.2\n",
      "  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "Collecting overrides==3.1.0\n",
      "  Using cached overrides-3.1.0-py3-none-any.whl\n",
      "Collecting requests==2.25.1\n",
      "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.5.4-cp36-cp36m-win_amd64.whl (31.2 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from allennlp==0.9.0->-r requirements.txt (line 2)) (1.19.5)\n",
      "Collecting matplotlib>=2.2.3\n",
      "  Using cached matplotlib-3.3.4-cp36-cp36m-win_amd64.whl (8.5 MB)\n",
      "Collecting nltk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: The candidate selected for download or install is a yanked version: 'protobuf' candidate (version 4.21.0 at https://files.pythonhosted.org/packages/27/82/986065ef305c0989c99d8ef3f29e58a03fac6e64bb2c36ffe64500cc6955/protobuf-4.21.0-py3-none-any.whl#sha256=4e78116673ba04e01e563f6a9cca2c72db0be8a3e1629094816357e81cc39d36 (from https://pypi.org/simple/protobuf/))\n",
      "Reason for being yanked: Required python version not configured correctly (https://github.com/protocolbuffers/protobuf/issues/10076)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Using cached nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
      "Collecting parsimonious>=0.8.0\n",
      "  Using cached parsimonious-0.10.0-py3-none-any.whl (48 kB)\n",
      "Collecting sqlparse>=0.2.4\n",
      "  Using cached sqlparse-0.4.4-py3-none-any.whl (41 kB)\n",
      "Collecting word2number>=1.1\n",
      "  Using cached word2number-1.1-py3-none-any.whl\n",
      "Collecting unidecode\n",
      "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
      "Collecting ftfy\n",
      "  Using cached ftfy-6.0.3-py3-none-any.whl\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-0.24.2-cp36-cp36m-win_amd64.whl (6.8 MB)\n",
      "Collecting flaky\n",
      "  Using cached flaky-3.7.0-py2.py3-none-any.whl (22 kB)\n",
      "Collecting jsonpickle\n",
      "  Using cached jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting boto3\n",
      "  Using cached boto3-1.23.10-py3-none-any.whl (132 kB)\n",
      "Collecting numpydoc>=0.8.0\n",
      "  Using cached numpydoc-1.1.0-py3-none-any.whl (47 kB)\n",
      "Collecting pytorch-transformers==1.1.0\n",
      "  Using cached pytorch_transformers-1.1.0-py3-none-any.whl (158 kB)\n",
      "Collecting gevent>=1.3.6\n",
      "  Using cached gevent-22.10.2-cp36-cp36m-win_amd64.whl (1.5 MB)\n",
      "Collecting pytest\n",
      "  Using cached pytest-7.0.1-py3-none-any.whl (296 kB)\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2023.3.post1-py2.py3-none-any.whl (502 kB)\n",
      "Collecting h5py\n",
      "  Using cached h5py-3.1.0-cp36-cp36m-win_amd64.whl (2.7 MB)\n",
      "Collecting pytorch-pretrained-bert>=0.6.0\n",
      "  Using cached pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
      "Collecting tensorboardX>=1.2\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "Collecting conllu==1.3.1\n",
      "  Using cached conllu-1.3.1-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting responses>=0.7\n",
      "  Using cached responses-0.17.0-py2.py3-none-any.whl (38 kB)\n",
      "Collecting editdistance\n",
      "  Using cached editdistance-0.6.2-cp36-cp36m-win_amd64.whl (24 kB)\n",
      "Collecting flask>=1.0.2\n",
      "  Using cached Flask-2.0.3-py3-none-any.whl (95 kB)\n",
      "Collecting spacy<2.2,>=2.1.0\n",
      "  Using cached spacy-2.1.9-cp36-cp36m-win_amd64.whl (30.0 MB)\n",
      "Collecting flask-cors>=3.0.7\n",
      "  Using cached Flask_Cors-4.0.0-py2.py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from transformers==3.0.2->-r requirements.txt (line 4)) (21.3)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Using cached sentencepiece-0.1.99-cp36-cp36m-win_amd64.whl (990 kB)\n",
      "Collecting dataclasses\n",
      "  Using cached dataclasses-0.8-py3-none-any.whl (19 kB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2023.8.8-cp36-cp36m-win_amd64.whl (280 kB)\n",
      "Collecting sacremoses\n",
      "  Using cached sacremoses-0.0.53-py3-none-any.whl\n",
      "Collecting tokenizers==0.8.1.rc1\n",
      "  Using cached tokenizers-0.8.1rc1-cp36-cp36m-win_amd64.whl (1.9 MB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.4.1-py3-none-any.whl (9.9 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from requests==2.25.1->-r requirements.txt (line 6)) (2021.5.30)\n",
      "Collecting idna<3,>=2.5\n",
      "  Using cached idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Using cached chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from tqdm->-r requirements.txt (line 1)) (0.4.4)\n",
      "Collecting importlib-resources\n",
      "  Using cached importlib_resources-5.4.0-py3-none-any.whl (28 kB)\n",
      "Collecting click>=7.1.2\n",
      "  Using cached click-8.0.4-py3-none-any.whl (97 kB)\n",
      "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from flask>=1.0.2->allennlp==0.9.0->-r requirements.txt (line 2)) (3.0.3)\n",
      "Collecting itsdangerous>=2.0\n",
      "  Using cached itsdangerous-2.0.1-py3-none-any.whl (18 kB)\n",
      "Collecting Werkzeug>=2.0\n",
      "  Using cached Werkzeug-2.0.3-py3-none-any.whl (289 kB)\n",
      "Collecting importlib-metadata\n",
      "  Using cached importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: cffi>=1.12.2 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from gevent>=1.3.6->allennlp==0.9.0->-r requirements.txt (line 2)) (1.14.6)\n",
      "Collecting zope.interface\n",
      "  Using cached zope.interface-5.5.2-cp36-cp36m-win_amd64.whl (211 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from gevent>=1.3.6->allennlp==0.9.0->-r requirements.txt (line 2)) (58.0.4)\n",
      "Collecting zope.event\n",
      "  Using cached zope.event-4.6-py2.py3-none-any.whl (6.8 kB)\n",
      "Collecting greenlet>=2.0.0\n",
      "  Using cached greenlet-2.0.2-cp36-cp36m-win_amd64.whl (197 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from cffi>=1.12.2->gevent>=1.3.6->allennlp==0.9.0->-r requirements.txt (line 2)) (2.21)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from Jinja2>=3.0->flask>=1.0.2->allennlp==0.9.0->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from matplotlib>=2.2.3->allennlp==0.9.0->-r requirements.txt (line 2)) (8.4.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from matplotlib>=2.2.3->allennlp==0.9.0->-r requirements.txt (line 2)) (2.8.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from matplotlib>=2.2.3->allennlp==0.9.0->-r requirements.txt (line 2)) (3.0.4)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.3.1-cp36-cp36m-win_amd64.whl (51 kB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting sphinx>=1.6.5\n",
      "  Using cached sphinx-5.3.0-py3-none-any.whl (3.2 MB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from python-dateutil>=2.1->matplotlib>=2.2.3->allennlp==0.9.0->-r requirements.txt (line 2)) (1.16.0)\n",
      "Collecting wasabi<1.1.0,>=0.2.0\n",
      "  Using cached wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
      "Collecting thinc<7.1.0,>=7.0.8\n",
      "  Using cached thinc-7.0.8-cp36-cp36m-win_amd64.whl (1.9 MB)\n",
      "Collecting srsly<1.1.0,>=0.0.6\n",
      "  Using cached srsly-1.0.7-cp36-cp36m-win_amd64.whl (367 kB)\n",
      "Collecting blis<0.3.0,>=0.2.2\n",
      "  Using cached blis-0.2.4-cp36-cp36m-win_amd64.whl (3.1 MB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.8-cp36-cp36m-win_amd64.whl (46 kB)\n",
      "Collecting preshed<2.1.0,>=2.0.1\n",
      "  Using cached preshed-2.0.1-cp36-cp36m-win_amd64.whl (73 kB)\n",
      "Collecting plac<1.0.0,>=0.9.6\n",
      "  Using cached plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.10-cp36-cp36m-win_amd64.whl (27 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.0\n",
      "  Using cached sphinxcontrib_htmlhelp-2.0.0-py2.py3-none-any.whl (100 kB)\n",
      "Collecting snowballstemmer>=2.0\n",
      "  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Collecting babel>=2.9\n",
      "  Using cached Babel-2.11.0-py3-none-any.whl (9.5 MB)\n",
      "Collecting sphinxcontrib-jsmath\n",
      "  Using cached sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.5\n",
      "  Using cached sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)\n",
      "Collecting sphinxcontrib-applehelp\n",
      "  Using cached sphinxcontrib_applehelp-1.0.2-py2.py3-none-any.whl (121 kB)\n",
      "Collecting sphinxcontrib-devhelp\n",
      "  Using cached sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)\n",
      "Collecting Pygments>=2.12\n",
      "  Using cached Pygments-2.14.0-py3-none-any.whl (1.1 MB)\n",
      "Collecting docutils<0.20,>=0.14\n",
      "  Using cached docutils-0.18.1-py2.py3-none-any.whl (570 kB)\n",
      "Collecting colorama\n",
      "  Using cached colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Collecting imagesize>=1.3\n",
      "  Using cached imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Collecting sphinxcontrib-qthelp\n",
      "  Using cached sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)\n",
      "Collecting alabaster<0.8,>=0.7\n",
      "  Using cached alabaster-0.7.13-py3-none-any.whl (13 kB)\n",
      "Collecting typing-extensions>=3.6.4\n",
      "  Using cached typing_extensions-4.1.1-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Using cached zipp-3.6.0-py3-none-any.whl (5.3 kB)\n",
      "Collecting protobuf>=3.20\n",
      "  Using cached protobuf-4.21.0-py3-none-any.whl (291 kB)\n",
      "Collecting s3transfer<0.6.0,>=0.5.0\n",
      "  Using cached s3transfer-0.5.2-py3-none-any.whl (79 kB)\n",
      "Collecting botocore<1.27.0,>=1.26.10\n",
      "  Using cached botocore-1.26.10-py3-none-any.whl (8.8 MB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1\n",
      "  Using cached jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from ftfy->allennlp==0.9.0->-r requirements.txt (line 2)) (0.2.5)\n",
      "Collecting cached-property\n",
      "  Using cached cached_property-1.5.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting joblib\n",
      "  Using cached joblib-1.1.1-py2.py3-none-any.whl (309 kB)\n",
      "Collecting atomicwrites>=1.0\n",
      "  Using cached atomicwrites-1.4.1-py2.py3-none-any.whl\n",
      "Collecting py>=1.8.2\n",
      "  Using cached py-1.11.0-py2.py3-none-any.whl (98 kB)\n",
      "Collecting pluggy<2.0,>=0.12\n",
      "  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting iniconfig\n",
      "  Using cached iniconfig-1.1.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Collecting tomli>=1.0.0\n",
      "  Using cached tomli-1.2.3-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\odaim\\anaconda3\\envs\\purereprodcution\\lib\\site-packages (from pytest->allennlp==0.9.0->-r requirements.txt (line 2)) (21.4.0)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: zipp, urllib3, typing-extensions, jmespath, pytz, importlib-resources, importlib-metadata, idna, dataclasses, cymem, colorama, chardet, botocore, Werkzeug, wasabi, tqdm, srsly, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, snowballstemmer, s3transfer, requests, Pygments, preshed, plac, murmurhash, itsdangerous, imagesize, docutils, click, blis, babel, alabaster, zope.interface, zope.event, tomli, threadpoolctl, thinc, sphinx, sentencepiece, scipy, regex, py, protobuf, pluggy, kiwisolver, joblib, iniconfig, greenlet, flask, cycler, cached-property, boto3, atomicwrites, word2number, unidecode, tokenizers, tensorboardX, sqlparse, spacy, scikit-learn, sacremoses, responses, pytorch-transformers, pytorch-pretrained-bert, pytest, parsimonious, overrides, numpydoc, nltk, matplotlib, jsonpickle, h5py, gevent, ftfy, flask-cors, flaky, filelock, editdistance, conllu, transformers, allennlp\n",
      "  Attempting uninstall: colorama\n",
      "    Found existing installation: colorama 0.4.4\n",
      "    Uninstalling colorama-0.4.4:\n",
      "      Successfully uninstalled colorama-0.4.4\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.11.2\n",
      "    Uninstalling Pygments-2.11.2:\n",
      "      Successfully uninstalled Pygments-2.11.2\n",
      "Successfully installed Pygments-2.14.0 Werkzeug-2.0.3 alabaster-0.7.13 allennlp-0.9.0 atomicwrites-1.4.1 babel-2.11.0 blis-0.2.4 boto3-1.23.10 botocore-1.26.10 cached-property-1.5.2 chardet-4.0.0 click-8.0.4 colorama-0.4.5 conllu-1.3.1 cycler-0.11.0 cymem-2.0.8 dataclasses-0.8 docutils-0.18.1 editdistance-0.6.2 filelock-3.4.1 flaky-3.7.0 flask-2.0.3 flask-cors-4.0.0 ftfy-6.0.3 gevent-22.10.2 greenlet-2.0.2 h5py-3.1.0 idna-2.10 imagesize-1.4.1 importlib-metadata-4.8.3 importlib-resources-5.4.0 iniconfig-1.1.1 itsdangerous-2.0.1 jmespath-0.10.0 joblib-1.1.1 jsonpickle-2.2.0 kiwisolver-1.3.1 matplotlib-3.3.4 murmurhash-1.0.10 nltk-3.6.7 numpydoc-1.1.0 overrides-3.1.0 parsimonious-0.10.0 plac-0.9.6 pluggy-1.0.0 preshed-2.0.1 protobuf-4.21.0 py-1.11.0 pytest-7.0.1 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 pytz-2023.3.post1 regex-2023.8.8 requests-2.25.1 responses-0.17.0 s3transfer-0.5.2 sacremoses-0.0.53 scikit-learn-0.24.2 scipy-1.5.4 sentencepiece-0.1.99 snowballstemmer-2.2.0 spacy-2.1.9 sphinx-5.3.0 sphinxcontrib-applehelp-1.0.2 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.0 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 sqlparse-0.4.4 srsly-1.0.7 tensorboardX-2.6.2.2 thinc-7.0.8 threadpoolctl-3.1.0 tokenizers-0.8.1rc1 tomli-1.2.3 tqdm-4.64.1 transformers-3.0.2 typing-extensions-4.1.1 unidecode-1.3.7 urllib3-1.26.18 wasabi-0.10.1 word2number-1.1 zipp-3.6.0 zope.event-4.6 zope.interface-5.5.2\n"
     ]
    }
   ],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec3bf34",
   "metadata": {},
   "source": [
    "There we go! There's a little warning, but let's pertend we didn't see that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b76ebf",
   "metadata": {},
   "source": [
    "### Download and preprocess the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18464cc9",
   "metadata": {},
   "source": [
    "Next, the authors ask us to download and process the datasets\n",
    "Their experiments are based on three datasets: ACE04, ACE05, and SciERC. Please find the links and pre-processing below:\n",
    "* ACE04/ACE05: We use the preprocessing code from [DyGIE repo](https://github.com/luanyi/DyGIE/tree/master/preprocessing). Please follow the instructions to preprocess the ACE05 and ACE04 datasets.\n",
    "* SciERC: The preprocessed SciERC dataset can be downloaded in their project [website](http://nlp.cs.washington.edu/sciIE/).\n",
    "\n",
    "Let's do that in the next section"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109dfd96",
   "metadata": {},
   "source": [
    "## Quick Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0674b9ec",
   "metadata": {},
   "source": [
    "For this reproduction, we will use the pre-trained models provided by the authors. And we will start with the SciERC dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a36392bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting clint\n",
      "  Downloading clint-0.5.1.tar.gz (29 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting args\n",
      "  Downloading args-0.1.0.tar.gz (3.0 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: clint, args\n",
      "  Building wheel for clint (setup.py): started\n",
      "  Building wheel for clint (setup.py): finished with status 'done'\n",
      "  Created wheel for clint: filename=clint-0.5.1-py3-none-any.whl size=34458 sha256=362cf8d8bbfcf083639eb05965cfbbefd23e2defeb0d69747083d96324b38260\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\2c\\69\\16\\04ffdd2e6fbbf2b3aa97970ba8d01c36d09df025f19f25c57e\n",
      "  Building wheel for args (setup.py): started\n",
      "  Building wheel for args (setup.py): finished with status 'done'\n",
      "  Created wheel for args: filename=args-0.1.0-py3-none-any.whl size=3321 sha256=e53dc3c1bf6de0fcf15aacd97872c9b249ae6ab5600eb730aeb0af4a54920dcb\n",
      "  Stored in directory: c:\\users\\odaim\\appdata\\local\\pip\\cache\\wheels\\35\\22\\2d\\ee3fc491993d35adc89bcc8f558090cabefeff184a9537928d\n",
      "Successfully built clint args\n",
      "Installing collected packages: args, clint\n",
      "Successfully installed args-0.1.0 clint-0.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip install clint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b6a1fd",
   "metadata": {},
   "source": [
    "### Helper functions\n",
    "Let's implenet some functions to help us\n",
    " - Dowanload files\n",
    " - Extract tar files\n",
    " - Unzip zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d93da120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_file(file_name, url):\n",
    "    file_name = os.getcwd() + file_name\n",
    "    os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
    "    r = requests.get(url, stream=True)\n",
    "\n",
    "    # Throw an error for bad status codes\n",
    "    r.raise_for_status()\n",
    "\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pbar = tqdm(unit=\"B\", total=int(r.headers['Content-Length']), position=0, leave=True, desc='Downloading')\n",
    "        for chunk in r.iter_content(chunk_size=1024): \n",
    "            if chunk: # filter out keep-alive new chunks\n",
    "                pbar.update(len(chunk))\n",
    "                f.write(chunk)\n",
    "\n",
    "import tarfile \n",
    "\n",
    "def extract_tar_file(file_name, target_directory):\n",
    "    with tarfile.open(name=os.getcwd() + file_name) as tar:\n",
    "\n",
    "        # Go over each member\n",
    "        for member in tqdm(iterable=tar.getmembers(), total=len(tar.getmembers()), desc='Extracting'):\n",
    "            tar.extract(member=member, path=os.getcwd() + target_directory) \n",
    "\n",
    "import zipfile\n",
    "\n",
    "def unzip_file(file_name, target_directory):\n",
    "    with zipfile.ZipFile(os.getcwd() + file_name) as zf:\n",
    "        for member in tqdm(zf.infolist(), desc='Extracting'):\n",
    "            zf.extract(member, os.getcwd() + target_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9cc5cc",
   "metadata": {},
   "source": [
    "### Download and extract the SciERC dataset\n",
    "This is the first step to get the data that we will run the pretrained models on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6f1941f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 695340151/695340151 [02:17<00:00, 5061976.13B/s] \n"
     ]
    }
   ],
   "source": [
    "# Downlaod the SciERC dataset\n",
    "download_file('/scierc_data/sciERC_processed.tar.gz', 'http://nlp.cs.washington.edu/sciIE/data/sciERC_processed.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d16fa281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 9/9 [00:04<00:00,  1.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# Extract the SciERC dataset\n",
    "extract_tar_file('/scierc_data/sciERC_processed.tar.gz', '/scierc_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71db5100",
   "metadata": {},
   "source": [
    "### Download and extract the pre-trained entity model\n",
    "Now we will downlaod the pre-trained entity model to use it to extract entities from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "6f6bd2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 409227718/409227718 [01:10<00:00, 5842408.54B/s] \n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained entity model\n",
    "download_file('/scierc_models/ent-scib-ctx0.zip', 'https://nlp.cs.princeton.edu/projects/pure/scierc_models/ent-scib-ctx0.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecd43061",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 6/6 [00:02<00:00,  2.47it/s]\n"
     ]
    }
   ],
   "source": [
    "### Unzip the pre-trained entity model\n",
    "unzip_file('/scierc_models/ent-scib-ctx0.zip', '/scierc_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ec19337",
   "metadata": {},
   "source": [
    "### Download and extract the pre-trained relation model\n",
    "Now we'll do the same for the relation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f4553e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 408246037/408246037 [00:22<00:00, 17918528.12B/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained relation model\n",
    "download_file('/scierc_models/rel-scib-ctx0.zip', 'https://nlp.cs.princeton.edu/projects/pure/scierc_models/rel-scib-ctx0.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb74bbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 6/6 [00:02<00:00,  2.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Unzip the pre-trained relation model\n",
    "unzip_file('/scierc_models/rel-scib-ctx0.zip', '/scierc_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2fe617",
   "metadata": {},
   "source": [
    "### Download and extract the pre-trained approximation relation model\n",
    "And one last time for the approximation relation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "196e179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 408248055/408248055 [00:31<00:00, 13067492.36B/s]\n"
     ]
    }
   ],
   "source": [
    "# Download the pre-trained approximation relation model\n",
    "download_file('/scierc_models/rel_approx-scib-ctx0.zip', 'https://nlp.cs.princeton.edu/projects/pure/scierc_models/rel_approx-scib-ctx0.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d4663ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|██████████| 6/6 [00:02<00:00,  2.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Unzip the pre-trained approximation relation model\n",
    "unzip_file('/scierc_models/rel_approx-scib-ctx0.zip', '/scierc_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb00539-6702-4fe6-9204-1d39d498ac46",
   "metadata": {},
   "source": [
    "### Run the entity model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e41d33a-d459-41c7-9913-fa030ba7d97a",
   "metadata": {},
   "source": [
    "The authors instruct us to run the entity model using the folowing comand. We will, however, do that in detail in the notebook run_entity.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624147ef-08b6-49e0-9067-dbf47ac2ed23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the pre-trained entity model, the result will be stored in ${scierc_ent_model}/ent_pred_test.json\n",
    "! python run_entity.py \\\n",
    "    --do_eval --eval_test \\\n",
    "    --context_window 0 \\\n",
    "    --task scierc \\\n",
    "    --data_dir ${scierc_dataset} \\\n",
    "    --model allenai/scibert_scivocab_uncased \\\n",
    "    --output_dir ${scierc_ent_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f733b2-eb05-495b-9f77-83f4817bbeda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
