{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "640d415f-6e89-42e8-af0e-a65e78034864",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Running the entity model\n",
    "In this notebook we will run and evalute the entity nmodel proposed in the research paper [A Frustratingly Easy Approach for Entity and Relation Extraction](https://arxiv.org/pdf/2010.12812.pdf).\n",
    "\n",
    "This is a reproduction based on the instructions left by the authors in their [GitHub repo](https://github.com/princeton-nlp/PURE)\n",
    "\n",
    "We will run the entity model on the SchiERC dataset using a pre-trained BERT based nodel.\n",
    "\n",
    "The output of this notebook, a JSON file where keys are **document and sentence indices**, and values are **lists of predicted entities** in the format [start, end, label], will be used as the input for the relation model in the notebook `run_relation`\n",
    "\n",
    "**Environment information**\n",
    "\n",
    "- Windows 11\n",
    "- Python 3.6.13\n",
    "- pip 21.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba35da-92ff-4703-8d62-dd4c93a9e96f",
   "metadata": {},
   "source": [
    "## Basic setup\n",
    "Firstly, we setup our notebook by importing needed libraries and modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5021b5c2-94c1-419a-9b7d-8a154ee74a0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odaim\\anaconda3\\envs\\PUREReprodcution\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from allennlp.modules import FeedForward\n",
    "from allennlp.nn.util import batched_index_select\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import AlbertTokenizer, AlbertPreTrainedModel, AlbertModel\n",
    "from transformers import BertTokenizer, BertPreTrainedModel, BertModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d50260-1823-4c1d-86b8-734afae6907e",
   "metadata": {},
   "source": [
    "And we initialize a logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "336427ee-d4c5-4dc2-bd88-26e3004e194c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "\n",
    "logger = logging.getLogger('root')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1ece49-e225-4c2a-b646-d6a863f1aabc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main classes\n",
    "The authors have implemented their system in an OOP style. Let's go through the defined classes and understand what they do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89a61e9-4541-40cf-bc8b-e2d4ac167c3a",
   "metadata": {},
   "source": [
    "### BertForEntity\n",
    "The fisrt class we'll look at is BertForEntity. It is a custom model for named entity recognition (NER) using BERT (Bidirectional Encoder Representations from Transformers) as the underlying pre-trained transformer model. The class is built on top of a pre-trained BERT mode, therefore, it extends the BertPreTrainedModel.\n",
    "\n",
    "Let's now look into the constructor, it initializes the BERT model, dropout, width embedding, and the NER classifier layers. It then calls init_weights() to initialize the model's weights.\n",
    "\n",
    "The constructor accepts takes several parameters:\n",
    "- config: BERT model configuration.\n",
    "- num_ner_labels: Number of NER labels.\n",
    "- head_hidden_dim: Hidden dimension for the feedforward layers in the NER classifier **(default: 150)**.\n",
    "- width_embedding_dim: Dimension of the width embedding **(default: 150)**.\n",
    "- max_span_length: Maximum length for a span **(default: 8)**.\n",
    "\n",
    "We must note the setup of the model:\n",
    "\n",
    "```python\n",
    "self.ner_classifier = nn.Sequential(\n",
    "            FeedForward(input_dim=config.hidden_size * 2 + width_embedding_dim,\n",
    "                        num_layers=2,\n",
    "                        hidden_dims=head_hidden_dim,\n",
    "                        activations=F.relu,\n",
    "                        dropout=0.2),\n",
    "            nn.Linear(head_hidden_dim, num_ner_labels))\n",
    "```\n",
    "\n",
    "The model is a FeedForward Neural Network:\n",
    "\n",
    "- It's defined using nn.Sequential and consists of two layers.\n",
    "- Input dimension (input_dim) is set to the sum of the following:\n",
    "  - config.hidden_size * 2: Twice the hidden size of the BERT model. This is likely because the span embeddings are concatenated, so the input dimension includes information from both start and end embeddings.\n",
    "  - width_embedding_dim: Dimension of the width embedding.\n",
    "- num_layers=2: There are two hidden layers in the feedforward network.\n",
    "- hidden_dims=head_hidden_dim: The hidden layer dimensions are set by the head_hidden_dim parameter **(default: 150)**.\n",
    "- activations=F.relu: Rectified Linear Unit (ReLU) activation function is used between layers.\n",
    "- dropout=0.2: 20% dropout is applied between layers for regularization.\n",
    "\n",
    "Output Layer:\n",
    "\n",
    "- After the feedforward layers, there is a linear layer (nn.Linear) with an output dimension of num_ner_labels.\n",
    "- This output dimension corresponds to the number of NER labels, indicating the classes the model is trying to predict.\n",
    "\n",
    "**Note:**\n",
    "The choice of ReLU activation and dropout between layers is a common practice in neural network architectures for introducing non-linearity and preventing overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "154336b5-a29c-4672-9e32-90875cdbb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForEntity(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_ner_labels, head_hidden_dim=150, width_embedding_dim=150, max_span_length=8):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.bert = BertModel(config)\n",
    "        self.hidden_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.width_embedding = nn.Embedding(max_span_length + 1, width_embedding_dim)\n",
    "\n",
    "        self.ner_classifier = nn.Sequential(\n",
    "            FeedForward(input_dim=config.hidden_size * 2 + width_embedding_dim,\n",
    "                        num_layers=2,\n",
    "                        hidden_dims=head_hidden_dim,\n",
    "                        activations=F.relu,\n",
    "                        dropout=0.2),\n",
    "            nn.Linear(head_hidden_dim, num_ner_labels)\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _get_span_embeddings(self, input_ids, spans, token_type_ids=None, attention_mask=None):\n",
    "        sequence_output, pooled_output = self.bert(input_ids=input_ids, token_type_ids=token_type_ids,\n",
    "                                                   attention_mask=attention_mask)\n",
    "\n",
    "        sequence_output = self.hidden_dropout(sequence_output)\n",
    "\n",
    "        \"\"\"\n",
    "        spans: [batch_size, num_spans, 3]; 0: left_ned, 1: right_end, 2: width\n",
    "        spans_mask: (batch_size, num_spans, )\n",
    "        \"\"\"\n",
    "        spans_start = spans[:, :, 0].view(spans.size(0), -1)\n",
    "        spans_start_embedding = batched_index_select(sequence_output, spans_start)\n",
    "        spans_end = spans[:, :, 1].view(spans.size(0), -1)\n",
    "        spans_end_embedding = batched_index_select(sequence_output, spans_end)\n",
    "\n",
    "        spans_width = spans[:, :, 2].view(spans.size(0), -1)\n",
    "        spans_width_embedding = self.width_embedding(spans_width)\n",
    "\n",
    "        # Concatenate embeddings of left/right points and the width embedding\n",
    "        spans_embedding = torch.cat((spans_start_embedding, spans_end_embedding, spans_width_embedding), dim=-1)\n",
    "        \"\"\"\n",
    "        spans_embedding: (batch_size, num_spans, hidden_size*2+embedding_dim)\n",
    "        \"\"\"\n",
    "        return spans_embedding\n",
    "\n",
    "    def forward(self, input_ids, spans, spans_mask, spans_ner_label=None, token_type_ids=None, attention_mask=None):\n",
    "        spans_embedding = self._get_span_embeddings(input_ids, spans, token_type_ids=token_type_ids,\n",
    "                                                    attention_mask=attention_mask)\n",
    "        ffnn_hidden = []\n",
    "        hidden = spans_embedding\n",
    "        for layer in self.ner_classifier:\n",
    "            hidden = layer(hidden)\n",
    "            ffnn_hidden.append(hidden)\n",
    "        logits = ffnn_hidden[-1]\n",
    "\n",
    "        if spans_ner_label is not None:\n",
    "            loss_fct = CrossEntropyLoss(reduction='sum')\n",
    "            if attention_mask is not None:\n",
    "                active_loss = spans_mask.view(-1) == 1\n",
    "                active_logits = logits.view(-1, logits.shape[-1])\n",
    "                active_labels = torch.where(\n",
    "                    active_loss, spans_ner_label.view(-1), torch.tensor(loss_fct.ignore_index).type_as(spans_ner_label)\n",
    "                )\n",
    "                loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                loss = loss_fct(logits.view(-1, logits.shape[-1]), spans_ner_label.view(-1))\n",
    "            return loss, logits, spans_embedding\n",
    "        else:\n",
    "            return logits, spans_embedding, spans_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e5f3a2-ca7e-4445-8aa6-44c59f2d77de",
   "metadata": {},
   "source": [
    "### AlbertForEntity\n",
    "\n",
    "There's also the class AlbertForEntity. Which is very similar to the BertForEntity except it uses the AlbertModel isntead of the BErtModel as it's inderlying transformer model architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46fc5f0b-7afd-4155-b3af-5975e79efa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlbertForEntity(AlbertPreTrainedModel):\n",
    "    def __init__(self, config, num_ner_labels, head_hidden_dim=150, width_embedding_dim=150, max_span_length=8):\n",
    "        super().__init__(config)\n",
    "\n",
    "        self.albert = AlbertModel(config)\n",
    "        self.hidden_dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.width_embedding = nn.Embedding(max_span_length+1, width_embedding_dim)\n",
    "        \n",
    "        self.ner_classifier = nn.Sequential(\n",
    "            FeedForward(input_dim=config.hidden_size*2+width_embedding_dim, \n",
    "                        num_layers=2,\n",
    "                        hidden_dims=head_hidden_dim,\n",
    "                        activations=F.relu,\n",
    "                        dropout=0.2),\n",
    "            nn.Linear(head_hidden_dim, num_ner_labels)\n",
    "        )\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _get_span_embeddings(self, input_ids, spans, token_type_ids=None, attention_mask=None):\n",
    "        sequence_output, pooled_output = self.albert(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        sequence_output = self.hidden_dropout(sequence_output)\n",
    "\n",
    "        \"\"\"\n",
    "        spans: [batch_size, num_spans, 3]; 0: left_ned, 1: right_end, 2: width\n",
    "        spans_mask: (batch_size, num_spans, )\n",
    "        \"\"\"\n",
    "        spans_start = spans[:, :, 0].view(spans.size(0), -1)\n",
    "        spans_start_embedding = batched_index_select(sequence_output, spans_start)\n",
    "        spans_end = spans[:, :, 1].view(spans.size(0), -1)\n",
    "        spans_end_embedding = batched_index_select(sequence_output, spans_end)\n",
    "\n",
    "        spans_width = spans[:, :, 2].view(spans.size(0), -1)\n",
    "        spans_width_embedding = self.width_embedding(spans_width)\n",
    "\n",
    "        spans_embedding = torch.cat((spans_start_embedding, spans_end_embedding, spans_width_embedding), dim=-1)\n",
    "        \"\"\"\n",
    "        spans_embedding: (batch_size, num_spans, hidden_size*2+embedding_dim)\n",
    "        \"\"\"\n",
    "        return spans_embedding\n",
    "\n",
    "    def forward(self, input_ids, spans, spans_mask, spans_ner_label=None, token_type_ids=None, attention_mask=None):\n",
    "        spans_embedding = self._get_span_embeddings(input_ids, spans, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        ffnn_hidden = []\n",
    "        hidden = spans_embedding\n",
    "        for layer in self.ner_classifier:\n",
    "            hidden = layer(hidden)\n",
    "            ffnn_hidden.append(hidden)\n",
    "        logits = ffnn_hidden[-1]\n",
    "\n",
    "        if spans_ner_label is not None:\n",
    "            loss_fct = CrossEntropyLoss(reduction='sum')\n",
    "            if attention_mask is not None:\n",
    "                active_loss = spans_mask.view(-1) == 1\n",
    "                active_logits = logits.view(-1, logits.shape[-1])\n",
    "                active_labels = torch.where(\n",
    "                    active_loss, spans_ner_label.view(-1), torch.tensor(loss_fct.ignore_index).type_as(spans_ner_label)\n",
    "                )\n",
    "                loss = loss_fct(active_logits, active_labels)\n",
    "            else:\n",
    "                loss = loss_fct(logits.view(-1, logits.shape[-1]), spans_ner_label.view(-1))\n",
    "            return loss, logits, spans_embedding\n",
    "        else:\n",
    "            return logits, spans_embedding, spans_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95beb8c4-f614-47d2-b105-368ee4a675be",
   "metadata": {},
   "source": [
    "### EntityModel\n",
    "\n",
    "This EntityModel class is a wrapper around a BERT or ALBERT model for Named Entity Recognition (NER) tasks. It's designed to provide a convenient interface for using BERT or ALBERT models for NER tasks, handling tokenization, model loading, device management, and batch processing.\n",
    "\n",
    "Let's break down the functionality and components of this class:\n",
    "\n",
    "#### nitialization (__init__ method):\n",
    "- Parameters:\n",
    "  - model: The name of the BERT or ALBERT model to be used.\n",
    "  - bert_model_dir: The directory where the pre-trained BERT or ALBERT model is stored.\n",
    "  - use_albert: A flag indicating whether to use ALBERT (True) or BERT (False).\n",
    "  - max_span_length: Maximum span length to be considered during tokenization.\n",
    "  - num_ner_labels: The number of Named Entity Recognition labels.\n",
    "  \n",
    "  \n",
    "- Initialization Steps:\n",
    "1. Set bert_model_name and vocab_name based on the provided parameters.\n",
    "2. If a BERT model directory is specified (bert_model_dir is not None), update bert_model_name and vocab_name accordingly.\n",
    "3. Initialize a tokenizer (AlbertTokenizer or BertTokenizer) based on the specified model name.\n",
    "4. Initialize the transformer model (AlbertForEntity or BertForEntity) with the provided parameters.\n",
    "\n",
    "\n",
    "#### Device Management (move_model_to_cuda method):\n",
    "\n",
    "\n",
    "- Functionality:\n",
    "  - Checks if a GPU (CUDA) is available.\n",
    "  - If available, moves the model to the GPU. If multiple GPUs are available, it wraps the model with **torch.nn.DataParallel** for parallel processing.\n",
    "\n",
    "\n",
    "##### Input Tensor Generation (\\_get_input_tensors method):\n",
    "- Functionality:\n",
    "  - Takes a list of tokens, spans, and spans' Named Entity Recognition (NER) labels.\n",
    "  - Tokenizes the input tokens using the tokenizer and converts them to indexed tokens.\n",
    "  - Converts span information to tensors.\n",
    "  \n",
    "  \n",
    "#### Batch Input Tensor Generation (_get_input_tensors_batch method):\n",
    "- Functionality:\n",
    "  - Takes a list of samples, where each sample contains tokens, spans, and spans' NER labels.\n",
    "  - Calls _get_input_tensors for each sample and constructs batched tensors for the entire input batch.\n",
    "  - Handles padding for both tokens and spans to create tensors of uniform shapes.\n",
    "#### Batch Execution (run_batch method):\n",
    "- Functionality:\n",
    "  - Converts the input samples to tensors using _get_input_tensors_batch.\n",
    "  - If in training mode, runs the BERT or ALBERT model in training mode and computes the NER loss.\n",
    "  - If in evaluation mode, runs the model in evaluation mode and generates predictions.\n",
    "  - Returns a dictionary containing NER loss, log-likelihoods (in training mode), predicted NER labels, NER probabilities, and last hidden states.\n",
    "  \n",
    "**Note:**\n",
    "- The class relies on external logger (logger) for logging information.\n",
    "- It assumes that the underlying BERT or ALBERT model classes (AlbertForEntity, BertForEntity) are correctly implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37774b5e-6ac6-4147-af19-9755e638c90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityModel:\n",
    "\n",
    "    def __init__(self, model, use_albert, max_span_length, num_ner_labels, bert_model_dir=None):\n",
    "        super().__init__()\n",
    "\n",
    "        bert_model_name = model\n",
    "        vocab_name = bert_model_name\n",
    "\n",
    "        if bert_model_dir is not None:\n",
    "            bert_model_name = str(bert_model_dir) + '/'\n",
    "            # vocab_name = bert_model_name + 'vocab.txt'\n",
    "            vocab_name = bert_model_name\n",
    "            logger.info('Loading BERT model from {}'.format(bert_model_name))\n",
    "\n",
    "        if use_albert:\n",
    "            self.tokenizer = AlbertTokenizer.from_pretrained(vocab_name)\n",
    "            self.bert_model = AlbertForEntity.from_pretrained(bert_model_name, num_ner_labels=num_ner_labels,\n",
    "                                                              max_span_length=max_span_length)\n",
    "        else:\n",
    "            self.tokenizer = BertTokenizer.from_pretrained(vocab_name)\n",
    "            self.bert_model = BertForEntity.from_pretrained(bert_model_name, num_ner_labels=num_ner_labels,\n",
    "                                                            max_span_length=max_span_length)\n",
    "\n",
    "        self._model_device = 'cpu'\n",
    "        self.move_model_to_cuda()\n",
    "\n",
    "    def move_model_to_cuda(self):\n",
    "        if not torch.cuda.is_available():\n",
    "            logger.error('No CUDA found!')\n",
    "            exit(-1)\n",
    "        logger.info('Moving to CUDA...')\n",
    "        self._model_device = 'cuda'\n",
    "        self.bert_model.cuda()\n",
    "        logger.info('# GPUs = %d' % (torch.cuda.device_count()))\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            self.bert_model = torch.nn.DataParallel(self.bert_model)\n",
    "\n",
    "    def _get_input_tensors(self, tokens, spans, spans_ner_label):\n",
    "        start2idx = []\n",
    "        end2idx = []\n",
    "\n",
    "        bert_tokens = []\n",
    "        bert_tokens.append(self.tokenizer.cls_token)\n",
    "        for token in tokens:\n",
    "            start2idx.append(len(bert_tokens))\n",
    "            sub_tokens = self.tokenizer.tokenize(token)\n",
    "            bert_tokens += sub_tokens\n",
    "            end2idx.append(len(bert_tokens) - 1)\n",
    "        bert_tokens.append(self.tokenizer.sep_token)\n",
    "\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(bert_tokens)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "        bert_spans = [[start2idx[span[0]], end2idx[span[1]], span[2]] for span in spans]\n",
    "        bert_spans_tensor = torch.tensor([bert_spans])\n",
    "\n",
    "        spans_ner_label_tensor = torch.tensor([spans_ner_label])\n",
    "\n",
    "        return tokens_tensor, bert_spans_tensor, spans_ner_label_tensor\n",
    "\n",
    "    def _get_input_tensors_batch(self, samples_list, training=True):\n",
    "        tokens_tensor_list = []\n",
    "        bert_spans_tensor_list = []\n",
    "        spans_ner_label_tensor_list = []\n",
    "        sentence_length = []\n",
    "\n",
    "        max_tokens = 0\n",
    "        max_spans = 0\n",
    "        for sample in samples_list:\n",
    "            tokens = sample['tokens']\n",
    "            spans = sample['spans']\n",
    "            spans_ner_label = sample['spans_label']\n",
    "\n",
    "            tokens_tensor, bert_spans_tensor, spans_ner_label_tensor = self._get_input_tensors(tokens, spans,\n",
    "                                                                                               spans_ner_label)\n",
    "            tokens_tensor_list.append(tokens_tensor)\n",
    "            bert_spans_tensor_list.append(bert_spans_tensor)\n",
    "            spans_ner_label_tensor_list.append(spans_ner_label_tensor)\n",
    "            assert (bert_spans_tensor.shape[1] == spans_ner_label_tensor.shape[1])\n",
    "            if (tokens_tensor.shape[1] > max_tokens):\n",
    "                max_tokens = tokens_tensor.shape[1]\n",
    "            if (bert_spans_tensor.shape[1] > max_spans):\n",
    "                max_spans = bert_spans_tensor.shape[1]\n",
    "            sentence_length.append(sample['sent_length'])\n",
    "        sentence_length = torch.Tensor(sentence_length)\n",
    "\n",
    "        # apply padding and concatenate tensors\n",
    "        final_tokens_tensor = None\n",
    "        final_attention_mask = None\n",
    "        final_bert_spans_tensor = None\n",
    "        final_spans_ner_label_tensor = None\n",
    "        final_spans_mask_tensor = None\n",
    "        for tokens_tensor, bert_spans_tensor, spans_ner_label_tensor in zip(tokens_tensor_list, bert_spans_tensor_list,\n",
    "                                                                            spans_ner_label_tensor_list):\n",
    "            # padding for tokens\n",
    "            num_tokens = tokens_tensor.shape[1]\n",
    "            tokens_pad_length = max_tokens - num_tokens\n",
    "            attention_tensor = torch.full([1, num_tokens], 1, dtype=torch.long)\n",
    "            if tokens_pad_length > 0:\n",
    "                pad = torch.full([1, tokens_pad_length], self.tokenizer.pad_token_id, dtype=torch.long)\n",
    "                tokens_tensor = torch.cat((tokens_tensor, pad), dim=1)\n",
    "                attention_pad = torch.full([1, tokens_pad_length], 0, dtype=torch.long)\n",
    "                attention_tensor = torch.cat((attention_tensor, attention_pad), dim=1)\n",
    "\n",
    "            # padding for spans\n",
    "            num_spans = bert_spans_tensor.shape[1]\n",
    "            spans_pad_length = max_spans - num_spans\n",
    "            spans_mask_tensor = torch.full([1, num_spans], 1, dtype=torch.long)\n",
    "            if spans_pad_length > 0:\n",
    "                pad = torch.full([1, spans_pad_length, bert_spans_tensor.shape[2]], 0, dtype=torch.long)\n",
    "                bert_spans_tensor = torch.cat((bert_spans_tensor, pad), dim=1)\n",
    "                mask_pad = torch.full([1, spans_pad_length], 0, dtype=torch.long)\n",
    "                spans_mask_tensor = torch.cat((spans_mask_tensor, mask_pad), dim=1)\n",
    "                spans_ner_label_tensor = torch.cat((spans_ner_label_tensor, mask_pad), dim=1)\n",
    "\n",
    "            # update final outputs\n",
    "            if final_tokens_tensor is None:\n",
    "                final_tokens_tensor = tokens_tensor\n",
    "                final_attention_mask = attention_tensor\n",
    "                final_bert_spans_tensor = bert_spans_tensor\n",
    "                final_spans_ner_label_tensor = spans_ner_label_tensor\n",
    "                final_spans_mask_tensor = spans_mask_tensor\n",
    "            else:\n",
    "                final_tokens_tensor = torch.cat((final_tokens_tensor, tokens_tensor), dim=0)\n",
    "                final_attention_mask = torch.cat((final_attention_mask, attention_tensor), dim=0)\n",
    "                final_bert_spans_tensor = torch.cat((final_bert_spans_tensor, bert_spans_tensor), dim=0)\n",
    "                final_spans_ner_label_tensor = torch.cat((final_spans_ner_label_tensor, spans_ner_label_tensor), dim=0)\n",
    "                final_spans_mask_tensor = torch.cat((final_spans_mask_tensor, spans_mask_tensor), dim=0)\n",
    "        # logger.info(final_tokens_tensor)\n",
    "        # logger.info(final_attention_mask)\n",
    "        # logger.info(final_bert_spans_tensor)\n",
    "        # logger.info(final_bert_spans_tensor.shape)\n",
    "        # logger.info(final_spans_mask_tensor.shape)\n",
    "        # logger.info(final_spans_ner_label_tensor.shape)\n",
    "        return final_tokens_tensor, final_attention_mask, final_bert_spans_tensor, final_spans_mask_tensor, final_spans_ner_label_tensor, sentence_length\n",
    "\n",
    "    def run_batch(self, samples_list, try_cuda=True, training=True):\n",
    "        # convert samples to input tensors\n",
    "        tokens_tensor, attention_mask_tensor, bert_spans_tensor, spans_mask_tensor, spans_ner_label_tensor, sentence_length = self._get_input_tensors_batch(\n",
    "            samples_list, training)\n",
    "\n",
    "        output_dict = {\n",
    "            'ner_loss': 0,\n",
    "        }\n",
    "\n",
    "        if training:\n",
    "            self.bert_model.train()\n",
    "            ner_loss, ner_logits, spans_embedding = self.bert_model(\n",
    "                input_ids=tokens_tensor.to(self._model_device),\n",
    "                spans=bert_spans_tensor.to(self._model_device),\n",
    "                spans_mask=spans_mask_tensor.to(self._model_device),\n",
    "                spans_ner_label=spans_ner_label_tensor.to(self._model_device),\n",
    "                attention_mask=attention_mask_tensor.to(self._model_device),\n",
    "            )\n",
    "            output_dict['ner_loss'] = ner_loss.sum()\n",
    "            output_dict['ner_llh'] = F.log_softmax(ner_logits, dim=-1)\n",
    "        else:\n",
    "            self.bert_model.eval()\n",
    "            with torch.no_grad():\n",
    "                ner_logits, spans_embedding, last_hidden = self.bert_model(\n",
    "                    input_ids=tokens_tensor.to(self._model_device),\n",
    "                    spans=bert_spans_tensor.to(self._model_device),\n",
    "                    spans_mask=spans_mask_tensor.to(self._model_device),\n",
    "                    spans_ner_label=None,\n",
    "                    attention_mask=attention_mask_tensor.to(self._model_device),\n",
    "                )\n",
    "            _, predicted_label = ner_logits.max(2)\n",
    "            predicted_label = predicted_label.cpu().numpy()\n",
    "            last_hidden = last_hidden.cpu().numpy()\n",
    "\n",
    "            predicted = []\n",
    "            pred_prob = []\n",
    "            hidden = []\n",
    "            for i, sample in enumerate(samples_list):\n",
    "                ner = []\n",
    "                prob = []\n",
    "                lh = []\n",
    "                for j in range(len(sample['spans'])):\n",
    "                    ner.append(predicted_label[i][j])\n",
    "                    # prob.append(F.softmax(ner_logits[i][j], dim=-1).cpu().numpy())\n",
    "                    prob.append(ner_logits[i][j].cpu().numpy())\n",
    "                    lh.append(last_hidden[i][j])\n",
    "                predicted.append(ner)\n",
    "                pred_prob.append(prob)\n",
    "                hidden.append(lh)\n",
    "            output_dict['pred_ner'] = predicted\n",
    "            output_dict['ner_probs'] = pred_prob\n",
    "            output_dict['ner_last_hidden'] = hidden\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462cf997-a515-41b4-95b2-f106c2527047",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Represents a dataset. It's a convenient wrapper for handling datasets, reading data from JSON files, and creating Document objects.\n",
    "\n",
    "Let's break down its components:\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the Dataset class.\n",
    "- Takes three parameters: `json_file`, `pred_file` **(default is `None`)**, and `doc_range` **(default is `None`)**.\n",
    "- Reads data from the specified JSON files (`json_file` and `pred_file`).\n",
    "- If a document range (`doc_range`) is provided, it selects a subset of documents within that range.\n",
    "- Creates a list of Document objects based on the read data.\n",
    "\n",
    "#### `update_from_js` method:\n",
    "\n",
    "- Updates the dataset with new data (`js`).\n",
    "- Re-creates the list of `Document` objects based on the updated data.\n",
    "\n",
    "#### \\`_read method`:\n",
    "\n",
    "- Reads data from JSON files (`json_file` and optionally `pred_file`).\n",
    "If `pred_file` is provided, it merges the data from the gold (`gold_docs`) and predicted (`pred_docs`) files.\n",
    "- Returns the merged list of documents.\n",
    "\n",
    "#### `__getitem__` method:\n",
    "\n",
    "- Enables indexing of the dataset. Given an index `ix`, it returns the corresponding Document object.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "- Returns the length of the dataset, i.e., the number of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f661a0aa-e6d6-4e06-8eda-0264e2e3708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, json_file, pred_file=None, doc_range=None):\n",
    "        self.js = self._read(json_file, pred_file)\n",
    "        if doc_range is not None:\n",
    "            self.js = self.js[doc_range[0]:doc_range[1]]\n",
    "        self.documents = [Document(js) for js in self.js]\n",
    "\n",
    "    def update_from_js(self, js):\n",
    "        self.js = js\n",
    "        self.documents = [Document(js) for js in self.js]\n",
    "\n",
    "    def _read(self, json_file, pred_file=None):\n",
    "        gold_docs = [json.loads(line) for line in open(json_file)]\n",
    "        if pred_file is None:\n",
    "            return gold_docs\n",
    "\n",
    "        pred_docs = [json.loads(line) for line in open(pred_file)]\n",
    "        merged_docs = []\n",
    "        for gold, pred in zip(gold_docs, pred_docs):\n",
    "            assert gold[\"doc_key\"] == pred[\"doc_key\"]\n",
    "            assert gold[\"sentences\"] == pred[\"sentences\"]\n",
    "            merged = copy.deepcopy(gold)\n",
    "            for k, v in pred.items():\n",
    "                if \"predicted\" in k:\n",
    "                    merged[k] = v\n",
    "            merged_docs.append(merged)\n",
    "\n",
    "        return merged_docs\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.documents[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7d6a61-eb95-47a4-afe8-ec90a40f8cce",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Document\n",
    "\n",
    "This class represents a document. It encapsulates information about a document, its sentences, and any associated clusters. It provides methods for accessing and manipulating this information.\n",
    "\n",
    "Let's go through each part:\n",
    "\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the Document class.\n",
    "- Takes a JSON object (`js`) as input.\n",
    "- Extracts the document key (`_doc_key`) from the JSON object.\n",
    "- Uses the `fields_to_batches` function to extract specific fields from the JSON and create a list of entries.\n",
    "- Computes sentence lengths and starts to facilitate sentence indexing.\n",
    "- Creates a list of Sentence objects based on the entries.\n",
    "- If \"`clusters`\" or \"`predicted_clusters`\" are present in the JSON, creates lists of Cluster objects for clusters and predicted clusters.\n",
    "\n",
    "#### `__repr__` method:\n",
    "\n",
    "- Returns a string representation of the document, including sentence indices and their corresponding text.\n",
    "\n",
    "#### `__getitem__` method:\n",
    "\n",
    "- Enables indexing of the document. Given an index ix, it returns the corresponding `Sentence` object.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "- Returns the number of sentences in the document.\n",
    "\n",
    "#### `print_plaintext method`:\n",
    "\n",
    "- Prints the plaintext representation of the document, sentence by sentence.\n",
    "\n",
    "#### `find_cluster` method:\n",
    "\n",
    "- Searches through reference clusters (either predicted or actual) to find the one containing a specified entity.\n",
    "- Returns the found cluster or None if no match is found.\n",
    "\n",
    "#### `n_tokens property`:\n",
    "\n",
    "- Returns the total number of tokens in the document by summing the number of tokens in each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8414bdc-9404-4a84-8196-1d3329cda851",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Document:\n",
    "    def __init__(self, js):\n",
    "        self._doc_key = js[\"doc_key\"]\n",
    "        entries = fields_to_batches(js, [\"doc_key\", \"clusters\", \"predicted_clusters\", \"section_starts\"])\n",
    "        sentence_lengths = [len(entry[\"sentences\"]) for entry in entries]\n",
    "        sentence_starts = np.cumsum(sentence_lengths)\n",
    "        sentence_starts = np.roll(sentence_starts, 1)\n",
    "        sentence_starts[0] = 0\n",
    "        self.sentence_starts = sentence_starts\n",
    "        self.sentences = [Sentence(entry, sentence_start, sentence_ix)\n",
    "                          for sentence_ix, (entry, sentence_start)\n",
    "                          in enumerate(zip(entries, sentence_starts))]\n",
    "        if \"clusters\" in js:\n",
    "            self.clusters = [Cluster(entry, i, self)\n",
    "                             for i, entry in enumerate(js[\"clusters\"])]\n",
    "        if \"predicted_clusters\" in js:\n",
    "            self.predicted_clusters = [Cluster(entry, i, self)\n",
    "                                       for i, entry in enumerate(js[\"predicted_clusters\"])]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"\\n\".join([str(i) + \": \" + \" \".join(sent.text) for i, sent in enumerate(self.sentences)])\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.sentences[ix]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def print_plaintext(self):\n",
    "        for sent in self:\n",
    "            print(\" \".join(sent.text))\n",
    "\n",
    "\n",
    "    def find_cluster(self, entity, predicted=True):\n",
    "        \"\"\"\n",
    "        Search through erence clusters and return the one containing the query entity, if it's\n",
    "        part of a cluster. If we don't find a match, return None.\n",
    "        \"\"\"\n",
    "        clusters = self.predicted_clusters if predicted else self.clusters\n",
    "        for clust in clusters:\n",
    "            for entry in clust:\n",
    "                if entry.span == entity.span:\n",
    "                    return clust\n",
    "\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def n_tokens(self):\n",
    "        return sum([len(sent) for sent in self.sentences])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516acbd4-ae1a-4aad-801c-6f53e9b163a2",
   "metadata": {},
   "source": [
    "### Cluster\n",
    "\n",
    "The `Cluster` class represents a cluster of entities within a document. It is used to group together entities that belong to the same cluster, providing information about the members of the cluster.\n",
    "This class is designed to encapsulate information about a cluster of entities within a document. It facilitates the organization and representation of entities belonging to the same cluster.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `cluster`: A list of entries representing the entities in the cluster.\n",
    "  - `cluster_id`: An identifier for the cluster.\n",
    "  - `document`: The document object to which the cluster belongs.\n",
    "- Attributes\n",
    "  - `members`: A list of ClusterMember instances, each representing an entity in the cluster.\n",
    "  - `cluster_id`: The identifier for the cluster.\n",
    "  \n",
    "#### Initialization Details\n",
    "- The `__init__` method initializes the cluster by extracting information about each entity in the cluster.\n",
    "- For each entry in the cluster, it determines the corresponding sentence and span in the document.\n",
    "- It creates `ClusterMember` instances for each entity and appends them to the members list.\n",
    "\n",
    "#### Representation\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the cluster, including the cluster identifier and a representation of its members.\n",
    "Accessing Members\n",
    "\n",
    "`__getitem__` Method:\n",
    "Allows accessing individual members of the cluster using indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b147c0b-05c7-48ab-916e-d290af305a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cluster:\n",
    "    def __init__(self, cluster, cluster_id, document):\n",
    "        members = []\n",
    "        for entry in cluster:\n",
    "            sentence_ix = get_sentence_of_span(entry, document.sentence_starts, document.n_tokens)\n",
    "            sentence = document[sentence_ix]\n",
    "            span = Span(entry[0], entry[1], sentence.text, sentence.sentence_start)\n",
    "            ners = [x for x in sentence.ner if x.span == span]\n",
    "            assert len(ners) <= 1\n",
    "            ner = ners[0] if len(ners) == 1 else None\n",
    "            to_append = ClusterMember(span, ner, sentence, cluster_id)\n",
    "            members.append(to_append)\n",
    "\n",
    "        self.members = members\n",
    "        self.cluster_id = cluster_id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self.cluster_id}: \" + self.members.__repr__()\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.members[ix]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d268f6-226f-4e58-8d15-850a20aab354",
   "metadata": {},
   "source": [
    "### ClusterMember\n",
    "\n",
    "Represents an individual entity within a cluster. It provides information about the entity's span, associated named entity recognition (NER) information, the sentence it belongs to, and the identifier of the cluster to which it is assigned. The class serves as a container for information about an individual entity within a cluster. It encapsulates details such as the span, NER information, sentence context, and the cluster to which the entity is assigned.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `span`: A Span instance representing the span of the entity in the document.\n",
    "  - `ner`: A NER instance representing the NER information for the entity.\n",
    "  - `sentence`: A Sentence instance representing the sentence containing the entity.\n",
    "  - `cluster_id`: The identifier of the cluster to which the entity belongs.\n",
    "- Attributes\n",
    "  - `span`: A Span instance representing the span of the entity.\n",
    "  - `ner`: A NER instance representing the NER information for the entity.\n",
    "  - `sentence`: A Sentence instance representing the sentence containing the entity.\n",
    "  - `cluster_id`: The identifier of the cluster to which the entity belongs.\n",
    "  \n",
    "#### Initialization Details\n",
    "\n",
    "The `__init__` method initializes a `ClusterMember` by assigning values to its attributes based on the provided parameters.\n",
    "Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the `ClusterMember`, including the sentence index and a representation of its span.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79298118-30aa-4827-8b14-9f04d1e27fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClusterMember:\n",
    "    def __init__(self, span, ner, sentence, cluster_id):\n",
    "        self.span = span\n",
    "        self.ner = ner\n",
    "        self.sentence = sentence\n",
    "        self.cluster_id = cluster_id\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<{self.sentence.sentence_ix}> \" + self.span.__repr__()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d4353-5d76-4aec-a46c-097943a25f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sentence\n",
    "\n",
    "This class represents a sentence. It encapsulates information about a sentence, including its text and associated entities (NER, relations, events). It provides methods for accessing and manipulating this information.\n",
    "\n",
    "Let's go through each method:\n",
    "\n",
    "#### `__init__` method:\n",
    "\n",
    "- Initializes an instance of the `Sentence` class.\n",
    "- Takes an `entry`, `sentence_start` (index of the sentence start in the document), and `sentence_ix` (sentence index) as input.\n",
    "- Stores information about the sentence's start position, text, and index.\n",
    "- Parses gold entities (NER, relations, events) and predicted entities (NER, relations, events).\n",
    "- Stores top spans if available.\n",
    "\n",
    "#### `__repr__` method:\n",
    "\n",
    "- Returns a string representation of the sentence, including the text and token indices.\n",
    "\n",
    "#### `__len__` method:\n",
    "\n",
    "-Returns the number of tokens in the sentence.\n",
    "\n",
    "#### `get_flavor` method:\n",
    "\n",
    "- Given an argument (presumably an entity), retrieves its flavor from the gold NER annotations.\n",
    "- If multiple NER annotations are found for the same span, prints a message (debugging)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89456192-84e8-4cf3-8833-605db4f7481c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, entry, sentence_start, sentence_ix):\n",
    "        self.sentence_start = sentence_start\n",
    "        self.text = entry[\"sentences\"]\n",
    "        self.sentence_ix = sentence_ix\n",
    "        # Gold\n",
    "        if \"ner_flavor\" in entry:\n",
    "            self.ner = [NER(this_ner, self.text, sentence_start, flavor=this_flavor)\n",
    "                        for this_ner, this_flavor in zip(entry[\"ner\"], entry[\"ner_flavor\"])]\n",
    "        elif \"ner\" in entry:\n",
    "            self.ner = [NER(this_ner, self.text, sentence_start)\n",
    "                        for this_ner in entry[\"ner\"]]\n",
    "        if \"relations\" in entry:\n",
    "            self.relations = [Relation(this_relation, self.text, sentence_start) for\n",
    "                              this_relation in entry[\"relations\"]]\n",
    "        if \"events\" in entry:\n",
    "            self.events = Events(entry[\"events\"], self.text, sentence_start)\n",
    "\n",
    "        # Predicted\n",
    "        if \"predicted_ner\" in entry:\n",
    "            self.predicted_ner = [NER(this_ner, self.text, sentence_start, flavor=None) for\n",
    "                                  this_ner in entry[\"predicted_ner\"]]\n",
    "        if \"predicted_relations\" in entry:\n",
    "            self.predicted_relations = [Relation(this_relation, self.text, sentence_start) for\n",
    "                                        this_relation in entry[\"predicted_relations\"]]\n",
    "        if \"predicted_events\" in entry:\n",
    "            self.predicted_events = Events(entry[\"predicted_events\"], self.text, sentence_start)\n",
    "\n",
    "        # Top spans\n",
    "        if \"top_spans\" in entry:\n",
    "            self.top_spans = [NER(this_ner, self.text, sentence_start, flavor=None) for\n",
    "                                this_ner in entry[\"top_spans\"]]\n",
    "\n",
    "    def __repr__(self):\n",
    "        the_text = \" \".join(self.text)\n",
    "        the_lengths = np.array([len(x) for x in self.text])\n",
    "        tok_ixs = \"\"\n",
    "        for i, offset in enumerate(the_lengths):\n",
    "            true_offset = offset if i < 10 else offset - 1\n",
    "            tok_ixs += str(i)\n",
    "            tok_ixs += \" \" * true_offset\n",
    "\n",
    "        return the_text + \"\\n\" + tok_ixs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text)\n",
    "\n",
    "    def get_flavor(self, argument):\n",
    "        the_ner = [x for x in self.ner if x.span == argument.span]\n",
    "        if len(the_ner) > 1:\n",
    "            print(\"Weird\")\n",
    "        if the_ner:\n",
    "            the_flavor = the_ner[0].flavor\n",
    "        else:\n",
    "            the_flavor = None\n",
    "        return the_flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b54ec5-76bf-42d5-be74-54158903f5cf",
   "metadata": {},
   "source": [
    "### NER\n",
    "\n",
    "The NER class represents a Named Entity Recognition annotation within a sentence. It encapsulates information about a named entity, providing methods for representation and equality checks. The `Span` (we'll get to it next) class is used to represent the span of the named entity within the context of the sentence.\n",
    "\n",
    "Here are some details about it:\n",
    "#### Initialization\n",
    "\n",
    "- Parameters:\n",
    "  - `ner`: A list containing information about the NER span, including start index, end index, and label.\n",
    "  - `text`: The text content of the sentence.\n",
    "  - `sentence_start`: The index of the sentence start in the document.\n",
    "  - `flavor`: An optional parameter representing the flavor or type of the named entity.\n",
    "  \n",
    "- Attributes:\n",
    "  - `span`: An instance of the Span class representing the span of the NER annotation.\n",
    "  - `label`: The label assigned to the NER entity.\n",
    "  - `flavor`: The flavor or type of the named entity.\n",
    "  \n",
    "- Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the NER annotation, including the span and label.\n",
    "Equality Check\n",
    "\n",
    "`__eq__` Method:\n",
    "Checks if two NER instances are equal by comparing their span, label, and flavor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffb706e4-8d08-42c1-99f5-9dce04b6b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NER:\n",
    "    def __init__(self, ner, text, sentence_start, flavor=None):\n",
    "        self.span = Span(ner[0], ner[1], text, sentence_start)\n",
    "        self.label = ner[2]\n",
    "        self.flavor = flavor\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.span.__repr__() + \": \" + self.label\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.span == other.span and\n",
    "                self.label == other.label and\n",
    "                self.flavor == other.flavor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643b324b-fad6-45c0-9998-64e92381e67c",
   "metadata": {},
   "source": [
    "### Span\n",
    "\n",
    "The `Span` class represents a span of text within a document. It encapsulate information about a text span, providing methods for representation, equality checks, and hashing. It ensures the proper handling of spans within the document and sentence contexts.\n",
    "\n",
    "#### Initialization\n",
    "- Parameters:\n",
    "  - `start`: The starting index of the span in the entire document.\n",
    "  - `end`: The ending index of the span in the entire document.\n",
    "  - `text`: The text content of the entire document.\n",
    "  - `sentence_start`: The index of the sentence start in the document.\n",
    "  \n",
    "- Attributes\n",
    "  - `start_doc`, `end_doc`: The start and end indices of the span in the entire document.\n",
    "  - `span_doc`: A tuple representing the span in the entire document.\n",
    "  - `start_sent`, `end_sent`: The start and end indices of the span within the sentence.\n",
    "  - `span_sent`: A tuple representing the span within the sentence.\n",
    "  - `text`: The actual text content of the span.\n",
    "  \n",
    "#### Representation\n",
    "\n",
    "`__repr__` Method:\n",
    "Returns a string representation of the span, including start and end indices and the actual text content.\n",
    "Equality Check\n",
    "\n",
    "`__eq__` Method:\n",
    "Checks if two Span instances are equal by comparing their spans in both the document and the sentence, along with the text content.\n",
    "Hashing\n",
    "\n",
    "`__hash__` Method:\n",
    "Computes a hash value for the Span instance based on its document and sentence spans, as well as the text content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c06fb6-8119-4258-a449-29cf2cdf0acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Span:\n",
    "    def __init__(self, start, end, text, sentence_start):\n",
    "        self.start_doc = start\n",
    "        self.end_doc = end\n",
    "        self.span_doc = (self.start_doc, self.end_doc)\n",
    "        self.start_sent = start - sentence_start\n",
    "        self.end_sent = end - sentence_start\n",
    "        self.span_sent = (self.start_sent, self.end_sent)\n",
    "        self.text = text[self.start_sent:self.end_sent + 1]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str((self.start_sent, self.end_sent, self.text))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.span_doc == other.span_doc and\n",
    "                self.span_sent == other.span_sent and\n",
    "                self.text == other.text)\n",
    "\n",
    "    def __hash__(self):\n",
    "        tup = self.span_doc + self.span_sent + (\" \".join(self.text),)\n",
    "        return hash(tup)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ce9fb0-36b5-43fd-b568-893a4b410550",
   "metadata": {},
   "source": [
    "### Relation\n",
    "\n",
    "The Relation class is designed to represent a relation between two spans within a text. It encapsulates information about the spans, such as their start and end positions, the text they cover, and the label assigned to the relation. Here's a breakdown of the class:\n",
    "\n",
    "#### Initialization\n",
    "\n",
    "- Parameters:\n",
    "\n",
    "  - `relation`: A tuple representing the start and end positions of the two spans and the label of the relation.\n",
    "  - `text`: The text containing the spans.\n",
    "  - `sentence_start`: The starting position of the sentence in the text.\n",
    "  \n",
    "- Attributes\n",
    "\n",
    "  - `pair`: A tuple containing two Span objects (span1 and span2) representing the spans of the relation.\n",
    "  - `label`: The label of the relation.\n",
    "  \n",
    "#### Representation\n",
    "`__repr__` Method: Returns a string representation of the Relation object, including the string representations of the two spans, the relation between them (\", \"), and the label.\n",
    "\n",
    "`__eq__` Method: Checks if two Relation objects are equal by comparing their span pairs and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd063a30-b42b-4fd5-a046-01e2ea332093",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relation:\n",
    "    def __init__(self, relation, text, sentence_start):\n",
    "        start1, end1 = relation[0], relation[1]\n",
    "        start2, end2 = relation[2], relation[3]\n",
    "        label = relation[4]\n",
    "        span1 = Span(start1, end1, text, sentence_start)\n",
    "        span2 = Span(start2, end2, text, sentence_start)\n",
    "        self.pair = (span1, span2)\n",
    "        self.label = label\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.pair[0].__repr__() + \", \" + self.pair[1].__repr__() + \": \" + self.label\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return (self.pair == other.pair) and (self.label == other.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d996f9-66a7-40ba-b5ce-ffff20169bad",
   "metadata": {},
   "source": [
    "### NpEncoder\n",
    "This class is a custom JSON encoder that extends the json.JSONEncoder class. It is designed to handle the encoding of NumPy-specific data types into a JSON-compatible format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105c3337-8efb-41f5-8469-3283ed350c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NpEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.integer):\n",
    "            return int(obj)\n",
    "        elif isinstance(obj, np.floating):\n",
    "            return float(obj)\n",
    "        elif isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        else:\n",
    "            return super(NpEncoder, self).default(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f51af1-6622-483e-bcec-44060540a4c3",
   "metadata": {},
   "source": [
    "## Utility functions\n",
    "The authors have aslo implemented some utility functions. Let's go through them and understand what they do.\n",
    "\n",
    "### get_sentence_of_span\n",
    "This function determines the index of the sentence to which a given span belongs within a document. It takes three parameters: \n",
    "- `span`: A tuple representing the start and end indices of the span.\n",
    "- `sentence_starts`: A list containing the starting indices of sentences in the document.\n",
    "- `doc_tokens`: The total number of tokens (or words) in the document.\n",
    "\n",
    "I've also added some comments to the function to explain how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e485a789-2c92-4840-aa83-c4534fe397fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_of_span(span, sentence_starts, doc_tokens):\n",
    "    \"\"\"\n",
    "    Return the index of the sentence that the span is part of.\n",
    "    \"\"\"\n",
    "    # Inclusive sentence ends\n",
    "    sentence_ends = [x - 1 for x in sentence_starts[1:]] + [doc_tokens - 1]\n",
    "    \n",
    "    # Check if the span is between each pair of sentence starts and ends\n",
    "    in_between = [span[0] >= start and span[1] <= end\n",
    "                  for start, end in zip(sentence_starts, sentence_ends)]\n",
    "    \n",
    "    # Ensure that the span is part of exactly one sentence\n",
    "    assert sum(in_between) == 1\n",
    "    \n",
    "    # Get the index of the sentence to which the span belongs\n",
    "    the_sentence = in_between.index(True)\n",
    "    \n",
    "    return the_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf33f5b-62b2-4676-9042-22a6eb1f267a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### convert_dataset_to_samples\n",
    "As the name suggests, this function is used to convert a dataset into a format suitable for training the entity model.\n",
    "\n",
    "It processes a dataset of documents, extracts information such as sentences and named entity recognition (NER) labels, and organizes the data into a format suitable for training the entity model.\n",
    "\n",
    "The function takes several parameters:\n",
    "\n",
    "dataset: A collection of documents, each containing sentences and NER information.\n",
    "- `max_span_length`: The maximum length of spans to consider.\n",
    "- `ner_label2id`: A mapping from NER labels to unique identifiers.\n",
    "- `context_window`: The size of the context window to consider around each sentence.\n",
    "- `split`: A parameter used for splitting the data into train and dev sets (for ACE04 dataset).\n",
    "\n",
    "Here's a breakdown of how the convert_dataset_to_samples function works:\n",
    "\n",
    "1. Initialization: The function initializes variables to keep track of statistics such as the number of NER labels (`num_ner`), the maximum sentence length (`max_len`), the maximum number of NER labels in a sentence (`max_ner`), and the number of overlapping spans (`num_overlap`).\n",
    "\n",
    "2. Data Splitting: If the split parameter is specified, the function determines the range of data to process based on whether to include the full dataset, the first 90% (split == 1), or the last 10% (split == 2).\n",
    "\n",
    "3. Processing Documents and Sentences: The function iterates over the documents and sentences within the specified data range. For each sentence, it creates a dictionary (`sample`) to store information about the document, sentence index, tokens, and more.\n",
    "\n",
    "4. Context Window Handling: If a `context_window` is specified and the sentence length exceeds it, the function adds left and right context to the current sentence.\n",
    "\n",
    "5. NER Label Processing: The function processes NER labels for each sentence and constructs spans. It records the spans' starting and ending indices, length, and assigns labels based on the NER information.\n",
    "\n",
    "6. Statistics and Logging: The function updates statistics such as the average input length, maximum length, and maximum NER labels. It also logs information about the dataset, including the number of extracted samples and NER labels.\n",
    "\n",
    "7. Return: The function returns a list of dictionaries (`samples`), where each dictionary represents a processed sample suitable for model training, along with the total number of NER labels (`num_ner`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ed493d5-63d1-4163-91d5-b121f747044b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dataset_to_samples(dataset, max_span_length, ner_label2id=None, context_window=0, split=0):\n",
    "    \"\"\"\n",
    "    Extract sentences and gold entities from a dataset\n",
    "    \"\"\"\n",
    "    # split: split the data into train and dev (for ACE04)\n",
    "    # split == 0: don't split\n",
    "    # split == 1: return first 90% (train)\n",
    "    # split == 2: return last 10% (dev)\n",
    "    samples = []\n",
    "    num_ner = 0\n",
    "    max_len = 0\n",
    "    max_ner = 0\n",
    "    num_overlap = 0\n",
    "    \n",
    "    if split == 0:\n",
    "        data_range = (0, len(dataset))\n",
    "    elif split == 1:\n",
    "        data_range = (0, int(len(dataset)*0.9))\n",
    "    elif split == 2:\n",
    "        data_range = (int(len(dataset)*0.9), len(dataset))\n",
    "\n",
    "    for c, doc in enumerate(dataset):\n",
    "        if c < data_range[0] or c >= data_range[1]:\n",
    "            continue\n",
    "        for i, sent in enumerate(doc):\n",
    "            num_ner += len(sent.ner)\n",
    "            sample = {\n",
    "                'doc_key': doc._doc_key,\n",
    "                'sentence_ix': sent.sentence_ix,\n",
    "            }\n",
    "            if context_window != 0 and len(sent.text) > context_window:\n",
    "                logger.info('Long sentence: {} {}'.format(sample, len(sent.text)))\n",
    "                # print('Exclude:', sample)\n",
    "                # continue\n",
    "            sample['tokens'] = sent.text\n",
    "            sample['sent_length'] = len(sent.text)\n",
    "            sent_start = 0\n",
    "            sent_end = len(sample['tokens'])\n",
    "\n",
    "            max_len = max(max_len, len(sent.text))\n",
    "            max_ner = max(max_ner, len(sent.ner))\n",
    "\n",
    "            if context_window > 0:\n",
    "                add_left = (context_window-len(sent.text)) // 2\n",
    "                add_right = (context_window-len(sent.text)) - add_left\n",
    "                \n",
    "                # add left context\n",
    "                j = i - 1\n",
    "                while j >= 0 and add_left > 0:\n",
    "                    context_to_add = doc[j].text[-add_left:]\n",
    "                    sample['tokens'] = context_to_add + sample['tokens']\n",
    "                    add_left -= len(context_to_add)\n",
    "                    sent_start += len(context_to_add)\n",
    "                    sent_end += len(context_to_add)\n",
    "                    j -= 1\n",
    "\n",
    "                # add right context\n",
    "                j = i + 1\n",
    "                while j < len(doc) and add_right > 0:\n",
    "                    context_to_add = doc[j].text[:add_right]\n",
    "                    sample['tokens'] = sample['tokens'] + context_to_add\n",
    "                    add_right -= len(context_to_add)\n",
    "                    j += 1\n",
    "\n",
    "            sample['sent_start'] = sent_start\n",
    "            sample['sent_end'] = sent_end\n",
    "            sample['sent_start_in_doc'] = sent.sentence_start\n",
    "            \n",
    "            sent_ner = {}\n",
    "            for ner in sent.ner:\n",
    "                sent_ner[ner.span.span_sent] = ner.label\n",
    "\n",
    "            span2id = {}\n",
    "            sample['spans'] = []\n",
    "            sample['spans_label'] = []\n",
    "            for i in range(len(sent.text)):\n",
    "                for j in range(i, min(len(sent.text), i+max_span_length)):\n",
    "                    sample['spans'].append((i+sent_start, j+sent_start, j-i+1))\n",
    "                    span2id[(i, j)] = len(sample['spans'])-1\n",
    "                    if (i, j) not in sent_ner:\n",
    "                        sample['spans_label'].append(0)\n",
    "                    else:\n",
    "                        sample['spans_label'].append(ner_label2id[sent_ner[(i, j)]])\n",
    "            samples.append(sample)\n",
    "    avg_length = sum([len(sample['tokens']) for sample in samples]) / len(samples)\n",
    "    max_length = max([len(sample['tokens']) for sample in samples])\n",
    "    logger.info('# Overlap: %d'%num_overlap)\n",
    "    logger.info('Extracted %d samples from %d documents, with %d NER labels, %.3f avg input length, %d max length'%(len(samples), data_range[1]-data_range[0], num_ner, avg_length, max_length))\n",
    "    logger.info('Max Length: %d, max NER: %d'%(max_len, max_ner))\n",
    "    return samples, num_ner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9acad0af-6560-44f2-bd0c-208e4f70aa4a",
   "metadata": {},
   "source": [
    "### batchify\n",
    "\n",
    "The `batchify` function is designed to organize a list of samples into batches of a specified size (`batch_size`). The function handles some special cases, such as creating single-sample batches for sentences that are too long to avoid GPU out-of-memory (OOM) issues.\n",
    "\n",
    "Here's a breakdown of how the `batchify` function works:\n",
    "\n",
    "1. Initialization: The function starts by initializing variables, including the total number of samples (`num_samples`) and an empty list to store batches (`list_samples_batches`).\n",
    "\n",
    "2. Single Batch for Long Sentences: The function checks each sample, and if the length of its tokens exceeds a threshold (350 in this case), it is added to a list (`to_single_batch`). For these long sentences, the function logs information and creates individual batches containing only that sample.\n",
    "\n",
    "3. Remove Single Batches from the Original List: The samples identified as long sentences are removed from the original list of samples.\n",
    "\n",
    "4. Create Batches: The function then proceeds to create batches from the remaining samples. It iterates over the samples, grouping them into batches of size `batch_size`. These batches are appended to the list of batches (`list_samples_batches`).\n",
    "\n",
    "5. Assertion Check: The function asserts that the total number of samples in the batches equals the original number of samples.\n",
    "\n",
    "6. Return: The function returns a list of batches, where each batch is a list of samples. Some of these batches may contain only one sample if the sentence was too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "99a2301a-2a86-422e-a00e-300aab275ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchify(samples, batch_size):\n",
    "    \"\"\"\n",
    "    Batchfy samples with a batch size\n",
    "    \"\"\"\n",
    "    num_samples = len(samples)\n",
    "\n",
    "    list_samples_batches = []\n",
    "    \n",
    "    # if a sentence is too long, make itself a batch to avoid GPU OOM\n",
    "    to_single_batch = []\n",
    "    for i in range(0, len(samples)):\n",
    "        if len(samples[i]['tokens']) > 350:\n",
    "            to_single_batch.append(i)\n",
    "    \n",
    "    for i in to_single_batch:\n",
    "        logger.info('Single batch sample: %s-%d', samples[i]['doc_key'], samples[i]['sentence_ix'])\n",
    "        list_samples_batches.append([samples[i]])\n",
    "    samples = [sample for i, sample in enumerate(samples) if i not in to_single_batch]\n",
    "\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        list_samples_batches.append(samples[i:i+batch_size])\n",
    "\n",
    "    assert(sum([len(batch) for batch in list_samples_batches]) == num_samples)\n",
    "\n",
    "    return list_samples_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b9418f-724f-4989-a22a-8dde8903e9dd",
   "metadata": {},
   "source": [
    "### get_labelmap\n",
    "\n",
    "This function takes a list of labels (`label_list`) and creates two mappings: `label2id` and `id2label`. These mappings are useful for converting between label names and their corresponding numerical identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d2737e8-1fd1-4d4a-a5be-cf3c80b336c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelmap(label_list):\n",
    "    label2id = {}\n",
    "    id2label = {}\n",
    "    for i, label in enumerate(label_list):\n",
    "        label2id[label] = i + 1\n",
    "        id2label[i + 1] = label\n",
    "    return label2id, id2label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dab563-5a08-419a-970c-fb29c4893fc7",
   "metadata": {},
   "source": [
    "### output_ner_predictions\n",
    "\n",
    "\n",
    "The output_ner_predictions function is designed to make NER predictions using a trained model, and then save these predictions as a JSON file. The function takes the following parameters:\n",
    "\n",
    "- `model`: The trained NER model.\n",
    "- `batches`: A list of batches, each containing samples for prediction.\n",
    "- `dataset`: The original dataset, which may contain the ground truth NER information.\n",
    "- `output_file`: The file path where the NER predictions will be saved.\n",
    "\n",
    "Here's a breakdown of how the output_ner_predictions function works:\n",
    "\n",
    "1. Initialization: The function initializes dictionaries (`ner_result` and `span_hidden_table`) and a counter (`tot_pred_ett`) to keep track of predicted entities.\n",
    "\n",
    "2. Batch Prediction: The function iterates over batches and uses the model to predict NER labels (`pred_ner`). It adjusts the predicted spans based on the sentence and document indices.\n",
    "\n",
    "3. Construction of NER Result Dictionary: The function constructs a dictionary (`ner_result`) where keys are **document and sentence indices**, and values are **lists of predicted entities** in the format [start, end, label].\n",
    "\n",
    "4. Updating Dataset with Predictions: The function updates the original dataset's JSON representation (js) with the predicted NER entities and **empty predicted relations**.\n",
    "\n",
    "5. Writing Predictions to File: The function writes the updated JSON representation to the specified output file.\n",
    "\n",
    "This JSON file is the input for the relation model in the run_relation notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2124bf2-8ad4-4007-8d03-0b415ee4926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_ner_predictions(model, batches, dataset, output_file):\n",
    "    \"\"\"\n",
    "    Save the prediction as a json file\n",
    "    \"\"\"\n",
    "    ner_result = {}\n",
    "    span_hidden_table = {}\n",
    "    tot_pred_ett = 0\n",
    "    \n",
    "    # Iterate over batches and make predictions\n",
    "    for i in range(len(batches)):\n",
    "        output_dict = model.run_batch(batches[i], training=False)\n",
    "        pred_ner = output_dict['pred_ner']\n",
    "        \n",
    "        # Iterate over samples in the batch\n",
    "        for sample, preds in zip(batches[i], pred_ner):\n",
    "            off = sample['sent_start_in_doc'] - sample['sent_start']\n",
    "            k = sample['doc_key'] + '-' + str(sample['sentence_ix'])\n",
    "            ner_result[k] = []\n",
    "            \n",
    "            # Iterate over spans and predicted labels\n",
    "            for span, pred in zip(sample['spans'], preds):\n",
    "                span_id = '%s::%d::(%d,%d)'%(sample['doc_key'], sample['sentence_ix'], span[0]+off, span[1]+off)\n",
    "                if pred == 0:\n",
    "                    continue\n",
    "                ner_result[k].append([span[0]+off, span[1]+off, ner_id2label[pred]])\n",
    "            tot_pred_ett += len(ner_result[k])\n",
    "\n",
    "    logger.info('Total pred entities: %d'%tot_pred_ett)\n",
    "\n",
    "    # Update the original dataset with predicted NER entities\n",
    "    js = dataset.js\n",
    "    for i, doc in enumerate(js):\n",
    "        doc[\"predicted_ner\"] = []\n",
    "        doc[\"predicted_relations\"] = []\n",
    "        for j in range(len(doc[\"sentences\"])):\n",
    "            k = doc['doc_key'] + '-' + str(j)\n",
    "            if k in ner_result:\n",
    "                doc[\"predicted_ner\"].append(ner_result[k])\n",
    "            else:\n",
    "                logger.info('%s not in NER results!'%k)\n",
    "                doc[\"predicted_ner\"].append([])\n",
    "            \n",
    "            doc[\"predicted_relations\"].append([])\n",
    "\n",
    "        js[i] = doc\n",
    "\n",
    "    # Write the updated JSON representation to the output file\n",
    "    logger.info('Output predictions to %s..'%(output_file))\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('\\n'.join(json.dumps(doc, cls=NpEncoder) for doc in js))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774406cc-b2f4-41e5-b18c-9013aa27f81e",
   "metadata": {},
   "source": [
    "### evaluate\n",
    "\n",
    "The evaluate function is designed to evaluate the performance of an entity model. The function takes the following parameters:\n",
    "\n",
    "- `model`: The trained entity model.\n",
    "- `batches`: A list of batches, each containing samples for evaluation.\n",
    "- `tot_gold`: The total number of gold (ground truth) entities in the dataset.\n",
    "\n",
    "Here's a breakdown of how the evaluate function works:\n",
    "1. Initialization: The function initializes variables to keep track of correct predictions (`cor)`, total predictions (`tot_pred`), correct predictions for spans (`l_cor`), and total spans (`l_tot`).\n",
    "\n",
    "2. Batch Evaluation: The function iterates over batches, uses the model to predict NER labels (`pred_ner`), and compares the predictions with the gold labels for each span.\n",
    "\n",
    "3. Calculation of Metrics: The function calculates accuracy, precision (`p`), recall (`r`), and F1 score (`f1`) based on the counts of correct predictions, total predictions, and total gold entities.\n",
    "\n",
    "4. Logging and Return: The function logs the calculated metrics and the time taken for evaluation. It then returns the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6b146633-7da1-4afb-9ad5-77d7f4fd9432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, batches, tot_gold):\n",
    "    \"\"\"\n",
    "    Evaluate the entity model\n",
    "    \"\"\"\n",
    "    logger.info('Evaluating...')\n",
    "    c_time = time.time()\n",
    "    cor = 0\n",
    "    tot_pred = 0\n",
    "    l_cor = 0\n",
    "    l_tot = 0\n",
    "\n",
    "    for i in range(len(batches)):\n",
    "        output_dict = model.run_batch(batches[i], training=False)\n",
    "        pred_ner = output_dict['pred_ner']\n",
    "        for sample, preds in zip(batches[i], pred_ner):\n",
    "            for gold, pred in zip(sample['spans_label'], preds):\n",
    "                l_tot += 1\n",
    "                if pred == gold:\n",
    "                    l_cor += 1\n",
    "                if pred != 0 and gold != 0 and pred == gold:\n",
    "                    cor += 1\n",
    "                if pred != 0:\n",
    "                    tot_pred += 1\n",
    "                   \n",
    "    acc = l_cor / l_tot\n",
    "    logger.info('Accuracy: %5f'%acc)\n",
    "    logger.info('Cor: %d, Pred TOT: %d, Gold TOT: %d'%(cor, tot_pred, tot_gold))\n",
    "    p = cor / tot_pred if cor > 0 else 0.0\n",
    "    r = cor / tot_gold if cor > 0 else 0.0\n",
    "    f1 = 2 * (p * r) / (p + r) if cor > 0 else 0.0\n",
    "    logger.info('P: %.5f, R: %.5f, F1: %.5f'%(p, r, f1))\n",
    "    logger.info('Used time: %f'%(time.time()-c_time))\n",
    "    return f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "361483ca-d980-47b2-a512-89d43bd5ef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fields_to_batches(d, keys_to_ignore=[]):\n",
    "    keys = [key for key in d.keys() if key not in keys_to_ignore]\n",
    "    lengths = [len(d[k]) for k in keys]\n",
    "    assert len(set(lengths)) == 1\n",
    "    length = lengths[0]\n",
    "    res = [{k: d[k][i] for k in keys} for i in range(length)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8d67fc-28f7-4404-ad92-6635d00f67ff",
   "metadata": {},
   "source": [
    "## Run entity do eval\n",
    "\n",
    "Now we can actually run the model. And remember that we're using a pre trained model, we havn't trained our own model yet. We will do that in the next steps.\n",
    "\n",
    "### Basic setup\n",
    "\n",
    "First a variable `task_ner_labels` is defined, a dictionarry mapping each dataset to its entity types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e2f8486-6867-4fd8-a7ff-7250ec40f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ner_labels = {\n",
    "    'ace04': ['FAC', 'WEA', 'LOC', 'VEH', 'GPE', 'ORG', 'PER'],\n",
    "    'ace05': ['FAC', 'WEA', 'LOC', 'VEH', 'GPE', 'ORG', 'PER'],\n",
    "    'scierc': ['Method', 'OtherScientificTerm', 'Task', 'Generic', 'Material', 'Metric'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a4c3b-f5d2-4ffc-b33b-3e4ec5949870",
   "metadata": {},
   "source": [
    "Then we define some variables:\n",
    "- `data_dir`: The directory in which our input data is stored.\n",
    "- `output_dir`: The directory to which to write  the output of the mnodel.\n",
    "- `task`: The task that the model will be used to make predictions on. \n",
    "- max_span_length: The maximum length of spans to consider. \n",
    "- context_window: The size of the context window to consider around each sentence.\n",
    "- eval_batch_size: The batch size of the samples.\n",
    "- test_pred_filename: The name of the prediction output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80b069ca-18d9-4075-87d3-1d0d13e0f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd() + '/scierc_data/processed_data/json'\n",
    "output_dir = os.getcwd() + '/scierc_models/ent-scib-ctx0/'\n",
    "task = 'scierc'\n",
    "max_span_length = 8\n",
    "context_window = 0\n",
    "eval_batch_size = 32\n",
    "test_pred_filename = 'ent_pred_test.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d1e65-35ed-4f3d-81fd-60b4b9a93dce",
   "metadata": {},
   "source": [
    "### Running and evaluationg the pre-trained model\n",
    "\n",
    "Now that the setup is out of the way. We can actually run the model and evaluate it with a pre-trained BERT-based model on the SciERC dataset.\n",
    "\n",
    "#### Data File Paths:\n",
    "Since the SciERC dataset is already split into a training, development, and test set. We don't need to perform any split. So let's just load set the paths to the data files dowanloaded with the dataset.\n",
    "\n",
    "The input data format of the entity model is JSONL. Each line of the input file contains one document in the following format.\n",
    "```json\n",
    "{\n",
    "  # document ID (please make sure doc_key can be used to identify a certain document)\n",
    "  \"doc_key\": \"CNN_ENG_20030306_083604.6\",\n",
    "\n",
    "  # sentences in the document, each sentence is a list of tokens\n",
    "  \"sentences\": [\n",
    "    [...],\n",
    "    [...],\n",
    "    [\"tens\", \"of\", \"thousands\", \"of\", \"college\", ...],\n",
    "    ...\n",
    "  ],\n",
    "\n",
    "  # entities (boundaries and entity type) in each sentence\n",
    "  \"ner\": [\n",
    "    [...],\n",
    "    [...],\n",
    "    [[26, 26, \"LOC\"], [14, 14, \"PER\"], ...], #the boundary positions are indexed in the document level\n",
    "    ...,\n",
    "  ],\n",
    "\n",
    "  # relations (two spans and relation type) in each sentence\n",
    "  \"relations\": [\n",
    "    [...],\n",
    "    [...],\n",
    "    [[14, 14, 10, 10, \"ORG-AFF\"], [14, 14, 12, 13, \"ORG-AFF\"], ...],\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfe19c86-0a03-46ee-85e1-1a794f84919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = os.path.join(data_dir, 'train.json')\n",
    "dev_data = os.path.join(data_dir, 'dev.json')\n",
    "test_data = os.path.join(data_dir, 'test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540da85-feeb-4269-8a58-8aa9a30d80e5",
   "metadata": {},
   "source": [
    "#### Output Directory Check\n",
    "\n",
    "Then, just to be safe, we check if the specified output directory (`output_dir`) exists. If not, we create the directory. This ensures that the output directory is available for storing model checkpoints, predictions, or other outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89f905f0-dcf6-4435-889c-86f2cc21b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d34ad66-e99e-4a89-89cd-cb4d7b31336b",
   "metadata": {},
   "source": [
    "#### NER Label Mapping\n",
    "\n",
    "The `get_labelmap` function is used to get the mapping for the SchiREC task as discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d478bec-612d-4431-9668-145a59a627cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_label2id, ner_id2label = get_labelmap(task_ner_labels[task])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6fbcb1-0b3c-4d84-9f43-166078354d61",
   "metadata": {},
   "source": [
    "#### Development Dataset Processing\n",
    "\n",
    "The development dataset (`dev_data`) is loaded into a `Dataset` object. Then, it is processed using the `convert_dataset_to_samples` function to obtain samples and NER labels. The samples are batchified using the `batchify` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59bf65e9-fad8-4663-950e-25cab705bc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/23/2023 17:44:41 - INFO - root - # Overlap: 0\n",
      "11/23/2023 17:44:41 - INFO - root - Extracted 275 samples from 50 documents, with 811 NER labels, 23.713 avg input length, 68 max length\n",
      "11/23/2023 17:44:41 - INFO - root - Max Length: 68, max NER: 11\n"
     ]
    }
   ],
   "source": [
    "dev_data = Dataset(dev_data)\n",
    "dev_samples, dev_ner = convert_dataset_to_samples(dev_data, max_span_length, ner_label2id=ner_label2id, context_window=context_window)\n",
    "dev_batches = batchify(dev_samples, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96822b91-d8f4-4bc9-bd7b-12c339acca82",
   "metadata": {},
   "source": [
    "#### Model Initialization\n",
    "\n",
    "The BERT-based entity model (`EntityModel`) is initialized with specific parameters, including the BERT model name (`allenai/scibert_scivocab_uncased`), output directory for saving checkpoints (`bert_model_dir`), and the number of NER labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ac52da30-c284-4a48-b6d4-cc2565e8812a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/23/2023 13:33:05 - INFO - root - Loading BERT model from C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//\n",
      "11/23/2023 13:33:05 - INFO - transformers.tokenization_utils_base - Model name 'C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/23/2023 13:33:05 - INFO - transformers.tokenization_utils_base - Didn't find file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//added_tokens.json. We won't load it.\n",
      "11/23/2023 13:33:05 - INFO - transformers.tokenization_utils_base - Didn't find file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//tokenizer.json. We won't load it.\n",
      "11/23/2023 13:33:05 - INFO - transformers.tokenization_utils_base - loading file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//vocab.txt\n",
      "11/23/2023 13:33:05 - INFO - transformers.tokenization_utils_base - loading file None\n",
      "11/23/2023 13:33:05 - INFO - transformers.tokenization_utils_base - loading file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//special_tokens_map.json\n",
      "11/23/2023 13:33:05 - INFO - transformers.tokenization_utils_base - loading file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//tokenizer_config.json\n",
      "11/23/2023 13:33:05 - INFO - transformers.tokenization_utils_base - loading file None\n",
      "11/23/2023 13:33:05 - INFO - transformers.configuration_utils - loading configuration file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//config.json\n",
      "11/23/2023 13:33:05 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertNerRe\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/23/2023 13:33:05 - INFO - transformers.modeling_utils - loading weights file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//pytorch_model.bin\n",
      "11/23/2023 13:33:08 - INFO - transformers.modeling_utils - All model checkpoint weights were used when initializing BertForEntity.\n",
      "\n",
      "11/23/2023 13:33:08 - INFO - transformers.modeling_utils - All the weights of BertForEntity were initialized from the model checkpoint at C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0//.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForEntity for predictions without further training.\n",
      "11/23/2023 13:33:08 - INFO - root - Moving to CUDA...\n",
      "11/23/2023 13:33:08 - INFO - root - # GPUs = 1\n"
     ]
    }
   ],
   "source": [
    "bert_model_dir = output_dir\n",
    "num_ner_labels = len(task_ner_labels[task]) + 1\n",
    "model = EntityModel(model='allenai/scibert_scivocab_uncased', bert_model_dir=bert_model_dir, use_albert=False, max_span_length=max_span_length, num_ner_labels=num_ner_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b65c7f-f07d-438a-980f-05f96e418821",
   "metadata": {},
   "source": [
    "#### Test Dataset Processing and Evaluation\n",
    "\n",
    "Finally the test dataset (`test_data`) is loaded, processed, and batchified similarly to the development dataset. The model is then evaluated on the test data using the `evaluate` function, and the NER predictions are saved to a file using the `output_ner_predictions` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f86cef2-d427-47d7-a3f1-1852cf1313d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/23/2023 13:33:13 - INFO - root - # Overlap: 0\n",
      "11/23/2023 13:33:13 - INFO - root - Extracted 551 samples from 100 documents, with 1685 NER labels, 24.321 avg input length, 97 max length\n",
      "11/23/2023 13:33:13 - INFO - root - Max Length: 97, max NER: 13\n",
      "11/23/2023 13:33:13 - INFO - root - Evaluating...\n",
      "11/23/2023 13:33:28 - INFO - root - Accuracy: 0.990194\n",
      "11/23/2023 13:33:28 - INFO - root - Cor: 1122, Pred TOT: 1680, Gold TOT: 1685\n",
      "11/23/2023 13:33:28 - INFO - root - P: 0.66786, R: 0.66588, F1: 0.66686\n",
      "11/23/2023 13:33:28 - INFO - root - Used time: 15.231171\n",
      "11/23/2023 13:33:41 - INFO - root - Total pred entities: 1680\n",
      "11/23/2023 13:33:41 - INFO - root - Output predictions to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0/ent_pred_test.json..\n"
     ]
    }
   ],
   "source": [
    "test_data = Dataset(test_data)\n",
    "prediction_file = os.path.join(output_dir, test_pred_filename)\n",
    "\n",
    "test_samples, test_ner = convert_dataset_to_samples(test_data, max_span_length, ner_label2id=ner_label2id, context_window=context_window)\n",
    "test_batches = batchify(test_samples, eval_batch_size)\n",
    "evaluate(model, test_batches, test_ner)\n",
    "output_ner_predictions(model, test_batches, test_data, output_file=prediction_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d76cb-3f0c-4822-bca5-d0df0d680434",
   "metadata": {},
   "source": [
    "### Training and evaluating the entity model from scratch\n",
    "\n",
    "#### One more utility function\n",
    "\n",
    "##### `save_model`\n",
    "\n",
    "This function is used to save the trained model to the output drectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9d87811a-ca54-4315-b9e8-27fdfdd914e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, output_dir):\n",
    "    \"\"\"\n",
    "    Save the model to the output directory\n",
    "    \"\"\"\n",
    "    logger.info('Saving model to %s...'%(output_dir))\n",
    "    model_to_save = model.bert_model.module if hasattr(model.bert_model, 'module') else model.bert_model\n",
    "    model_to_save.save_pretrained(output_dir)\n",
    "    model.tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d5b2d-2b2f-4dbb-8107-bf413b9e577e",
   "metadata": {},
   "source": [
    "#### Setting up some variables\n",
    "\n",
    "Now we setup some variables that are needed for the training. And we have some new variables:\n",
    "\n",
    "- `bertadam`: If bertadam, then set correct_bias = False\n",
    "- `num_epoch`: The number of the training epochs. (I set this to 1 because epochs take too long on my machine)\n",
    "- `warmup_proportion`: The ratio of the warmup steps to the total steps\n",
    "- `eval_per_epoch`: How often evaluating the trained model on dev set during training\n",
    "- `train_shuffle`: Whether to train with randomly shuffled data\n",
    "- `print_loss_step`: How often logging the loss value during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a494db9e-9981-4a66-9e37-bdee8df90120",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd() + '/scierc_data/processed_data/json'\n",
    "output_dir = os.getcwd() + '/scierc_models/from-scratch/ent-scib-ctx0/'\n",
    "task = 'scierc'\n",
    "num_ner_labels = len(task_ner_labels[task]) + 1\n",
    "max_span_length = 8\n",
    "context_window = 300\n",
    "eval_batch_size = 32\n",
    "train_batch_size = 2\n",
    "learning_rate = 1e-5\n",
    "task_learning_rate = 5e-4\n",
    "bertadam = True # If bertadam, then set correct_bias = False\n",
    "num_epoch = 10 # number of the training epochs\n",
    "warmup_proportion = 0.1 # the ratio of the warmup steps to the total steps\n",
    "eval_per_epoch = 1 # how often evaluating the trained model on dev set during training\n",
    "train_shuffle = True # whether to train with randomly shuffled data\n",
    "print_loss_step = 100 # how often logging the loss value during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed681b0-39ce-4efb-986c-a2f04fa02150",
   "metadata": {},
   "source": [
    "#### Output directory validation\n",
    "\n",
    "Check if output directory exists and create it if it doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "930c2736-b5a3-4367-9c62-33efd702f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0c433-bceb-45fc-a567-ad2316ba0b70",
   "metadata": {},
   "source": [
    "#### Initialize our entity model\n",
    "\n",
    "The diffrence here is that we don't set the bert_model_dir variable. Instead, we'd like to train the model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b6b73c57-5a85-43bb-a3ca-e7d3ce1484db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/23/2023 17:44:52 - INFO - transformers.tokenization_utils_base - Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/23/2023 17:44:56 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/vocab.txt from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\e3debd8fbdf40874753724814ee0520f612b577b26c8755bca485103b47cd3bc.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
      "11/23/2023 17:44:56 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/added_tokens.json from cache at None\n",
      "11/23/2023 17:44:56 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/special_tokens_map.json from cache at None\n",
      "11/23/2023 17:44:56 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer_config.json from cache at None\n",
      "11/23/2023 17:44:56 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer.json from cache at None\n",
      "11/23/2023 17:44:57 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "11/23/2023 17:44:57 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/23/2023 17:44:57 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/allenai/scibert_scivocab_uncased/pytorch_model.bin from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\54e18c298451d3195ba8359e7a3fa2bc04c70c730c5b6744928278e67940eacb.7587182ea55c40bf7fd0961c1176c31fa22558da2bf20c199874fa5a8ecb4613\n",
      "11/23/2023 17:44:59 - WARNING - transformers.modeling_utils - Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForEntity: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForEntity from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForEntity from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "11/23/2023 17:44:59 - WARNING - transformers.modeling_utils - Some weights of BertForEntity were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['width_embedding.weight', 'ner_classifier.0._linear_layers.0.weight', 'ner_classifier.0._linear_layers.0.bias', 'ner_classifier.0._linear_layers.1.weight', 'ner_classifier.0._linear_layers.1.bias', 'ner_classifier.1.weight', 'ner_classifier.1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "11/23/2023 17:45:00 - INFO - root - Moving to CUDA...\n",
      "11/23/2023 17:45:03 - INFO - root - # GPUs = 1\n"
     ]
    }
   ],
   "source": [
    "model = EntityModel(model='allenai/scibert_scivocab_uncased', use_albert=False, max_span_length=max_span_length, num_ner_labels=num_ner_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a7c6f-6693-4528-9699-b3bdcd292b9c",
   "metadata": {},
   "source": [
    "#### Load training data\n",
    "\n",
    "We load the training data from the JSON file into a Database instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9678bf11-9b92-4487-b96c-405db69e7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a5e57-6943-471a-9d57-ab614c7e7c76",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    "\n",
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28080738-d3a9-49bb-8601-c53b7fd5968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/23/2023 17:45:09 - INFO - root - # Overlap: 0\n",
      "11/23/2023 17:45:09 - INFO - root - Extracted 1861 samples from 350 documents, with 5598 NER labels, 140.335 avg input length, 300 max length\n",
      "11/23/2023 17:45:09 - INFO - root - Max Length: 101, max NER: 13\n",
      " 11%|         | 99/931 [00:37<04:56,  2.80it/s]11/23/2023 17:45:46 - INFO - root - Epoch=0, iter=99, loss=166.25206\n",
      " 21%|       | 199/931 [01:12<03:56,  3.09it/s]11/23/2023 17:46:21 - INFO - root - Epoch=0, iter=199, loss=18.53227\n",
      " 32%|      | 299/931 [01:46<03:20,  3.15it/s]11/23/2023 17:46:55 - INFO - root - Epoch=0, iter=299, loss=14.77129\n",
      " 43%|     | 399/931 [02:22<03:35,  2.47it/s]11/23/2023 17:47:32 - INFO - root - Epoch=0, iter=399, loss=12.42971\n",
      " 54%|    | 499/931 [02:59<02:17,  3.13it/s]11/23/2023 17:48:08 - INFO - root - Epoch=0, iter=499, loss=9.51807\n",
      " 64%|   | 599/931 [03:33<01:40,  3.30it/s]11/23/2023 17:48:43 - INFO - root - Epoch=0, iter=599, loss=8.73267\n",
      " 75%|  | 699/931 [04:09<01:35,  2.44it/s]11/23/2023 17:49:18 - INFO - root - Epoch=0, iter=699, loss=7.48667\n",
      " 86%| | 799/931 [04:44<00:45,  2.92it/s]11/23/2023 17:49:54 - INFO - root - Epoch=0, iter=799, loss=7.55933\n",
      " 97%|| 899/931 [05:19<00:12,  2.47it/s]11/23/2023 17:50:29 - INFO - root - Epoch=0, iter=899, loss=6.79787\n",
      "100%|| 930/931 [05:30<00:00,  2.53it/s]11/23/2023 17:50:40 - INFO - root - Evaluating...\n",
      "11/23/2023 17:50:46 - INFO - root - Accuracy: 0.987452\n",
      "11/23/2023 17:50:46 - INFO - root - Cor: 301, Pred TOT: 411, Gold TOT: 811\n",
      "11/23/2023 17:50:46 - INFO - root - P: 0.73236, R: 0.37115, F1: 0.49264\n",
      "11/23/2023 17:50:46 - INFO - root - Used time: 6.704059\n",
      "11/23/2023 17:50:46 - INFO - root - !!! Best valid (epoch=0): 49.26\n",
      "11/23/2023 17:50:46 - INFO - root - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/...\n",
      "11/23/2023 17:50:46 - INFO - transformers.configuration_utils - Configuration saved in C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/config.json\n",
      "11/23/2023 17:50:47 - INFO - transformers.modeling_utils - Model weights saved in C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/pytorch_model.bin\n",
      "100%|| 931/931 [05:38<00:00,  2.75it/s]\n",
      "  7%|         | 68/931 [00:24<05:22,  2.68it/s]11/23/2023 17:51:12 - INFO - root - Epoch=1, iter=68, loss=6.34958\n",
      " 18%|        | 168/931 [01:00<04:56,  2.58it/s]11/23/2023 17:51:48 - INFO - root - Epoch=1, iter=168, loss=5.94387\n",
      " 29%|       | 268/931 [01:35<03:30,  3.16it/s]11/23/2023 17:52:23 - INFO - root - Epoch=1, iter=268, loss=5.52454\n",
      " 40%|      | 368/931 [02:12<03:32,  2.66it/s]11/23/2023 17:53:00 - INFO - root - Epoch=1, iter=368, loss=5.30385\n",
      " 50%|     | 468/931 [02:46<02:29,  3.09it/s]11/23/2023 17:53:34 - INFO - root - Epoch=1, iter=468, loss=5.07446\n",
      " 61%|    | 568/931 [03:21<02:11,  2.75it/s]11/23/2023 17:54:09 - INFO - root - Epoch=1, iter=568, loss=4.90717\n",
      " 72%|  | 668/931 [03:55<01:21,  3.21it/s]11/23/2023 17:54:43 - INFO - root - Epoch=1, iter=668, loss=5.04569\n",
      " 82%| | 768/931 [04:31<01:00,  2.71it/s]11/23/2023 17:55:19 - INFO - root - Epoch=1, iter=768, loss=4.75154\n",
      " 93%|| 868/931 [05:07<00:23,  2.71it/s]11/23/2023 17:55:55 - INFO - root - Epoch=1, iter=868, loss=4.44570\n",
      "100%|| 930/931 [05:28<00:00,  2.91it/s]11/23/2023 17:56:16 - INFO - root - Evaluating...\n",
      "11/23/2023 17:56:22 - INFO - root - Accuracy: 0.990105\n",
      "11/23/2023 17:56:22 - INFO - root - Cor: 510, Pred TOT: 722, Gold TOT: 811\n",
      "11/23/2023 17:56:22 - INFO - root - P: 0.70637, R: 0.62885, F1: 0.66536\n",
      "11/23/2023 17:56:22 - INFO - root - Used time: 6.689876\n",
      "11/23/2023 17:56:22 - INFO - root - !!! Best valid (epoch=1): 66.54\n",
      "11/23/2023 17:56:22 - INFO - root - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/...\n",
      "11/23/2023 17:56:22 - INFO - transformers.configuration_utils - Configuration saved in C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/config.json\n",
      "11/23/2023 17:56:23 - INFO - transformers.modeling_utils - Model weights saved in C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/pytorch_model.bin\n",
      "100%|| 931/931 [05:35<00:00,  2.77it/s]\n",
      "  4%|         | 37/931 [00:13<06:04,  2.45it/s]11/23/2023 17:56:36 - INFO - root - Epoch=2, iter=37, loss=3.81764\n",
      " 15%|        | 137/931 [00:48<05:12,  2.54it/s]11/23/2023 17:57:12 - INFO - root - Epoch=2, iter=137, loss=3.41791\n",
      " 25%|       | 237/931 [01:23<03:48,  3.04it/s]11/23/2023 17:57:46 - INFO - root - Epoch=2, iter=237, loss=3.01009\n",
      " 36%|      | 337/931 [01:58<03:39,  2.71it/s]11/23/2023 17:58:22 - INFO - root - Epoch=2, iter=337, loss=3.21232\n",
      " 47%|     | 437/931 [02:34<02:44,  2.99it/s]11/23/2023 17:58:58 - INFO - root - Epoch=2, iter=437, loss=3.26889\n",
      " 58%|    | 537/931 [03:11<02:32,  2.58it/s]11/23/2023 17:59:35 - INFO - root - Epoch=2, iter=537, loss=3.70703\n",
      " 68%|   | 637/931 [03:50<02:08,  2.28it/s]11/23/2023 18:00:14 - INFO - root - Epoch=2, iter=637, loss=2.96068\n",
      " 79%|  | 737/931 [04:25<00:52,  3.70it/s]11/23/2023 18:00:49 - INFO - root - Epoch=2, iter=737, loss=2.83677\n",
      " 90%| | 837/931 [05:00<00:38,  2.42it/s]11/23/2023 18:01:24 - INFO - root - Epoch=2, iter=837, loss=3.07535\n",
      "100%|| 930/931 [05:34<00:00,  2.67it/s]11/23/2023 18:01:58 - INFO - root - Evaluating...\n",
      "11/23/2023 18:02:04 - INFO - root - Accuracy: 0.991095\n",
      "11/23/2023 18:02:04 - INFO - root - Cor: 556, Pred TOT: 771, Gold TOT: 811\n",
      "11/23/2023 18:02:04 - INFO - root - P: 0.72114, R: 0.68557, F1: 0.70291\n",
      "11/23/2023 18:02:04 - INFO - root - Used time: 6.593042\n",
      "11/23/2023 18:02:04 - INFO - root - !!! Best valid (epoch=2): 70.29\n",
      "11/23/2023 18:02:04 - INFO - root - Saving model to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/...\n",
      "11/23/2023 18:02:04 - INFO - transformers.configuration_utils - Configuration saved in C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/config.json\n",
      "11/23/2023 18:02:05 - INFO - transformers.modeling_utils - Model weights saved in C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/pytorch_model.bin\n",
      "100%|| 931/931 [05:41<00:00,  2.72it/s]\n",
      "  1%|          | 6/931 [00:01<04:35,  3.35it/s]11/23/2023 18:02:07 - INFO - root - Epoch=3, iter=6, loss=2.77299\n",
      " 11%|        | 106/931 [00:37<05:18,  2.59it/s]11/23/2023 18:02:43 - INFO - root - Epoch=3, iter=106, loss=1.74399\n",
      " 22%|       | 206/931 [01:12<03:48,  3.18it/s]11/23/2023 18:03:17 - INFO - root - Epoch=3, iter=206, loss=2.00869\n",
      " 33%|      | 306/931 [01:47<04:17,  2.43it/s]11/23/2023 18:03:52 - INFO - root - Epoch=3, iter=306, loss=1.94672\n",
      " 44%|     | 406/931 [02:23<03:09,  2.77it/s]11/23/2023 18:04:29 - INFO - root - Epoch=3, iter=406, loss=1.99071\n",
      " 54%|    | 506/931 [02:59<02:35,  2.73it/s]11/23/2023 18:05:05 - INFO - root - Epoch=3, iter=506, loss=2.25570\n",
      " 65%|   | 606/931 [03:36<02:13,  2.44it/s]11/23/2023 18:05:41 - INFO - root - Epoch=3, iter=606, loss=2.42537\n",
      " 76%|  | 706/931 [04:09<01:20,  2.80it/s]11/23/2023 18:06:15 - INFO - root - Epoch=3, iter=706, loss=2.25227\n",
      " 87%| | 806/931 [04:44<00:44,  2.82it/s]11/23/2023 18:06:50 - INFO - root - Epoch=3, iter=806, loss=2.36956\n",
      " 97%|| 906/931 [05:20<00:09,  2.53it/s]11/23/2023 18:07:25 - INFO - root - Epoch=3, iter=906, loss=1.86261\n",
      "100%|| 930/931 [05:28<00:00,  3.09it/s]11/23/2023 18:07:33 - INFO - root - Evaluating...\n",
      "11/23/2023 18:07:40 - INFO - root - Accuracy: 0.990195\n",
      "11/23/2023 18:07:40 - INFO - root - Cor: 560, Pred TOT: 835, Gold TOT: 811\n",
      "11/23/2023 18:07:40 - INFO - root - P: 0.67066, R: 0.69051, F1: 0.68044\n",
      "11/23/2023 18:07:40 - INFO - root - Used time: 6.609572\n",
      "100%|| 931/931 [05:35<00:00,  2.78it/s]\n",
      "  8%|         | 75/931 [00:26<04:32,  3.14it/s]11/23/2023 18:08:07 - INFO - root - Epoch=4, iter=75, loss=1.64457\n",
      " 19%|        | 175/931 [01:00<04:12,  2.99it/s]11/23/2023 18:08:41 - INFO - root - Epoch=4, iter=175, loss=1.14438\n",
      " 30%|       | 275/931 [01:34<03:26,  3.18it/s]11/23/2023 18:09:15 - INFO - root - Epoch=4, iter=275, loss=1.38575\n",
      " 40%|      | 375/931 [02:08<02:30,  3.68it/s]11/23/2023 18:09:49 - INFO - root - Epoch=4, iter=375, loss=1.47189\n",
      " 51%|     | 475/931 [02:44<02:29,  3.05it/s]11/23/2023 18:10:25 - INFO - root - Epoch=4, iter=475, loss=1.33812\n",
      " 62%|   | 575/931 [03:20<02:15,  2.63it/s]11/23/2023 18:11:01 - INFO - root - Epoch=4, iter=575, loss=1.49993\n",
      " 73%|  | 675/931 [03:57<01:26,  2.94it/s]11/23/2023 18:11:38 - INFO - root - Epoch=4, iter=675, loss=1.40344\n",
      " 83%| | 775/931 [04:32<01:01,  2.55it/s]11/23/2023 18:12:13 - INFO - root - Epoch=4, iter=775, loss=1.36383\n",
      " 94%|| 875/931 [05:07<00:18,  3.02it/s]11/23/2023 18:12:48 - INFO - root - Epoch=4, iter=875, loss=1.34067\n",
      "100%|| 930/931 [12:07<00:00,  1.65it/s] 11/23/2023 18:19:48 - INFO - root - Evaluating...\n",
      "11/23/2023 18:19:55 - INFO - root - Accuracy: 0.990533\n",
      "11/23/2023 18:19:55 - INFO - root - Cor: 559, Pred TOT: 807, Gold TOT: 811\n",
      "11/23/2023 18:19:55 - INFO - root - P: 0.69269, R: 0.68927, F1: 0.69098\n",
      "11/23/2023 18:19:55 - INFO - root - Used time: 7.115315\n",
      "100%|| 931/931 [12:14<00:00,  1.27it/s]\n",
      "  5%|         | 44/931 [00:14<04:53,  3.03it/s]11/23/2023 18:20:10 - INFO - root - Epoch=5, iter=44, loss=1.02225\n",
      " 15%|        | 144/931 [00:50<05:28,  2.40it/s]11/23/2023 18:20:46 - INFO - root - Epoch=5, iter=144, loss=0.92360\n",
      " 26%|       | 244/931 [01:25<04:21,  2.62it/s]11/23/2023 18:21:21 - INFO - root - Epoch=5, iter=244, loss=1.06028\n",
      " 37%|      | 344/931 [02:00<03:00,  3.25it/s]11/23/2023 18:21:56 - INFO - root - Epoch=5, iter=344, loss=0.86163\n",
      " 48%|     | 444/931 [02:36<02:56,  2.76it/s]11/23/2023 18:22:32 - INFO - root - Epoch=5, iter=444, loss=0.95002\n",
      " 58%|    | 544/931 [03:11<02:18,  2.79it/s]11/23/2023 18:23:07 - INFO - root - Epoch=5, iter=544, loss=0.97866\n",
      " 69%|   | 644/931 [03:45<01:38,  2.92it/s]11/23/2023 18:23:40 - INFO - root - Epoch=5, iter=644, loss=1.03384\n",
      " 80%|  | 744/931 [04:20<01:05,  2.84it/s]11/23/2023 18:24:16 - INFO - root - Epoch=5, iter=744, loss=0.88952\n",
      " 91%| | 844/931 [04:56<00:32,  2.68it/s]11/23/2023 18:24:52 - INFO - root - Epoch=5, iter=844, loss=0.56506\n",
      "100%|| 930/931 [05:28<00:00,  3.04it/s]11/23/2023 18:25:24 - INFO - root - Evaluating...\n",
      "11/23/2023 18:25:31 - INFO - root - Accuracy: 0.990780\n",
      "11/23/2023 18:25:31 - INFO - root - Cor: 547, Pred TOT: 770, Gold TOT: 811\n",
      "11/23/2023 18:25:31 - INFO - root - P: 0.71039, R: 0.67448, F1: 0.69197\n",
      "11/23/2023 18:25:31 - INFO - root - Used time: 7.087796\n",
      "100%|| 931/931 [05:35<00:00,  2.77it/s]\n",
      "  1%|         | 13/931 [12:26<2:24:29,  9.44s/it] 11/23/2023 18:37:58 - INFO - root - Epoch=6, iter=13, loss=0.88774\n",
      " 12%|        | 113/931 [13:01<04:52,  2.79it/s] 11/23/2023 18:38:33 - INFO - root - Epoch=6, iter=113, loss=0.52290\n",
      " 23%|       | 213/931 [13:35<04:11,  2.86it/s]11/23/2023 18:39:07 - INFO - root - Epoch=6, iter=213, loss=0.81331\n",
      " 34%|      | 313/931 [14:09<03:18,  3.11it/s]11/23/2023 18:39:40 - INFO - root - Epoch=6, iter=313, loss=0.54975\n",
      " 44%|     | 413/931 [14:45<02:51,  3.02it/s]11/23/2023 18:40:16 - INFO - root - Epoch=6, iter=413, loss=0.52083\n",
      " 55%|    | 513/931 [15:20<02:28,  2.81it/s]11/23/2023 18:40:52 - INFO - root - Epoch=6, iter=513, loss=0.64358\n",
      " 66%|   | 613/931 [15:55<02:09,  2.45it/s]11/23/2023 18:41:27 - INFO - root - Epoch=6, iter=613, loss=0.62734\n",
      " 77%|  | 713/931 [16:31<01:17,  2.81it/s]11/23/2023 18:42:02 - INFO - root - Epoch=6, iter=713, loss=0.74340\n",
      " 87%| | 813/931 [17:08<00:42,  2.79it/s]11/23/2023 18:42:40 - INFO - root - Epoch=6, iter=813, loss=0.57247\n",
      " 98%|| 913/931 [17:45<00:07,  2.42it/s]11/23/2023 18:43:16 - INFO - root - Epoch=6, iter=913, loss=0.60532\n",
      "100%|| 930/931 [17:51<00:00,  2.52it/s]11/23/2023 18:43:22 - INFO - root - Evaluating...\n",
      "11/23/2023 18:43:30 - INFO - root - Accuracy: 0.990667\n",
      "11/23/2023 18:43:30 - INFO - root - Cor: 541, Pred TOT: 767, Gold TOT: 811\n",
      "11/23/2023 18:43:30 - INFO - root - P: 0.70535, R: 0.66708, F1: 0.68568\n",
      "11/23/2023 18:43:30 - INFO - root - Used time: 7.404328\n",
      "100%|| 931/931 [17:58<00:00,  1.16s/it]\n",
      "  9%|         | 82/931 [07:59<05:27,  2.59it/s]   11/23/2023 18:51:30 - INFO - root - Epoch=7, iter=82, loss=0.46556\n",
      " 20%|        | 182/931 [08:33<03:43,  3.35it/s]11/23/2023 18:52:03 - INFO - root - Epoch=7, iter=182, loss=0.46126\n",
      " 30%|       | 282/931 [09:08<03:58,  2.72it/s]11/23/2023 18:52:38 - INFO - root - Epoch=7, iter=282, loss=0.43831\n",
      " 41%|      | 382/931 [09:43<03:29,  2.62it/s]11/23/2023 18:53:14 - INFO - root - Epoch=7, iter=382, loss=0.43520\n",
      " 52%|    | 482/931 [10:18<02:30,  2.98it/s]11/23/2023 18:53:49 - INFO - root - Epoch=7, iter=482, loss=0.40244\n",
      " 63%|   | 582/931 [10:53<02:09,  2.69it/s]11/23/2023 18:54:24 - INFO - root - Epoch=7, iter=582, loss=0.42933\n",
      " 73%|  | 682/931 [11:28<01:28,  2.80it/s]11/23/2023 18:54:59 - INFO - root - Epoch=7, iter=682, loss=0.36486\n",
      " 84%| | 782/931 [12:03<00:52,  2.84it/s]11/23/2023 18:55:34 - INFO - root - Epoch=7, iter=782, loss=0.36686\n",
      " 95%|| 882/931 [12:38<00:15,  3.21it/s]11/23/2023 18:56:09 - INFO - root - Epoch=7, iter=882, loss=0.41779\n",
      "100%|| 930/931 [12:55<00:00,  3.10it/s]11/23/2023 18:56:26 - INFO - root - Evaluating...\n",
      "11/23/2023 19:57:47 - INFO - root - Accuracy: 0.990330\n",
      "11/23/2023 19:57:47 - INFO - root - Cor: 582, Pred TOT: 865, Gold TOT: 811\n",
      "11/23/2023 19:57:47 - INFO - root - P: 0.67283, R: 0.71763, F1: 0.69451\n",
      "11/23/2023 19:57:47 - INFO - root - Used time: 3680.620845\n",
      "100%|| 931/931 [1:14:16<00:00,  4.79s/it]  \n",
      "  5%|         | 51/931 [00:17<04:11,  3.50it/s]/it]11/23/2023 19:58:04 - INFO - root - Epoch=8, iter=51, loss=0.29189\n",
      " 16%|        | 151/931 [00:52<04:39,  2.80it/s]11/23/2023 19:58:40 - INFO - root - Epoch=8, iter=151, loss=0.23021\n",
      " 27%|       | 251/931 [01:35<05:41,  1.99it/s]11/23/2023 19:59:23 - INFO - root - Epoch=8, iter=251, loss=0.34123\n",
      " 38%|      | 351/931 [02:21<05:00,  1.93it/s]11/23/2023 20:00:08 - INFO - root - Epoch=8, iter=351, loss=0.28778\n",
      " 48%|     | 451/931 [03:06<03:55,  2.03it/s]11/23/2023 20:00:54 - INFO - root - Epoch=8, iter=451, loss=0.34405\n",
      " 59%|    | 551/931 [03:53<03:13,  1.97it/s]11/23/2023 20:01:40 - INFO - root - Epoch=8, iter=551, loss=0.43574\n",
      " 70%|   | 651/931 [04:38<02:03,  2.27it/s]11/23/2023 20:02:26 - INFO - root - Epoch=8, iter=651, loss=0.24233\n",
      " 81%|  | 751/931 [42:50<01:14,  2.42it/s]    11/23/2023 20:40:38 - INFO - root - Epoch=8, iter=751, loss=0.27100\n",
      " 91%|| 851/931 [2:41:05<00:25,  3.12it/s]     11/23/2023 22:38:53 - INFO - root - Epoch=8, iter=851, loss=0.32656\n",
      "100%|| 930/931 [2:41:32<00:00,  2.63it/s]11/23/2023 22:39:20 - INFO - root - Evaluating...\n",
      "11/23/2023 22:39:26 - INFO - root - Accuracy: 0.990757\n",
      "11/23/2023 22:39:26 - INFO - root - Cor: 570, Pred TOT: 821, Gold TOT: 811\n",
      "11/23/2023 22:39:26 - INFO - root - P: 0.69428, R: 0.70284, F1: 0.69853\n",
      "11/23/2023 22:39:26 - INFO - root - Used time: 6.566416\n",
      "100%|| 931/931 [2:41:39<00:00, 10.42s/it]\n",
      "  2%|         | 20/931 [00:07<05:35,  2.72it/s]/it]11/23/2023 22:39:34 - INFO - root - Epoch=9, iter=20, loss=0.23998\n",
      " 13%|        | 120/931 [00:48<07:01,  1.92it/s]11/23/2023 22:40:15 - INFO - root - Epoch=9, iter=120, loss=0.22956\n",
      " 24%|       | 220/931 [01:33<05:21,  2.21it/s]11/23/2023 22:41:00 - INFO - root - Epoch=9, iter=220, loss=0.19182\n",
      " 34%|      | 320/931 [02:17<04:36,  2.21it/s]11/23/2023 22:41:45 - INFO - root - Epoch=9, iter=320, loss=0.25649\n",
      " 45%|     | 420/931 [03:06<03:56,  2.16it/s]11/23/2023 22:42:33 - INFO - root - Epoch=9, iter=420, loss=0.36685\n",
      " 56%|    | 520/931 [03:51<03:08,  2.18it/s]11/23/2023 22:43:18 - INFO - root - Epoch=9, iter=520, loss=0.25606\n",
      " 67%|   | 620/931 [17:34<3:25:09, 39.58s/it]  11/23/2023 22:57:01 - INFO - root - Epoch=9, iter=620, loss=0.23576\n",
      " 77%|  | 720/931 [1:21:15<01:47,  1.96it/s]     11/24/2023 00:00:42 - INFO - root - Epoch=9, iter=720, loss=0.25698\n",
      " 88%| | 820/931 [2:43:35<00:39,  2.83it/s]     11/24/2023 01:23:02 - INFO - root - Epoch=9, iter=820, loss=0.17098\n",
      " 99%|| 920/931 [2:44:11<00:04,  2.59it/s]11/24/2023 01:23:38 - INFO - root - Epoch=9, iter=920, loss=0.20443\n",
      "100%|| 930/931 [2:44:15<00:00,  2.53it/s]11/24/2023 01:23:42 - INFO - root - Evaluating...\n",
      "11/24/2023 01:23:50 - INFO - root - Accuracy: 0.990600\n",
      "11/24/2023 01:23:50 - INFO - root - Cor: 570, Pred TOT: 830, Gold TOT: 811\n",
      "11/24/2023 01:23:50 - INFO - root - P: 0.68675, R: 0.70284, F1: 0.69470\n",
      "11/24/2023 01:23:50 - INFO - root - Used time: 7.773287\n",
      "100%|| 931/931 [2:44:23<00:00, 10.59s/it]\n",
      "100%|| 10/10 [7:38:40<00:00, 2752.09s/it] \n"
     ]
    }
   ],
   "source": [
    "train_samples, train_ner = convert_dataset_to_samples(train_data, max_span_length, ner_label2id=ner_label2id, context_window=context_window)\n",
    "train_batches = batchify(train_samples, train_batch_size)\n",
    "best_result = 0.0\n",
    "\n",
    "param_optimizer = list(model.bert_model.named_parameters())\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer\n",
    "        if 'bert' in n]},\n",
    "    {'params': [p for n, p in param_optimizer\n",
    "        if 'bert' not in n], 'lr': task_learning_rate}]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=not(bertadam))\n",
    "t_total = len(train_batches) * num_epoch\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, int(t_total*warmup_proportion), t_total)\n",
    "\n",
    "tr_loss = 0\n",
    "tr_examples = 0\n",
    "global_step = 0\n",
    "eval_step = len(train_batches) // eval_per_epoch\n",
    "for _ in tqdm(range(num_epoch), position=0, leave=True):\n",
    "    if train_shuffle:\n",
    "        random.shuffle(train_batches)\n",
    "    for i in tqdm(range(len(train_batches)), position=0, leave=True):\n",
    "        output_dict = model.run_batch(train_batches[i], training=True)\n",
    "        loss = output_dict['ner_loss']\n",
    "        loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        tr_examples += len(train_batches[i])\n",
    "        global_step += 1\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if global_step % print_loss_step == 0:\n",
    "            logger.info('Epoch=%d, iter=%d, loss=%.5f'%(_, i, tr_loss / tr_examples))\n",
    "            tr_loss = 0\n",
    "            tr_examples = 0\n",
    "\n",
    "        if global_step % eval_step == 0:\n",
    "            f1 = evaluate(model, dev_batches, dev_ner)\n",
    "            if f1 > best_result:\n",
    "                best_result = f1\n",
    "                logger.info('!!! Best valid (epoch=%d): %.2f' % (_, f1*100))\n",
    "                save_model(model, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92085027-5535-4edb-9bbb-afdbe0c5e3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
