{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf2820c0-b76d-4e71-8ae0-b99ab7e969c4",
   "metadata": {},
   "source": [
    "## Training and evaluating the entity model\n",
    "\n",
    "In this notebook we will build on our the classes and functions we defined in the entity_setup notebook to run and evalute the entity model proposed in the research paper [A Frustratingly Easy Approach for Entity and Relation Extraction](https://arxiv.org/pdf/2010.12812.pdf).\n",
    "\n",
    "This is a reproduction based on the instructions left by the authors in their [GitHub repo](https://github.com/princeton-nlp/PURE)\n",
    "\n",
    "We will run the entity model on the SchiERC dataset using a pre-trained BERT based nodel.\n",
    "\n",
    "The output of this notebook, a JSON file where keys are document and sentence indices, and values are lists of predicted entities in the format [start, end, label], will be used as the input for the relation model in the notebook `run_relation`\n",
    "\n",
    "\n",
    "Note that we haven't trained our own model yet. We will do that in the next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85774f-b0ca-4322-af3b-2fec51f5439a",
   "metadata": {},
   "source": [
    "### Basic setup\n",
    "\n",
    "First we need to import run work in the notebook `entity_setup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c487caa8-073a-471d-b056-16f54fd534b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run entity_setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb572a-87ab-4544-9999-f39018c88e2f",
   "metadata": {},
   "source": [
    "Then we degine a variable `task_ner_labels`, it's a dictionarry mapping each dataset to its entity types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e2f8486-6867-4fd8-a7ff-7250ec40f58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_ner_labels = {\n",
    "    'ace04': ['FAC', 'WEA', 'LOC', 'VEH', 'GPE', 'ORG', 'PER'],\n",
    "    'ace05': ['FAC', 'WEA', 'LOC', 'VEH', 'GPE', 'ORG', 'PER'],\n",
    "    'scierc': ['Method', 'OtherScientificTerm', 'Task', 'Generic', 'Material', 'Metric'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69a4c3b-f5d2-4ffc-b33b-3e4ec5949870",
   "metadata": {},
   "source": [
    "Then we define some variables:\n",
    "- `data_dir`: The directory in which our input data is stored.\n",
    "- `output_dir`: The directory to which to write  the output of the mnodel.\n",
    "- `task`: The task that the model will be used to make predictions on. \n",
    "- max_span_length: The maximum length of spans to consider. \n",
    "- context_window: The size of the context window to consider around each sentence.\n",
    "- eval_batch_size: The batch size of the samples.\n",
    "- test_pred_filename: The name of the prediction output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80b069ca-18d9-4075-87d3-1d0d13e0f941",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd() + '/scierc_data/processed_data/json'\n",
    "output_dir = os.getcwd() + '/scierc_models/ent-scib-ctx0/'\n",
    "task = 'scierc'\n",
    "max_span_length = 8\n",
    "context_window = 0\n",
    "eval_batch_size = 32\n",
    "test_pred_filename = 'ent_pred_test.json'\n",
    "dev_pred_filename = 'ent_pred_dev.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9d1e65-35ed-4f3d-81fd-60b4b9a93dce",
   "metadata": {},
   "source": [
    "### Running and evaluationg the pre-trained model\n",
    "\n",
    "Now that the setup is out of the way. We can actually run the model and evaluate it with a pre-trained BERT-based model on the SciERC dataset.\n",
    "\n",
    "#### Data File Paths:\n",
    "Since the SciERC dataset is already split into a training, development, and test set. We don't need to perform any split. So let's just load set the paths to the data files dowanloaded with the dataset.\n",
    "\n",
    "The input data format of the entity model is JSONL. Each line of the input file contains one document in the following format.\n",
    "```json\n",
    "{\n",
    "  # document ID (please make sure doc_key can be used to identify a certain document)\n",
    "  \"doc_key\": \"CNN_ENG_20030306_083604.6\",\n",
    "\n",
    "  # sentences in the document, each sentence is a list of tokens\n",
    "  \"sentences\": [\n",
    "    [...],\n",
    "    [...],\n",
    "    [\"tens\", \"of\", \"thousands\", \"of\", \"college\", ...],\n",
    "    ...\n",
    "  ],\n",
    "\n",
    "  # entities (boundaries and entity type) in each sentence\n",
    "  \"ner\": [\n",
    "    [...],\n",
    "    [...],\n",
    "    [[26, 26, \"LOC\"], [14, 14, \"PER\"], ...], #the boundary positions are indexed in the document level\n",
    "    ...,\n",
    "  ],\n",
    "\n",
    "  # relations (two spans and relation type) in each sentence\n",
    "  \"relations\": [\n",
    "    [...],\n",
    "    [...],\n",
    "    [[14, 14, 10, 10, \"ORG-AFF\"], [14, 14, 12, 13, \"ORG-AFF\"], ...],\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cfe19c86-0a03-46ee-85e1-1a794f84919b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = os.path.join(data_dir, 'train.json')\n",
    "dev_data = os.path.join(data_dir, 'dev.json')\n",
    "test_data = os.path.join(data_dir, 'test.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9540da85-feeb-4269-8a58-8aa9a30d80e5",
   "metadata": {},
   "source": [
    "#### Output Directory Check\n",
    "\n",
    "Then, just to be safe, we check if the specified output directory (`output_dir`) exists. If not, we create the directory. This ensures that the output directory is available for storing model checkpoints, predictions, or other outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89f905f0-dcf6-4435-889c-86f2cc21b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d34ad66-e99e-4a89-89cd-cb4d7b31336b",
   "metadata": {},
   "source": [
    "#### NER Label Mapping\n",
    "\n",
    "The `get_labelmap` function is used to get the mapping for the SchiREC task as discussed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8d478bec-612d-4431-9668-145a59a627cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_label2id, ner_id2label = get_labelmap(task_ner_labels[task])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6fbcb1-0b3c-4d84-9f43-166078354d61",
   "metadata": {},
   "source": [
    "#### Development Dataset Processing\n",
    "\n",
    "The development dataset (`dev_data`) is loaded into a `Dataset` object. Then, it is processed using the `convert_dataset_to_samples` function to obtain samples and NER labels. The samples are batchified using the `batchify` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59bf65e9-fad8-4663-950e-25cab705bc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/04/2024 20:42:11 - INFO - root - # Overlap: 0\n",
      "01/04/2024 20:42:11 - INFO - root - Extracted 275 samples from 50 documents, with 811 NER labels, 23.713 avg input length, 68 max length\n",
      "01/04/2024 20:42:11 - INFO - root - Max Length: 68, max NER: 11\n"
     ]
    }
   ],
   "source": [
    "dev_data = Dataset(dev_data)\n",
    "dev_samples, dev_ner = convert_dataset_to_samples(dev_data, max_span_length, ner_label2id=ner_label2id, context_window=context_window)\n",
    "dev_batches = batchify(dev_samples, eval_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d76cb-3f0c-4822-bca5-d0df0d680434",
   "metadata": {},
   "source": [
    "## Training and evaluating the entity model from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9d5b2d-2b2f-4dbb-8107-bf413b9e577e",
   "metadata": {},
   "source": [
    "#### Setting up some variables\n",
    "\n",
    "Now we setup some variables that are needed for the training. And we have some new variables:\n",
    "\n",
    "- `bertadam`: If bertadam, then set correct_bias = False\n",
    "- `num_epoch`: The number of the training epochs. (I set this to 1 because epochs take too long on my machine)\n",
    "- `warmup_proportion`: The ratio of the warmup steps to the total steps\n",
    "- `eval_per_epoch`: How often evaluating the trained model on dev set during training\n",
    "- `train_shuffle`: Whether to train with randomly shuffled data\n",
    "- `print_loss_step`: How often logging the loss value during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a494db9e-9981-4a66-9e37-bdee8df90120",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd() + '/scierc_data/processed_data/json'\n",
    "output_dir = os.getcwd() + '/scierc_models/from-scratch/ent-scib-ctx0/'\n",
    "task = 'scierc'\n",
    "num_ner_labels = len(task_ner_labels[task]) + 1\n",
    "max_span_length = 8\n",
    "context_window = 300\n",
    "eval_batch_size = 32\n",
    "train_batch_size = 2\n",
    "learning_rate = 1e-5\n",
    "task_learning_rate = 5e-4\n",
    "bertadam = True # If bertadam, then set correct_bias = False\n",
    "num_epoch = 10 # number of the training epochs\n",
    "warmup_proportion = 0.1 # the ratio of the warmup steps to the total steps\n",
    "eval_per_epoch = 1 # how often evaluating the trained model on dev set during training\n",
    "train_shuffle = True # whether to train with randomly shuffled data\n",
    "print_loss_step = 100 # how often logging the loss value during training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed681b0-39ce-4efb-986c-a2f04fa02150",
   "metadata": {},
   "source": [
    "#### Output directory validation\n",
    "\n",
    "Check if output directory exists and create it if it doesn't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "930c2736-b5a3-4367-9c62-33efd702f9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee0c433-bceb-45fc-a567-ad2316ba0b70",
   "metadata": {},
   "source": [
    "#### Initialize our entity model\n",
    "\n",
    "The diffrence here is that we don't set the bert_model_dir variable. Instead, we'd like to train the model from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6b73c57-5a85-43bb-a3ca-e7d3ce1484db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/04/2024 20:42:50 - INFO - transformers.tokenization_utils_base - Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "01/04/2024 20:42:54 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/vocab.txt from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\e3debd8fbdf40874753724814ee0520f612b577b26c8755bca485103b47cd3bc.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
      "01/04/2024 20:42:54 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/added_tokens.json from cache at None\n",
      "01/04/2024 20:42:54 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/special_tokens_map.json from cache at None\n",
      "01/04/2024 20:42:54 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer_config.json from cache at None\n",
      "01/04/2024 20:42:54 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer.json from cache at None\n",
      "01/04/2024 20:42:55 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "01/04/2024 20:42:55 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "01/04/2024 20:42:55 - INFO - transformers.modeling_utils - loading weights file https://cdn.huggingface.co/allenai/scibert_scivocab_uncased/pytorch_model.bin from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\54e18c298451d3195ba8359e7a3fa2bc04c70c730c5b6744928278e67940eacb.7587182ea55c40bf7fd0961c1176c31fa22558da2bf20c199874fa5a8ecb4613\n",
      "01/04/2024 20:42:58 - WARNING - transformers.modeling_utils - Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing BertForEntity: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForEntity from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForEntity from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "01/04/2024 20:42:58 - WARNING - transformers.modeling_utils - Some weights of BertForEntity were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['width_embedding.weight', 'ner_classifier.0._linear_layers.0.weight', 'ner_classifier.0._linear_layers.0.bias', 'ner_classifier.0._linear_layers.1.weight', 'ner_classifier.0._linear_layers.1.bias', 'ner_classifier.1.weight', 'ner_classifier.1.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "01/04/2024 20:42:58 - INFO - root - Moving to CUDA...\n",
      "01/04/2024 20:43:06 - INFO - root - # GPUs = 1\n"
     ]
    }
   ],
   "source": [
    "model = EntityModel(model='allenai/scibert_scivocab_uncased', use_albert=False, max_span_length=max_span_length, num_ner_labels=num_ner_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29a7c6f-6693-4528-9699-b3bdcd292b9c",
   "metadata": {},
   "source": [
    "#### Load training data\n",
    "\n",
    "We load the training data from the JSON file into a Database instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9678bf11-9b92-4487-b96c-405db69e7305",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43a5e57-6943-471a-9d57-ab614c7e7c76",
   "metadata": {},
   "source": [
    "#### Training the model\n",
    "\n",
    "Now we can train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28080738-d3a9-49bb-8601-c53b7fd5968a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "01/04/2024 20:43:24 - INFO - root - # Overlap: 0\n",
      "01/04/2024 20:43:24 - INFO - root - Extracted 1861 samples from 350 documents, with 5598 NER labels, 140.335 avg input length, 300 max length\n",
      "01/04/2024 20:43:24 - INFO - root - Max Length: 101, max NER: 13\n",
      "  2%|‚ñè         | 18/931 [00:08<07:18,  2.08it/s]\n",
      "  0%|          | 0/10 [00:08<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-5757a876e08c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0moutput_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ner_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-e4c6a000a609>\u001b[0m in \u001b[0;36mrun_batch\u001b[1;34m(self, samples_list, try_cuda, training)\u001b[0m\n\u001b[0;32m    151\u001b[0m                 \u001b[0mspans_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspans_mask_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m                 \u001b[0mspans_ner_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspans_ner_label_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             )\n\u001b[0;32m    155\u001b[0m             \u001b[0moutput_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ner_loss'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mner_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PUREReprodcution\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-9b4b8cbf6629>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, spans, spans_mask, spans_ner_label, token_type_ids, attention_mask)\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspans\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspans_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspans_ner_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         spans_embedding = self._get_span_embeddings(input_ids, spans, token_type_ids=token_type_ids,\n\u001b[1;32m---> 47\u001b[1;33m                                                     attention_mask=attention_mask)\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[0mffnn_hidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m         \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspans_embedding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-9b4b8cbf6629>\u001b[0m in \u001b[0;36m_get_span_embeddings\u001b[1;34m(self, input_ids, spans, token_type_ids, attention_mask)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \"\"\"\n\u001b[0;32m     30\u001b[0m         \u001b[0mspans_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mspans_start_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatched_index_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspans_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mspans_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspans\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mspans_end_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatched_index_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspans_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PUREReprodcution\\lib\\site-packages\\allennlp\\nn\\util.py\u001b[0m in \u001b[0;36mbatched_index_select\u001b[1;34m(target, indices, flattened_indices)\u001b[0m\n\u001b[0;32m   1156\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflattened_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1157\u001b[0m         \u001b[1;31m# Shape: (batch_size * d_1 * ... * d_n)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1158\u001b[1;33m         \u001b[0mflattened_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflatten_and_batch_shift_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1160\u001b[0m     \u001b[1;31m# Shape: (batch_size * sequence_length, embedding_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PUREReprodcution\\lib\\site-packages\\allennlp\\nn\\util.py\u001b[0m in \u001b[0;36mflatten_and_batch_shift_indices\u001b[1;34m(indices, sequence_length)\u001b[0m\n\u001b[0;32m   1101\u001b[0m     \"\"\"\n\u001b[0;32m   1102\u001b[0m     \u001b[1;31m# Shape: (batch_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1103\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0msequence_length\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1104\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mConfigurationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"All elements in indices should be in range (0, {sequence_length - 1})\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1105\u001b[0m     \u001b[0moffsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_range_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_device_of\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msequence_length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_samples, train_ner = convert_dataset_to_samples(train_data, max_span_length, ner_label2id=ner_label2id, context_window=context_window)\n",
    "train_batches = batchify(train_samples, train_batch_size)\n",
    "best_result = 0.0\n",
    "\n",
    "param_optimizer = list(model.bert_model.named_parameters())\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer\n",
    "        if 'bert' in n]},\n",
    "    {'params': [p for n, p in param_optimizer\n",
    "        if 'bert' not in n], 'lr': task_learning_rate}]\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate, correct_bias=not(bertadam))\n",
    "t_total = len(train_batches) * num_epoch\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, int(t_total*warmup_proportion), t_total)\n",
    "\n",
    "tr_loss = 0\n",
    "tr_examples = 0\n",
    "global_step = 0\n",
    "eval_step = len(train_batches) // eval_per_epoch\n",
    "for _ in tqdm(range(num_epoch), position=0, leave=True):\n",
    "    if train_shuffle:\n",
    "        random.shuffle(train_batches)\n",
    "    for i in tqdm(range(len(train_batches)), position=0, leave=True):\n",
    "        output_dict = model.run_batch(train_batches[i], training=True)\n",
    "        loss = output_dict['ner_loss']\n",
    "        loss.backward()\n",
    "\n",
    "        tr_loss += loss.item()\n",
    "        tr_examples += len(train_batches[i])\n",
    "        global_step += 1\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if global_step % print_loss_step == 0:\n",
    "            logger.info('Epoch=%d, iter=%d, loss=%.5f'%(_, i, tr_loss / tr_examples))\n",
    "            tr_loss = 0\n",
    "            tr_examples = 0\n",
    "\n",
    "        if global_step % eval_step == 0:\n",
    "            f1 = evaluate(model, dev_batches, dev_ner)\n",
    "            if f1 > best_result:\n",
    "                best_result = f1\n",
    "                logger.info('!!! Best valid (epoch=%d): %.2f' % (_, f1*100))\n",
    "                save_model(model, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd7db41-97ca-45a6-a88b-15495b7359ed",
   "metadata": {},
   "source": [
    "#### Trained model evaluation\n",
    "\n",
    "Now let's evaluate our trained model on the test data.\n",
    "\n",
    "Again, The BERT-based entity model (`EntityModel`) is initialized with specific parameters, including the BERT model name (`allenai/scibert_scivocab_uncased`), output directory in which the model is located (`bert_model_dir`), and the number of NER labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "46ed09f3-4004-4390-aa36-4489aada6341",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/24/2023 16:01:04 - INFO - root - Loading BERT model from C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//\n",
      "11/24/2023 16:01:04 - INFO - transformers.tokenization_utils_base - Model name 'C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/24/2023 16:01:04 - INFO - transformers.tokenization_utils_base - Didn't find file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//added_tokens.json. We won't load it.\n",
      "11/24/2023 16:01:04 - INFO - transformers.tokenization_utils_base - Didn't find file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//tokenizer.json. We won't load it.\n",
      "11/24/2023 16:01:04 - INFO - transformers.tokenization_utils_base - loading file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//vocab.txt\n",
      "11/24/2023 16:01:04 - INFO - transformers.tokenization_utils_base - loading file None\n",
      "11/24/2023 16:01:04 - INFO - transformers.tokenization_utils_base - loading file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//special_tokens_map.json\n",
      "11/24/2023 16:01:04 - INFO - transformers.tokenization_utils_base - loading file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//tokenizer_config.json\n",
      "11/24/2023 16:01:04 - INFO - transformers.tokenization_utils_base - loading file None\n",
      "11/24/2023 16:01:04 - INFO - transformers.configuration_utils - loading configuration file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//config.json\n",
      "11/24/2023 16:01:04 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForEntity\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/24/2023 16:01:04 - INFO - transformers.modeling_utils - loading weights file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//pytorch_model.bin\n",
      "11/24/2023 16:01:06 - INFO - transformers.modeling_utils - All model checkpoint weights were used when initializing BertForEntity.\n",
      "\n",
      "11/24/2023 16:01:06 - INFO - transformers.modeling_utils - All the weights of BertForEntity were initialized from the model checkpoint at C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0//.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForEntity for predictions without further training.\n",
      "11/24/2023 16:01:06 - INFO - root - Moving to CUDA...\n",
      "11/24/2023 16:01:06 - INFO - root - # GPUs = 1\n"
     ]
    }
   ],
   "source": [
    "bert_model_dir = output_dir\n",
    "num_ner_labels = len(task_ner_labels[task]) + 1\n",
    "model = EntityModel(model='allenai/scibert_scivocab_uncased', bert_model_dir=bert_model_dir, use_albert=False, max_span_length=max_span_length, num_ner_labels=num_ner_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5a6a34-f0bb-4eeb-9497-76599fcb2df7",
   "metadata": {},
   "source": [
    "#### Test Dataset Processing and Evaluation\n",
    "\n",
    "Just like we did with pre-trained model, the test dataset (`test_data`) is loaded, processed, and batchified similarly to the development dataset. The model is then evaluated on the test data using the `evaluate` function, and the NER predictions are saved to a file using the `output_ner_predictions` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "584a651a-e589-42d4-9f2b-b53fc949eeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/24/2023 16:01:21 - INFO - root - # Overlap: 0\n",
      "11/24/2023 16:01:21 - INFO - root - Extracted 275 samples from 50 documents, with 811 NER labels, 138.455 avg input length, 226 max length\n",
      "11/24/2023 16:01:21 - INFO - root - Max Length: 68, max NER: 11\n",
      "11/24/2023 16:01:21 - INFO - root - Evaluating...\n",
      "11/24/2023 16:01:41 - INFO - root - Accuracy: 0.991297\n",
      "11/24/2023 16:01:41 - INFO - root - Cor: 567, Pred TOT: 786, Gold TOT: 811\n",
      "11/24/2023 16:01:41 - INFO - root - P: 0.72137, R: 0.69914, F1: 0.71008\n",
      "11/24/2023 16:01:41 - INFO - root - Used time: 20.052119\n",
      "11/24/2023 16:02:01 - INFO - root - Total pred entities: 786\n",
      "11/24/2023 16:02:01 - INFO - root - Output predictions to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/from-scratch/ent-scib-ctx0/ent_pred_dev.json..\n"
     ]
    }
   ],
   "source": [
    "test_data = Dataset(test_data)\n",
    "prediction_file = os.path.join(output_dir, test_pred_filename)\n",
    "\n",
    "test_data = Dataset(dev_data)\n",
    "prediction_file = os.path.join(output_dir, dev_pred_filename)\n",
    "    \n",
    "test_samples, test_ner = convert_dataset_to_samples(test_data, max_span_length, ner_label2id=ner_label2id, context_window=context_window)\n",
    "test_batches = batchify(test_samples, eval_batch_size)\n",
    "evaluate(model, test_batches, test_ner)\n",
    "output_ner_predictions(model, test_batches, test_data, output_file=prediction_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbb6455-a657-4f6d-9077-75d2972e104d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Results\n",
    "\n",
    "**Accuracy**: 99.09%\n",
    "\n",
    "**Precision**: 70.73%\\\n",
    "**Recall**: 67.54%\\\n",
    "**F1 Score**: 69.10%\n",
    "\n",
    "**Compared to the pre-trained model:**\n",
    "\n",
    "- Both models exhibit high accuracy, indicating strong overall performance.\n",
    "- Our model has a slightly higher accuracy **(0.09% higher)** compared to the pre-trained model.\n",
    "- Our model has higher precision **(70.73%)** compared to the pre-trained model **(66.79%)**, suggesting that when it predicts an entity, it is more likely to be correct.\n",
    "- Our model also has higher recall **(67.54%)** compared to the pre-trained model **(66.59%)**, indicating that it captures a larger proportion of the actual entities present in the data.\n",
    "- The F1 score is also higher for our model **(69.10%)** compared to the pre-trained model **(66.69%)**.\n",
    "- Both models have similar numbers of correct predictions, but our model has slightly more **(1138 compared to 1122)**.\n",
    "\n",
    "**Implications:**\n",
    "\n",
    "- Our model performs slightly better across all metrics, with improvements in precision, recall, and the F1 score.\n",
    "- The higher precision suggests that when our model makes a prediction, it is more likely to be correct, which can be crucial in applications where false positives are costly.\n",
    "- The higher recall of our model indicates that it is better at capturing a larger proportion of the actual entities, which is important when the goal is to identify as many relevant entities as possible.\n",
    "\n",
    "In summary, while both models are high-performing, our's appears to have a slight edge in terms of precision, recall, and the overall F1 score. The choice between the two models may depend on the specific requirements and priorities of the NER task at hand, such as the importance of precision vs. recall in the given application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1d1fa3-4c3f-46fe-bfd3-32aeb5e0c2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
