{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7145ef96-18f7-4c97-ba26-a3d20df5fcda",
   "metadata": {},
   "source": [
    "# Running the relation model\n",
    "In this notebook we will run and evalute the relation model proposed in the research paper [A Frustratingly Easy Approach for Entity and Relation Extraction](https://arxiv.org/pdf/2010.12812.pdf).\n",
    "\n",
    "This is a reproduction based on the instructions left by the authors in their [GitHub repo](https://github.com/princeton-nlp/PURE)\n",
    "\n",
    "**Environment information**\n",
    "\n",
    "- Windows 11\n",
    "- Python 3.6.13\n",
    "- pip 21.2.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20c0e8b-76a1-468e-b48a-9b473be65ca7",
   "metadata": {},
   "source": [
    "## Basic setup\n",
    "Firstly, run the notebook relation_setup to load needed classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c781d0-3f3d-48b0-aaed-db60beba4cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odaim\\anaconda3\\envs\\PUREReprodcution\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%run relation_setup.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38c0c6c-6e50-4233-b220-8308fad884c8",
   "metadata": {},
   "source": [
    "Next, we setup our notebook by importing needed libraries and modules.\n",
    "\n",
    "And we initialize a logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35c9995f-df21-4e6c-bed8-d759200ef493",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\odaim\\anaconda3\\envs\\PUREReprodcution\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertPreTrainedModel\n",
    "from transformers import AlbertModel, AlbertPreTrainedModel\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers.file_utils import PYTORCH_PRETRAINED_BERT_CACHE, WEIGHTS_NAME, CONFIG_NAME\n",
    "\n",
    "import os\n",
    "import time\n",
    "import torch\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s - %(levelname)s - %(name)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %H:%M:%S',\n",
    "                    level=logging.INFO)\n",
    "logger = logging.getLogger('run_relation')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad931ef-cf57-47c7-9cfd-0ab3db015747",
   "metadata": {},
   "source": [
    "## Running and evaluationg the pre-trained relation model\n",
    "\n",
    "Now that the setup is out of the way. We can actually run the model and evaluate it with a pre-trained BERT-based model on the SciERC dataset.\n",
    "\n",
    "Let's perform the training, evaluating, and predicting of the relation model using the SciBERT model.\n",
    "\n",
    "Configuration Parameters:\n",
    "- model_name: The name the pre-trained SciBERT model.\n",
    "- add_new_tokens: A boolean indicating whether to add new task-specific tokens to the tokenizer.\n",
    "- no_cuda: A boolean indicating whether to use CPU instead of GPU.\n",
    "- do_train, do_eval, eval_test: Boolean flags to control whether to perform training, evaluation, and evaluation on the test set.\n",
    "- do_lower_case: A boolean indicating whether to convert text to lowercase during tokenization.\n",
    "- entity_output_dir: The directory containing output from the entity recognition model.\n",
    "- entity_predictions_dev, entity_predictions_test: The filenames for entity predictions on the development and test sets.\n",
    "- eval_with_gold: A boolean indicating whether to use gold standard entities during evaluation.\n",
    "- context_window: The size of the context window around each sentence.\n",
    "- max_seq_length: The maximum sequence length for tokenized input.\n",
    "- seed: The random seed for reproducibility.\n",
    "- output_dir: The directory to save the trained model and evaluation logs.\n",
    "- negative_label: The label for negative relations.\n",
    "- task: The specific relation extraction task (assumed to be \"scierc\").\n",
    "- train_mode: The training mode, assumed to be \"random_sorted\".\n",
    "- train_batch_size, eval_batch_size: Batch sizes for training and evaluation.\n",
    "- num_train_epochs: The number of training epochs.\n",
    "- train_file: The file containing training data.\n",
    "- eval_per_epoch: The frequency of evaluation per epoch.\n",
    "- learning_rate: The learning rate for training.\n",
    "- prediction_file: The filename for saving predictions.\n",
    "- BertLayerNorm: The LayerNorm class to be used (assumed to be from torch.nn).\n",
    "- CLS, SEP: Special tokens for [CLS] (classification) and [SEP] (separator).\n",
    "- RelationModel: The model class for relation extraction.\n",
    "- device: The computing device (CPU or GPU).\n",
    "- n_gpu: The number of available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8b14b727-39e4-4328-a96f-6a10b50e65ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'allenai/scibert_scivocab_uncased'\n",
    "add_new_tokens = False\n",
    "no_cuda = False\n",
    "do_train = False\n",
    "do_eval = True\n",
    "eval_test = True\n",
    "do_lower_case = True\n",
    "entity_output_dir = os.getcwd() + '/scierc_models/ent-scib-ctx0/'\n",
    "entity_predictions_dev = 'ent_pred_dev.json'\n",
    "eval_with_gold = True\n",
    "context_window = 0\n",
    "max_seq_length = 128\n",
    "entity_predictions_test = 'ent_pred_test.json'\n",
    "seed = 0\n",
    "output_dir = os.getcwd() + '/scierc_models/rel_approx-scib-ctx0/'\n",
    "negative_label = 'no_relation'\n",
    "task = 'scierc'\n",
    "train_mode = 'random_sorted'\n",
    "train_batch_size = 32\n",
    "eval_batch_size = 8\n",
    "num_train_epochs = 3.0\n",
    "train_file = None\n",
    "eval_per_epoch = 10\n",
    "learning_rate = None\n",
    "prediction_file = 'predictions.json'\n",
    "BertLayerNorm = torch.nn.LayerNorm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213d198d-b4de-49a8-bc2e-ccdaea283483",
   "metadata": {},
   "source": [
    "#### Special Tokens and Model Initialization:\n",
    "\n",
    "- `CLS` and `SEP` are special tokens used in BERT-like models, where [CLS] denotes the start of a sequence, and [SEP] separates segments or sentences.\n",
    "- `RelationModel` is set to the BertForRelation model, since that's the model we will useCLS = \"[CLS]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "963d6af7-d127-4478-9a90-a1efb83c0a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS = \"[CLS]\"\n",
    "SEP = \"[SEP]\"\n",
    "\n",
    "RelationModel = BertForRelation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7d25e0-90d5-4655-afc6-bbab5ba70fab",
   "metadata": {},
   "source": [
    "#### Device and GPU Configuration:\n",
    "\n",
    "- `device`: It checks if a GPU is available. If available, it uses GPU; otherwise, it falls back to CPU.\n",
    "- `n_gpu`: It counts the number of available GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e820beaf-9bfd-407d-933e-4fa2a400272f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() and not no_cuda else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f9fe93-f05f-4b92-b0c1-3bde4ed340b3",
   "metadata": {},
   "source": [
    "#### Data Preparation:\n",
    "\n",
    "The input data format of the relation model is almost the same as that of the entity model, except that there is one more filed .\"predicted_ner\" to store the predictions of the entity model.\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"doc_key\": \"CNN_ENG_20030306_083604.6\",\n",
    "  \"sentences\": [...],\n",
    "  \"ner\": [...],\n",
    "  \"relations\": [...],\n",
    "  \"predicted_ner\": [\n",
    "    [...],\n",
    "    [...],\n",
    "    [[26, 26, \"LOC\"], [14, 15, \"PER\"], ...],\n",
    "    ...\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\n",
    "Let's prepare the data for the training, development (dev), and test sets using the generate_relation_data function.\n",
    "- `train_dataset`, `eval_dataset`, and `test_dataset` hold the generated datasets.\n",
    "- `train_examples`, `eval_examples`, and `test_examples` contain examples from the respective datasets.\n",
    "- `train_nrel`, `eval_nrel`, and `test_nrel` store the number of relations in the corresponding sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c87d6bac-ffdc-448b-8f58-f03929827dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:29 - INFO - run_relation - Generate relation data from C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/ent-scib-ctx0/ent_pred_test.json\n",
      "11/21/2023 15:53:30 - INFO - run_relation - #samples: 5062, max #sent.samples: 156\n"
     ]
    }
   ],
   "source": [
    "# train set\n",
    "if do_train:\n",
    "    train_dataset, train_examples, train_nrel = generate_relation_data(train_file, use_gold=True, context_window=context_window)\n",
    "# dev set\n",
    "if (do_eval and do_train) or (do_eval and not(eval_test)):\n",
    "    eval_dataset, eval_examples, eval_nrel = generate_relation_data(os.path.join(entity_output_dir, entity_predictions_dev), use_gold=eval_with_gold, context_window=context_window)\n",
    "# test set\n",
    "if eval_test:\n",
    "    test_dataset, test_examples, test_nrel = generate_relation_data(os.path.join(entity_output_dir, entity_predictions_test), use_gold=eval_with_gold, context_window=context_window)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9b9e86-1ab6-401e-884c-015c1b52c4e4",
   "metadata": {},
   "source": [
    "#### Random Seed Setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "146f7485-4459-4c99-8624-ea7dd497e5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "setseed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dacfb4-a261-4aa4-a5a5-12c55df05ec1",
   "metadata": {},
   "source": [
    "#### Directory and Logging Setup:\n",
    "\n",
    "- Ensuring that at least one of `do_train` or `do_eval` is set to True.\n",
    "- We also create the output directory if it doesn't exist and set up logging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "88ccfb8f-e50c-4399-961d-341f7a4229eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not do_train and not do_eval:\n",
    "    raise ValueError(\"At least one of `do_train` or `do_eval` must be True.\")\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if do_train:\n",
    "    logger.addHandler(logging.FileHandler(os.path.join(output_dir, \"train.log\"), 'w'))\n",
    "else:\n",
    "    logger.addHandler(logging.FileHandler(os.path.join(output_dir, \"eval.log\"), 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28721e51-b916-46cf-b317-72d3003746de",
   "metadata": {},
   "source": [
    "#### Label List and Mappings:\n",
    "\n",
    "- Loading/creating a list of relation labels (`label_list`) and saving it to a file.\n",
    "- Again, we create the mappings (`label2id` and `id2label`) and calculate the number of labels (`num_labels`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fadd1860-e68a-4518-87bf-06c26b8774c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get label_list\n",
    "if os.path.exists(os.path.join(output_dir, 'label_list.json')):\n",
    "    with open(os.path.join(output_dir, 'label_list.json'), 'r') as f:\n",
    "        label_list = json.load(f)\n",
    "else:\n",
    "    label_list = [negative_label] + task_rel_labels[task]\n",
    "    with open(os.path.join(output_dir, 'label_list.json'), 'w') as f:\n",
    "        json.dump(label_list, f)\n",
    "label2id = {label: i for i, label in enumerate(label_list)}\n",
    "id2label = {i: label for i, label in enumerate(label_list)}\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2051a95a-905e-4c9f-86c5-e71572709c2e",
   "metadata": {},
   "source": [
    "#### Tokenizer and Special Tokens:\n",
    "\n",
    "- It initializes the tokenizer using the specified pre-trained model (`model_name`).\n",
    "- If `add_new_tokens` is set to True, it adds task-specific marker tokens using the `add_marker_tokens` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f898f08f-3d56-4cc2-8092-79c478be88bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:36 - INFO - transformers.configuration_utils - loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/config.json from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\199e28e62d2210c23d63625bd9eecc20cf72a156b29e2a540d4933af4f50bda1.4b6b9f5d813f7395e7ea533039e02deb1723d8fd9d8ba655391a01a69ad6223d\n",
      "11/21/2023 15:53:36 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/21/2023 15:53:36 - INFO - transformers.tokenization_utils_base - Model name 'allenai/scibert_scivocab_uncased' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, TurkuNLP/bert-base-finnish-cased-v1, TurkuNLP/bert-base-finnish-uncased-v1, wietsedv/bert-base-dutch-cased). Assuming 'allenai/scibert_scivocab_uncased' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/vocab.txt from cache at C:\\Users\\odaim/.cache\\torch\\transformers\\e3debd8fbdf40874753724814ee0520f612b577b26c8755bca485103b47cd3bc.60287becc5ab96d85a4bf377eb90feaf3b9c80d3b23e84311dccd3588f56d4fb\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/added_tokens.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/special_tokens_map.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer_config.json from cache at None\n",
      "11/21/2023 15:53:39 - INFO - transformers.tokenization_utils_base - loading file https://s3.amazonaws.com/models.huggingface.co/bert/allenai/scibert_scivocab_uncased/tokenizer.json from cache at None\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=do_lower_case)\n",
    "if add_new_tokens:\n",
    "    add_marker_tokens(tokenizer, task_ner_labels[task])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda9cbe2-81c3-4020-93a6-a53d166eb015",
   "metadata": {},
   "source": [
    "#### Special Tokens Saving/Loading:\n",
    "\n",
    "It loads or initializes a dictionary for special tokens (`special_tokens`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6554cd01-60d3-4ab8-a9c4-0bee2501761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(output_dir, 'special_tokens.json')):\n",
    "    with open(os.path.join(output_dir, 'special_tokens.json'), 'r') as f:\n",
    "        special_tokens = json.load(f)\n",
    "else:\n",
    "    special_tokens = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fc7210-7735-48c8-aca5-81fc2d073e06",
   "metadata": {},
   "source": [
    "#### Evaluation Data Preparation:\n",
    "\n",
    "- It converts evaluation examples (eval_examples) to features using the convert_examples_to_features function.\n",
    "- It logs information about the evaluation dataset, such as the number of examples and the batch size.\n",
    "- It creates PyTorch tensors for input features (all_input_ids, all_input_mask, etc.).\n",
    "- It constructs a PyTorch TensorDataset and a corresponding DataLoader for the evaluation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5dc1cc5d-b61a-4052-b9d7-309d1d9b4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "if do_eval and (do_train or not(eval_test)):\n",
    "    eval_features = convert_examples_to_features(\n",
    "        eval_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "    logger.info(\"***** Dev *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(eval_examples))\n",
    "    logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "    all_sub_idx = torch.tensor([f.sub_idx for f in eval_features], dtype=torch.long)\n",
    "    all_obj_idx = torch.tensor([f.obj_idx for f in eval_features], dtype=torch.long)\n",
    "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "    eval_dataloader = DataLoader(eval_data, batch_size=eval_batch_size)\n",
    "    eval_label_ids = all_label_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5dd61b-c99f-4372-96dd-717f43891147",
   "metadata": {},
   "source": [
    "#### Save Special Tokens\n",
    "\n",
    "It saves the `special_tokens` dictionary to a JSON file named 'special_tokens.json' in the output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9000703a-a771-4def-92be-c61540ad6e13",
   "metadata": {},
   "source": [
    "with open(os.path.join(output_dir, 'special_tokens.json'), 'w') as f:\n",
    "    json.dump(special_tokens, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659fa904-1fe5-4b16-bafd-0d44625a1092",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Model Evaluation\n",
    "\n",
    "- It logs the `special_tokens` dictionary.\n",
    "- If `eval_test` is True, it uses the test dataset (`test_dataset`, `test_examples`) for evaluation; otherwise, it uses the previously loaded dev dataset.\n",
    "- It converts the evaluation examples to features and constructs a PyTorch TensorDataset and a corresponding DataLoader for the evaluation set.\n",
    "- It loads the pre-trained relation extraction model (RelationModel) from the output directory.\n",
    "- It evaluates the model on the evaluation set and logs the results.\n",
    "- It prints the predictions to a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e80d3b70-f753-45a1-b06d-ba7404ddc275",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/21/2023 15:53:45 - INFO - run_relation - {'SUBJ_START': '[unused1]', 'SUBJ_END': '[unused2]', 'OBJ_START': '[unused3]', 'OBJ_END': '[unused4]', 'SUBJ=Generic': '[unused5]', 'OBJ=OtherScientificTerm': '[unused6]', 'SUBJ_START=Generic': '[unused7]', 'SUBJ_END=Generic': '[unused8]', 'OBJ_START=OtherScientificTerm': '[unused9]', 'OBJ_END=OtherScientificTerm': '[unused10]', 'OBJ=Material': '[unused11]', 'OBJ_START=Material': '[unused12]', 'OBJ_END=Material': '[unused13]', 'SUBJ=OtherScientificTerm': '[unused14]', 'OBJ=Generic': '[unused15]', 'SUBJ_START=OtherScientificTerm': '[unused16]', 'SUBJ_END=OtherScientificTerm': '[unused17]', 'OBJ_START=Generic': '[unused18]', 'OBJ_END=Generic': '[unused19]', 'SUBJ=Material': '[unused20]', 'SUBJ_START=Material': '[unused21]', 'SUBJ_END=Material': '[unused22]', 'OBJ=Task': '[unused23]', 'OBJ_START=Task': '[unused24]', 'OBJ_END=Task': '[unused25]', 'SUBJ=Task': '[unused26]', 'SUBJ_START=Task': '[unused27]', 'SUBJ_END=Task': '[unused28]', 'OBJ=Method': '[unused29]', 'OBJ_START=Method': '[unused30]', 'OBJ_END=Method': '[unused31]', 'SUBJ=Method': '[unused32]', 'SUBJ_START=Method': '[unused33]', 'SUBJ_END=Method': '[unused34]', 'OBJ=Metric': '[unused35]', 'OBJ_START=Metric': '[unused36]', 'OBJ_END=Metric': '[unused37]', 'SUBJ=Metric': '[unused38]', 'SUBJ_START=Metric': '[unused39]', 'SUBJ_END=Metric': '[unused40]'}\n",
      "11/21/2023 15:53:45 - INFO - run_relation - Writing example 0 of 5062\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(2,3)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of [unused9] proper nouns [unused28] [unused10] in japanese text has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 10 1193 24748 29 11 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 4\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(5,6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in [unused12] japanese text [unused13] has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 13 9155 3267 14 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 8\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(19,20)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in japanese text has been studied as a part of the more general problem of [unused24] morphological analysis [unused25] in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 25 6893 669 26 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 22\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(0,3)-(22,24)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused27] recognition of proper nouns [unused28] in japanese text has been studied as a part of the more general problem of morphological analysis in [unused24] japanese text processing [unused25] - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 28 3512 131 1193 24748 29 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 25 9155 3267 2307 26 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 25\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(2,3)-(0,3)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused24] recognition of [unused16] proper nouns [unused17] [unused25] in japanese text has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 25 3512 131 17 1193 24748 18 26 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: no_relation (id = 0)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 4, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(2,3)-(5,6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] recognition of [unused16] proper nouns [unused17] in [unused12] japanese text [unused13] has been studied as a part of the more general problem of morphological analysis in japanese text processing - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 3512 131 17 1193 24748 18 121 13 9155 3267 14 434 528 2580 188 106 1188 131 111 475 1196 1167 131 6893 669 121 9155 3267 2307 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 3, 8\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@0::(19,20)-(22,24)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] recognition of proper nouns in japanese text has been studied as a part of the more general problem of [unused27] morphological analysis [unused28] in [unused24] japanese text processing [unused25] - lr ##b - - ls ##b - 1 - rs ##b - - ls ##b - 2 - rs ##b - - rr ##b - . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 3512 131 1193 24748 121 9155 3267 434 528 2580 188 106 1188 131 111 475 1196 1167 131 28 6893 669 29 121 25 9155 3267 2307 26 579 8295 30125 579 579 6208 30125 579 158 579 3102 30125 579 579 6208 30125 579 170 579 3102 30125 579 579 5058 30125 579 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 20, 25\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@1::(43,45)-(34,34)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused18] it [unused19] has also been studied in the framework of [unused27] japanese information extraction [unused28] - lr ##b - - ls ##b - 3 - rs ##b - - rr ##b - in recent years . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 19 256 20 434 469 528 2580 121 111 2641 131 28 9155 776 4220 29 579 8295 30125 579 579 6208 30125 579 239 579 3102 30125 579 579 5058 30125 579 121 2151 1320 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 12, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(56,56)-(59,64)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our [unused7] approach [unused8] to the [unused24] multi - lingu ##al evaluation task - lr ##b - met - rr ##b - [unused25] for japanese text is to consider the given task as a morphological analysis problem in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 8 1139 9 147 111 25 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 26 168 9155 3267 165 147 1129 111 906 2188 188 106 6893 669 1167 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 2, 7\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(59,64)-(66,67)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the [unused27] multi - lingu ##al evaluation task - lr ##b - met - rr ##b - [unused28] for [unused12] japanese text [unused13] is to consider the given task as a morphological analysis problem in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 28 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 29 168 13 9155 3267 14 165 147 1129 111 906 2188 188 106 6893 669 1167 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 5, 23\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(76,78)-(73,73)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the multi - lingu ##al evaluation task - lr ##b - met - rr ##b - for japanese text is to consider the given [unused18] task [unused19] as a [unused27] morphological analysis problem [unused28] in japanese . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 168 9155 3267 165 147 1129 111 906 19 2188 20 188 106 28 6893 669 1167 29 121 9155 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 33, 28\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@2::(80,80)-(76,78)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our approach to the multi - lingu ##al evaluation task - lr ##b - met - rr ##b - for japanese text is to consider the given task as a [unused24] morphological analysis problem [unused25] in [unused21] japanese [unused22] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 1139 147 111 869 579 8589 120 2166 2188 579 8295 30125 579 374 579 5058 30125 579 168 9155 3267 165 147 1129 111 906 2188 188 106 25 6893 669 1167 26 121 22 9155 23 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 37, 31\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(83,84)-(93,103)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our [unused33] morphological analyzer [unused34] has done all the necessary work for the [unused24] recognition and classification of proper names , numerical and temporal expressions [unused25] , i . e . named entity - lr ##b - ne - rr ##b - items in the japanese text . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 34 6893 12951 35 434 2992 355 111 2538 697 168 111 25 3512 137 2998 131 1193 8541 422 4058 137 3930 6370 26 422 259 205 139 205 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 121 111 9155 3267 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 2, 14\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(106,111)-(97,103)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our morphological analyzer has done all the necessary work for the recognition and classification of [unused9] proper names , numerical and temporal expressions [unused10] , i . e . [unused16] named entity - lr ##b - ne - rr ##b - items [unused17] in the japanese text . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 6893 12951 434 2992 355 111 2538 697 168 111 3512 137 2998 131 10 1193 8541 422 4058 137 3930 6370 11 422 259 205 139 205 17 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 18 121 111 9155 3267 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: HYPONYM-OF (id = 6)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 30, 16\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@3::(106,111)-(114,115)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] our morphological analyzer has done all the necessary work for the recognition and classification of proper names , numerical and temporal expressions , i . e . [unused16] named entity - lr ##b - ne - rr ##b - items [unused17] in the [unused12] japanese text [unused13] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 580 6893 12951 434 2992 355 111 2538 697 168 111 3512 137 2998 131 1193 8541 422 4058 137 3930 6370 422 259 205 139 205 17 8832 8494 579 8295 30125 579 287 579 5058 30125 579 3945 18 121 111 13 9155 3267 14 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 28, 44\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(125,125)-(127,128)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused33] amorph [unused34] recognizes [unused9] ne items [unused10] in two stages : dictionary lookup and rule application . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 34 15291 35 20269 10 287 3945 11 121 502 4303 862 13050 22474 137 3346 1836 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 1, 5\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(133,134)-(125,125)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused30] amorph [unused31] recognizes ne items in two stages : [unused33] dictionary lookup [unused34] and rule application . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 31 15291 32 20269 287 3945 121 502 4303 862 34 13050 22474 35 137 3346 1836 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 11, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(133,134)-(136,137)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] amorph recognizes ne items in two stages : [unused33] dictionary lookup [unused34] and [unused30] rule application [unused31] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 15291 20269 287 3945 121 502 4303 862 34 13050 22474 35 137 31 3346 1836 32 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: CONJUNCTION (id = 4)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 9, 14\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@5::(136,137)-(125,125)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] [unused30] amorph [unused31] recognizes ne items in two stages : dictionary lookup and [unused33] rule application [unused34] . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 31 15291 32 20269 287 3945 121 502 4303 862 13050 22474 137 34 3346 1836 35 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: PART-OF (id = 1)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 14, 1\n",
      "11/21/2023 15:53:45 - INFO - run_relation - *** Example ***\n",
      "11/21/2023 15:53:45 - INFO - run_relation - guid: X96-1059@6::(146,146)-(141,141)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - tokens: [CLS] first , [unused18] it [unused19] uses several kinds of [unused16] diction ##aries [unused17] to segment and tag japanese character strings . [SEP]\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_ids: 102 705 422 19 256 20 3294 1323 7337 131 17 11618 2881 18 147 3197 137 5374 9155 954 13408 205 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "11/21/2023 15:53:45 - INFO - run_relation - label: USED-FOR (id = 2)\n",
      "11/21/2023 15:53:45 - INFO - run_relation - sub_idx, obj_idx: 10, 3\n",
      "11/21/2023 15:53:54 - INFO - run_relation - Average #tokens: 44.54\n",
      "11/21/2023 15:53:54 - INFO - run_relation - Max #tokens: 131\n",
      "11/21/2023 15:53:54 - INFO - run_relation - 4906 (96.92 %) examples can fit max_seq_length = 128\n",
      "11/21/2023 15:53:54 - INFO - run_relation - {'SUBJ_START': '[unused1]', 'SUBJ_END': '[unused2]', 'OBJ_START': '[unused3]', 'OBJ_END': '[unused4]', 'SUBJ=Generic': '[unused5]', 'OBJ=OtherScientificTerm': '[unused6]', 'SUBJ_START=Generic': '[unused7]', 'SUBJ_END=Generic': '[unused8]', 'OBJ_START=OtherScientificTerm': '[unused9]', 'OBJ_END=OtherScientificTerm': '[unused10]', 'OBJ=Material': '[unused11]', 'OBJ_START=Material': '[unused12]', 'OBJ_END=Material': '[unused13]', 'SUBJ=OtherScientificTerm': '[unused14]', 'OBJ=Generic': '[unused15]', 'SUBJ_START=OtherScientificTerm': '[unused16]', 'SUBJ_END=OtherScientificTerm': '[unused17]', 'OBJ_START=Generic': '[unused18]', 'OBJ_END=Generic': '[unused19]', 'SUBJ=Material': '[unused20]', 'SUBJ_START=Material': '[unused21]', 'SUBJ_END=Material': '[unused22]', 'OBJ=Task': '[unused23]', 'OBJ_START=Task': '[unused24]', 'OBJ_END=Task': '[unused25]', 'SUBJ=Task': '[unused26]', 'SUBJ_START=Task': '[unused27]', 'SUBJ_END=Task': '[unused28]', 'OBJ=Method': '[unused29]', 'OBJ_START=Method': '[unused30]', 'OBJ_END=Method': '[unused31]', 'SUBJ=Method': '[unused32]', 'SUBJ_START=Method': '[unused33]', 'SUBJ_END=Method': '[unused34]', 'OBJ=Metric': '[unused35]', 'OBJ_START=Metric': '[unused36]', 'OBJ_END=Metric': '[unused37]', 'SUBJ=Metric': '[unused38]', 'SUBJ_START=Metric': '[unused39]', 'SUBJ_END=Metric': '[unused40]'}\n",
      "11/21/2023 15:53:54 - INFO - run_relation - ***** Test *****\n",
      "11/21/2023 15:53:54 - INFO - run_relation -   Num examples = 5062\n",
      "11/21/2023 15:53:54 - INFO - run_relation -   Batch size = 8\n",
      "11/21/2023 15:53:54 - INFO - transformers.configuration_utils - loading configuration file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/config.json\n",
      "11/21/2023 15:53:54 - INFO - transformers.configuration_utils - Model config BertConfig {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "11/21/2023 15:53:54 - INFO - transformers.modeling_utils - loading weights file C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/pytorch_model.bin\n",
      "11/21/2023 15:53:57 - INFO - transformers.modeling_utils - All model checkpoint weights were used when initializing BertForRelation.\n",
      "\n",
      "11/21/2023 15:53:57 - INFO - transformers.modeling_utils - All the weights of BertForRelation were initialized from the model checkpoint at C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use BertForRelation for predictions without further training.\n",
      "11/21/2023 15:56:58 - INFO - run_relation - ***** Eval results *****\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   accuracy = 0.8557882259976294\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   eval_loss = 0.4450051788046462\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_correct = 651\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_gold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_pred = 1124\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   precision = 0.5791814946619217\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_ngold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation - *** Evaluation Results ***\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   accuracy = 0.8557882259976294\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   eval_loss = 0.4450051788046462\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_correct = 651\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_gold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   n_pred = 1124\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   precision = 0.5791814946619217\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_f1 = 0.6205910390848427\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_ngold = 974\n",
      "11/21/2023 15:56:58 - INFO - run_relation -   task_recall = 0.6683778234086243\n",
      "11/21/2023 15:56:58 - INFO - run_relation - Output predictions to C:\\Users\\odaim\\Documents\\PURE reproduction/scierc_models/rel_approx-scib-ctx0/predictions.json..\n"
     ]
    }
   ],
   "source": [
    "if do_eval:\n",
    "    logger.info(special_tokens)\n",
    "    if eval_test:\n",
    "        eval_dataset = test_dataset\n",
    "        eval_examples = test_examples\n",
    "        eval_features = convert_examples_to_features(\n",
    "            test_examples, label2id, max_seq_length, tokenizer, special_tokens, unused_tokens=not(add_new_tokens))\n",
    "        eval_nrel = test_nrel\n",
    "        logger.info(special_tokens)\n",
    "        logger.info(\"***** Test *****\")\n",
    "        logger.info(\"  Num examples = %d\", len(test_examples))\n",
    "        logger.info(\"  Batch size = %d\", eval_batch_size)\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_label_ids = torch.tensor([f.label_id for f in eval_features], dtype=torch.long)\n",
    "        all_sub_idx = torch.tensor([f.sub_idx for f in eval_features], dtype=torch.long)\n",
    "        all_obj_idx = torch.tensor([f.obj_idx for f in eval_features], dtype=torch.long)\n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids, all_sub_idx, all_obj_idx)\n",
    "        eval_dataloader = DataLoader(eval_data, batch_size=eval_batch_size)\n",
    "        eval_label_ids = all_label_ids\n",
    "    model = RelationModel.from_pretrained(output_dir, num_rel_labels=num_labels)\n",
    "    model.to(device)\n",
    "    preds, result, logits = evaluate(model, device, eval_dataloader, eval_label_ids, num_labels, e2e_ngold=eval_nrel)\n",
    "\n",
    "    logger.info('*** Evaluation Results ***')\n",
    "    for key in sorted(result.keys()):\n",
    "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
    "\n",
    "    print_pred_json(eval_dataset, eval_examples, preds, id2label, os.path.join(output_dir, prediction_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50470f7b-ef69-4d60-9242-d0a904d0e493",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "**Accuracy**: 0.8558\n",
    "\n",
    "**Evaluation Loss**: 0.4450\n",
    "\n",
    "**Precision**: 0.5792\\\n",
    "**Recall**: 0.6684\\\n",
    "**F1 Score**: 0.6206\n",
    "\n",
    "Implications:\n",
    "\n",
    "- The model achieved a relatively high overall accuracy, indicating strong performance in predicting entity relations.\n",
    "- The F1 score suggests a reasonable balance between precision and recall, with room for improvement.\n",
    "- The precision of 57.92% indicates that when the model predicts a relation, it is correct around 57.92% of the time.\n",
    "- The recall of 66.84% suggests that the model is capturing a substantial proportion of the actual relations.\n",
    "- The task-specific F1 score and recall metrics further emphasize the model's performance on the relation extraction task.\n",
    "\n",
    "In summary, the model is performing well in identifying entity relations, but there is still room for improvement, particularly in precision. The results provide insights into how well the model is generalizing to unseen data and its effectiveness in extracting relations between entities. Fine-tuning or adjusting the model architecture may be considered to further improve performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
